{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andychong23/IE4213_Part2_Assignment/blob/feature%2Fandy%2FQ1/IE4213_Assgn2_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gBUF2HJd1fVT",
        "outputId": "016d9ad4-cea9-40b8-86e3-01db3a4f3104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-6-dd38495b15a0>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-dd38495b15a0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Student_1 = Andy Chong Weikang #@param {type:\"string\"}  Name of student 1\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "Student_1 = Andy Chong Weikang #@param {type:\"string\"}  Name of student 1\n",
        "Student_2 = '' #@param {type:\"string\"}  Name of student 2\n",
        "Student_3 = '' #@param {type:\"string\"}  Name of student 3\n",
        "Student_4 = '' #@param {type:\"string\"}  Name of student 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PhWOSD2hLUM"
      },
      "source": [
        "# Overvew\n",
        "\n",
        "This is the skeleton code file for the EE4802/IE4213 assignment. Replace the `XX`. in the name of this Colab notebook with your group number (this is important for correct marks to be awarded to your group). Fill in the blank cells below with the necessary code (you should work on this Colab notebook section by section). At the end, the entire Colab notebook should generate all the required results and execute without error.\n",
        "\n",
        "The text above the blank cells provides information on the functionality that needs to be implemented. You need to write Python code at places indicated by `[WriteCode]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXckzF3Fhd4p"
      },
      "source": [
        "## Install and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "19JbK59PhbuE"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# %%capture hides the output\n",
        "# install visulization tool\n",
        "!pip install renderlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E669iRUFhn9J"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "import gymnasium as gym\n",
        "import renderlab as rl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d3w4FRMS36_"
      },
      "source": [
        "# Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8RD1Ggwcqg1"
      },
      "source": [
        "## Environment Exploration: Cart-Pole\n",
        "\n",
        "The **Cart-Pole environment** is a classic reinforcement learning problem where a pole is attached by an un-actuated joint to a cart. The cart moves along a frictionless track, and the goal is to balance the pole upright by applying forces to move the cart left or right.\n",
        "\n",
        "<img src=\"https://gymnasium.farama.org/_images/cart_pole.gif\" width=\"400\">\n",
        "\n",
        "Below is a breakdown of the base Cart-Pole environment:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geWhWkTJRu5w"
      },
      "source": [
        "#### - **Observation Space (*s*)**\n",
        "The observation is represented as a `ndarray` of shape `(4,)`, corresponding to:\n",
        "- **Cart Position**: Horizontal location of the cart.\n",
        "- **Cart Velocity**: Speed of the cart along the track.\n",
        "- **Pole Angle**: Angular position of the pole relative to vertical.\n",
        "- **Pole Angular Velocity**: Speed at which the pole angle changes.\n",
        "\n",
        "The observations are initialized with uniformly random values in the range `(-0.05, 0.05)`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r3befVJR4SJ"
      },
      "source": [
        "#### - **Action Space (*a*)**\n",
        "The action is a discrete value (`0` or `1`) indicating the direction of the force applied to the cart:\n",
        "- `0`: Push the cart to the left.\n",
        "- `1`: Push the cart to the right.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfanxRL4R5jO"
      },
      "source": [
        "\n",
        "#### - **Reward Function (*r*)**\n",
        "The agent receives a reward of `+1` for each time step it successfully keeps the pole upright. The maximum achievable reward in a single episode is `500`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spv7Ul4CR7SN"
      },
      "source": [
        "#### - **Episode Termination (*isDone*)**\n",
        "An episode ends if any of the following conditions occur:\n",
        "1. **Pole Angle** exceeds `±12°`.\n",
        "2. **Cart Position** exceeds `±2.4` (the cart reaches the edge of the track).\n",
        "3. **Truncation**: The episode reaches the maximum length of `500 steps`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD50TBeLif6F"
      },
      "source": [
        "## Getting Familiar with Basic Gym Usage\n",
        "\n",
        "Let's observe how to interact with a Gym environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkeWe780XZVv"
      },
      "source": [
        "The classic “agent-environment loop” pictured below is a simplified representation of reinforcement learning that Gymnasium implements.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1feMbDMTfOFTBtj2PAZz-kMjSQKVukEm6\" width=\"250\">\n",
        "\n",
        "\n",
        "The following section represents a simple episode of this loop, we will:\n",
        "\n",
        "1. Import the base Cart-Pole environment from the gym library and explore its functionality.\n",
        "\n",
        "2. Apply modifications to make the environment more challenging by adjusting the pole's dynamics and introducing stochastic forces.\n",
        "\n",
        "3. Sample random actions to control the cart-pole and visualize the process using `renderlab`.\n",
        "\n",
        "These steps will help us understand how the environment behaves under different conditions and prepare us for implementing reinforcement learning agents in later sections.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x2PMYpIKXtWv",
        "outputId": "b6eeee8c-f2d3-4da7-e66c-537e40759c85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Exploring the Base Environment ---\n",
            "Initial Observation: [ 0.04761885 -0.01017103 -0.00038496 -0.01980918]\n",
            "Action Space: Discrete(2)\n",
            "Observation Space: Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n",
            "\n",
            "--- Sampling Random Actions and Visualizing ---\n",
            "[-0.00278495  0.2426938   0.00613751 -0.27662826] 1.0 False False {}\n",
            "[ 0.00206893  0.43772766  0.00060494 -0.5673691 ] 1.0 False False {}\n",
            "[ 0.01082348  0.2425972  -0.01074244 -0.27449566] 1.0 False False {}\n",
            "[ 0.01567543  0.43787077 -0.01623235 -0.57054734] 1.0 False False {}\n",
            "[ 0.02443284  0.24298018 -0.0276433  -0.28302205] 1.0 False False {}\n",
            "[ 0.02929245  0.0482632  -0.03330374  0.00081575] 1.0 False False {}\n",
            "[ 0.03025771 -0.14636569 -0.03328742  0.2828077 ] 1.0 False False {}\n",
            "[ 0.0273304   0.04921485 -0.02763127 -0.02018528] 1.0 False False {}\n",
            "[ 0.02831469 -0.14550017 -0.02803498  0.2636532 ] 1.0 False False {}\n",
            "[ 0.02540469  0.05001049 -0.02276191 -0.03773876] 1.0 False False {}\n",
            "[ 0.0264049   0.24545133 -0.02351669 -0.3375155 ] 1.0 False False {}\n",
            "[ 0.03131393  0.05067179 -0.030267   -0.05234024] 1.0 False False {}\n",
            "[ 0.03232736 -0.14400339 -0.0313138   0.23064165] 1.0 False False {}\n",
            "[ 0.02944729 -0.3386642  -0.02670097  0.513285  ] 1.0 False False {}\n",
            "[ 0.02267401 -0.14317657 -0.01643527  0.2123089 ] 1.0 False False {}\n",
            "[ 0.01981048  0.05217646 -0.01218909 -0.08551283] 1.0 False False {}\n",
            "[ 0.02085401  0.24747099 -0.01389935 -0.38201636] 1.0 False False {}\n",
            "[ 0.02580343  0.05254913 -0.02153967 -0.09374809] 1.0 False False {}\n",
            "[ 0.02685441  0.24797308 -0.02341464 -0.39314818] 1.0 False False {}\n",
            "[ 0.03181387  0.44341934 -0.0312776  -0.6931205 ] 1.0 False False {}\n",
            "[ 0.04068226  0.6389609  -0.04514001 -0.9954835 ] 1.0 False False {}\n",
            "[ 0.05346148  0.8346566  -0.06504968 -1.3019947 ] 1.0 False False {}\n",
            "[ 0.07015461  0.64041746 -0.09108958 -1.0303633 ] 1.0 False False {}\n",
            "[ 0.08296296  0.44661775 -0.11169684 -0.7676123 ] 1.0 False False {}\n",
            "[ 0.09189531  0.64308566 -0.12704909 -1.0932482 ] 1.0 False False {}\n",
            "[ 0.10475703  0.8396315  -0.14891405 -1.4229428 ] 1.0 False False {}\n",
            "[ 0.12154966  0.64663154 -0.1773729  -1.1802659 ] 1.0 False False {}\n",
            "[ 0.13448228  0.4541989  -0.20097822 -0.94802034] 1.0 False False {}\n",
            "[ 0.14356627  0.2622669  -0.21993864 -0.7246078 ] 1.0 True False {}\n",
            "Moviepy - Building video temp-{start}.mp4.\n",
            "Moviepy - Writing video temp-{start}.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready temp-{start}.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video controls  >\n",
              " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import and Explore the Environment\n",
        "print(\"\\n--- Exploring the Base Environment ---\")\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "observation, info = env.reset()\n",
        "\n",
        "# Print information about the environment\n",
        "print(f\"Initial Observation: {observation}\")\n",
        "print(f\"Action Space: {env.action_space}\")  # Discrete actions: 0 (left), 1 (right)\n",
        "print(f\"Observation Space: {env.observation_space}\")  # State variables: cart position, etc.\n",
        "\n",
        "# Sample Random Actions and Visualize\n",
        "print(\"\\n--- Sampling Random Actions and Visualizing ---\")\n",
        "env = rl.RenderFrame(env, \"./output\")\n",
        "observation, info = env.reset()\n",
        "isDone = False\n",
        "\n",
        "# Simulate an episode with random actions\n",
        "while not isDone:\n",
        "    action = env.action_space.sample()  # Take random action\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "    print(observation, reward, terminated, truncated, info)\n",
        "    isDone = terminated or truncated\n",
        "\n",
        "env.close()\n",
        "env.play()  # Play the recorded video"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Helper Functions"
      ],
      "metadata": {
        "id": "s9wjDE0kfFJd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0UFVPRylCdv"
      },
      "source": [
        "## Plotting Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vsmmRtAVlUz_"
      },
      "outputs": [],
      "source": [
        "# Some plotting functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_eval_rwd_mean(eval_mean_list):\n",
        "  \"\"\"Plot evaluation reward mean.\"\"\"\n",
        "  # [WriteCode]\n",
        "  plt.plot(np.array([i for i in range(len(eval_mean_list))]), eval_mean_list)\n",
        "  plt.title(\"Evaluation Reward Mean\")\n",
        "  plt.xlabel(\"Episodes\")\n",
        "  plt.ylabel(\"Reward Mean\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def plot_eval_rwd_var(eval_var_list):\n",
        "  \"\"\"Plot evaluation reward variance.\"\"\"\n",
        "  # [WriteCode]\n",
        "  plt.plot(np.array([i for i in range(len(eval_var_list))]), eval_var_list)\n",
        "  plt.title(\"Evaluation Reward Varaince\")\n",
        "  plt.xlabel(\"Episodes\")\n",
        "  plt.ylabel(\"Reward Variance\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def plot_smoothed_training_rwd(train_rwd_list, window_size=20):\n",
        "  \"\"\"Plot smoothed training rewards using a moving average.\"\"\"\n",
        "  y_output = []\n",
        "  x_output = []\n",
        "  # [WriteCode]\n",
        "  for idx in range(len(train_rwd_list) - window_size):\n",
        "    current_window = train_rwd_list[idx:idx + window_size]\n",
        "    y_output.append(sum(current_window) / window_size)\n",
        "    x_output.append(idx)\n",
        "  plt.plot(x_output, y_output)\n",
        "  plt.title(\"Smoothed Training Rewards\")\n",
        "  plt.xlabel(\"Episodes\")\n",
        "  plt.ylabel(\"Average training rewards\")\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Function\n",
        "\n",
        "Evaluate the learnt policy by running 3 evaluation episodes and computing the average and variance of rewards collected."
      ],
      "metadata": {
        "id": "N7hA67eaYkCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model, max_timesteps=500):\n",
        "    eval_env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "    state_size = eval_env.observation_space.shape[0] # Number of observations (CartPole)\n",
        "    action_size = eval_env.action_space.n            # Number of possible actions\n",
        "    eval_reward = []\n",
        "\n",
        "    for i in range (3):\n",
        "        round_reward = 0\n",
        "        state, _ = eval_env.reset()\n",
        "        state = np.reshape(state, [1, state_size])\n",
        "\n",
        "        for i in range(max_timesteps):\n",
        "            action = np.argmax(model.predict(state, verbose=0)[0])\n",
        "            next_state, reward, terminated, truncated, _ = eval_env.step(action)\n",
        "            next_state = np.reshape(next_state, [1, state_size])\n",
        "\n",
        "            round_reward += reward\n",
        "            state = next_state\n",
        "\n",
        "            if terminated or truncated:\n",
        "                eval_reward.append(round_reward)\n",
        "                break\n",
        "\n",
        "    eval_env.close()\n",
        "\n",
        "    eval_reward_mean = np.sum(eval_reward)/len(eval_reward)\n",
        "    eval_reward_var = np.var(eval_reward)\n",
        "\n",
        "    return eval_reward_mean, eval_reward_var"
      ],
      "metadata": {
        "id": "kKS1vpSmYjyg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWS8Kd8eiXau"
      },
      "source": [
        "# Setting up Tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ADO90Q7Hs-lx"
      },
      "outputs": [],
      "source": [
        "def get_run_logdir(k):\n",
        "    root_logdir = os.path.join(os.curdir, \"ee4802_logs\", k)\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B07kopgXtOVU"
      },
      "source": [
        "# Initialize Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JL9ABa8-vRf3"
      },
      "outputs": [],
      "source": [
        "# Use the following set of NN hyperparameters for ALL FOUR basline policies\n",
        "lr =  0.01        #@param {type:\"number\"}               # learning rate\n",
        "epoch =  32     #@param {type:\"number\"}               # epochs\n",
        "episode = 30  #@param {type:\"number\"}               # episodes\n",
        "\n",
        "epsilon = 0.9           #@param {type:\"number\"}     # Starting exploration rate\n",
        "epsilon_min = 0.1    #@param {type:\"number\"}     # Exploration rate min\n",
        "epsilon_decay = 0.99     #@param {type:\"number\"}     # Exploration rate decay\n",
        "\n",
        "gamma = 0.99          #@param {type:\"number\"}     # Agent discount factor\n",
        "\n",
        "# Use the following set of NN hyperparameters for Naive DQN, DQN and DDQN policies\n",
        "ba =  32       #@param {type:\"number\"}               # batch_size\n",
        "\n",
        "# Use the following set of RL hyperparameters for DQN and DDQN policies\n",
        "target_update_freq = 0 # @param {type:\"number\"}    # Target network update frequency\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q-Network - Baseline"
      ],
      "metadata": {
        "id": "npUYex5Em46O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define and Compile the Neural Network\n",
        "\n",
        "A single network $Q_\\theta$ (parameterized by $\\theta$) is used to approximate $Q(s,a)$.\n",
        "\n",
        "The target used by Naive DQN is then:\n",
        "\n",
        "$Y^{NaiveQ}_t = R_{t+1} + \\gamma Q_{\\theta}(S_{t+1}, a)$\n",
        "\n",
        "The training of Q-Network does rely on a Replay Buffer."
      ],
      "metadata": {
        "id": "XLr4PDQ7nC5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q-Network Baseline Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, LayerNormalization\n",
        "from keras.activations import softmax, relu\n",
        "\n",
        "# [WriteCode] from ... import ...\n",
        "\n",
        "STATE_SIZE = (4,)\n",
        "ACTION_SIZE = 2\n",
        "LAYER_SIZE = 16\n",
        "\n",
        "# Define the Q-network\n",
        "model = Sequential()\n",
        "\n",
        "# [WriteCode]\n",
        "# model.add(...\n",
        "model.add(Input(shape=STATE_SIZE))\n",
        "'''\n",
        "Add in intermediate layers\n",
        "- Assume 3 layers of 32 nodes each with relu activation\n",
        "'''\n",
        "for i in range(2):\n",
        "  model.add(Dense(LAYER_SIZE, activation=relu))\n",
        "  model.add(LayerNormalization())\n",
        "model.add(Dense(ACTION_SIZE))\n",
        "\n",
        "# Compile the model\n",
        "# [WriteCode]\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "# Print the model summary\n",
        "# [WriteCode]\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "WyXho4UKpH3Q",
        "outputId": "4326d40d-387b-4a2f-e47c-6cf260faa871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m80\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m32\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m32\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m34\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m450\u001b[0m (1.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> (1.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m450\u001b[0m (1.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> (1.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up Env and Train the Policy"
      ],
      "metadata": {
        "id": "PunGDA41nK-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For logging\n",
        "train_reward_lst = []\n",
        "eval_reward_mean_lst = []\n",
        "eval_reward_var_lst = []\n",
        "\n",
        "\n",
        "# Set up environment\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "state_size = env.observation_space.shape[0] # Number of observations (CartPole)\n",
        "action_size = env.action_space.n            # Number of possible actions\n",
        "\n",
        "model_dir = \"q_net_baseline\"  # TensorBoard log directory\n",
        "cb = keras.callbacks.TensorBoard(log_dir = get_run_logdir(model_dir), histogram_freq=1)\n",
        "\n",
        "# For timing training\n",
        "total_training_time = 0\n",
        "\n",
        "for ep in range(episode):\n",
        "    state, _ = env.reset()\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "    total_reward = 0\n",
        "\n",
        "    # record start time\n",
        "    start = time.time()\n",
        "\n",
        "    for _ in range(500):\n",
        "        # Interact with the environment with epsilon-greedy policy\n",
        "        if np.random.rand() <= epsilon:\n",
        "            action = np.random.choice(action_size)\n",
        "        else:\n",
        "            q_values = model.predict(state, verbose=0)\n",
        "            action = np.argmax(q_values)\n",
        "\n",
        "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "        next_state = np.reshape(next_state, [1, state_size])\n",
        "\n",
        "        done = terminated or truncated\n",
        "\n",
        "        # Train model using Q-Learning update:  Q(s, a) = r + gamma * max Q(s', a')\n",
        "        # [WriteCode]\n",
        "        q_base = model.predict(state, verbose=0)\n",
        "        q_1_base = model.predict(next_state, verbose=0)\n",
        "        if done:\n",
        "          q_target = reward\n",
        "        else:\n",
        "          q_target = reward + gamma * np.max(q_1_base)\n",
        "\n",
        "        print(\n",
        "            f'''\n",
        "            Action Taken: {action}\n",
        "            Current State: {state}\n",
        "            Next State: {next_state}\n",
        "            Total Reward: {total_reward}\n",
        "            Reward: {reward}\n",
        "            Is terminated: {terminated}\n",
        "            Q Values: {model.predict(state, verbose=0)}\n",
        "            Q Target: {q_target}\n",
        "            Q change: {q_target - q_base[0][action]}\n",
        "            '''\n",
        "        )\n",
        "\n",
        "        q_feed = q_base.copy()\n",
        "        q_feed[0][action] = q_feed[0][action] + lr * (q_target - q_feed[0][action])\n",
        "        model.fit(state, q_feed, epochs=epoch, verbose=0, batch_size=ba)\n",
        "        # Hints:\n",
        "\n",
        "        # 1. Compute target Q-values:\n",
        "        # - If done, Q-target = reward (no future reward)\n",
        "        # - Otherwise, Q-target = reward + gamma * max(Q(next_state, a))\n",
        "\n",
        "        # 2. Predict current Q-values for state\n",
        "        # Update only the Q-value for the taken action\n",
        "\n",
        "        # new_q_val = current_q_val + lr * (q_target - current_q_val)\n",
        "        # print(new_q_val)\n",
        "        # 3. Fit the model:\n",
        "        # - Inputs: state\n",
        "        # - Targets: updated Q-values (with action Q-value replaced by computed target)\n",
        "        # model.fit(state, new_q_val, epochs=epoch, verbose=0, batch_size=ba)\n",
        "\n",
        "\n",
        "        # Update exploration rate\n",
        "        if epsilon > epsilon_min and ep >= 10:\n",
        "            epsilon *= epsilon_decay\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # record end time and log training time\n",
        "    end = time.time()\n",
        "    total_training_time += end - start\n",
        "\n",
        "    # Evaluation\n",
        "    # [WriteCode]\n",
        "    eval_reward_mean, eval_reward_var = evaluation(model)\n",
        "\n",
        "    print(f\"Episode {ep + 1}/{episode} | Ep. Total Reward: {total_reward}\"\n",
        "        f\" | Epsilon : {epsilon:.3f}\"\n",
        "        f\" | Eval Rwd Mean: {eval_reward_mean:.2f}\"\n",
        "        f\" | Eval Rwd Var: {eval_reward_var:.2f}\")\n",
        "\n",
        "    # Log\n",
        "    eval_reward_mean_lst.append(eval_reward_mean)\n",
        "    eval_reward_var_lst.append(eval_reward_var)\n",
        "    train_reward_lst.append(total_reward)\n",
        "\n",
        "    # Early Stopping Condition to avoid overfitting\n",
        "    # If the evaluation reward reaches the specified threshold, stop training early.\n",
        "    # The default threshold is set to 500, but you should adjust this based on observed training performance.\n",
        "    if eval_reward_mean > 500: # [Modify this threshold as needed]\n",
        "        print(f\"Early stopping triggered at Episode {ep + 1}.\")\n",
        "        break\n",
        "\n",
        "# evaluate average training time per episode\n",
        "print(f\"Training time: {total_training_time/(ep + 1):.4f} seconds per episode\")\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "id": "-cDAJtaGnCQL",
        "outputId": "d9b7973b-4c3d-4e9c-95ea-b7d620d6eb13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.0002199   0.00078131 -0.01746892  0.01014009]]\n",
            "            Next State: [[-2.0427530e-04  1.9614938e-01 -1.7266119e-02 -2.8800291e-01]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.58183914 -0.60826385]]\n",
            "            Q Target: 1.3501851558685303\n",
            "            Q change: 1.9584490060806274\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-2.0427530e-04  1.9614938e-01 -1.7266119e-02 -2.8800291e-01]]\n",
            "            Next State: [[ 0.00371871  0.00127785 -0.02302618 -0.00081517]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.35231104 0.1215034 ]]\n",
            "            Q Target: 1.574866771697998\n",
            "            Q change: 1.2225557565689087\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.00371871  0.00127785 -0.02302618 -0.00081517]]\n",
            "            Next State: [[ 0.00374427  0.19672233 -0.02304248 -0.30067328]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5815065  -0.49696442]]\n",
            "            Q Target: 1.3710343837738037\n",
            "            Q change: 1.8679988384246826\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.00374427  0.19672233 -0.02304248 -0.30067328]]\n",
            "            Next State: [[ 0.00767872  0.392165   -0.02905595 -0.60053337]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.38241217 0.14385785]]\n",
            "            Q Target: 1.3929482698440552\n",
            "            Q change: 1.2490904331207275\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.00767872  0.392165   -0.02905595 -0.60053337]]\n",
            "            Next State: [[ 0.01552202  0.19746132 -0.04106661 -0.31714237]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.39824617 0.15156685]]\n",
            "            Q Target: 1.403144359588623\n",
            "            Q change: 1.004898190498352\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01552202  0.19746132 -0.04106661 -0.31714237]]\n",
            "            Next State: [[ 0.01947124  0.00294763 -0.04740946 -0.03768799]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.41552132 0.17444693]]\n",
            "            Q Target: 1.4585239887237549\n",
            "            Q change: 1.0430026054382324\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.01947124  0.00294763 -0.04740946 -0.03768799]]\n",
            "            Next State: [[ 0.0195302   0.19871625 -0.04816322 -0.34494412]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.46963546 -0.15602328]]\n",
            "            Q Target: 1.4343796968460083\n",
            "            Q change: 1.5904029607772827\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.0195302   0.19871625 -0.04816322 -0.34494412]]\n",
            "            Next State: [[ 0.02350452  0.00431134 -0.0550621  -0.06782944]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.43797332 0.18223453]]\n",
            "            Q Target: 1.5155891180038452\n",
            "            Q change: 1.077615737915039\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.02350452  0.00431134 -0.0550621  -0.06782944]]\n",
            "            Next State: [[ 0.02359075 -0.18997972 -0.05641869  0.2069854 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5290058 -0.007225 ]]\n",
            "            Q Target: 0.18882685899734497\n",
            "            Q change: -0.3401789665222168\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.02359075 -0.18997972 -0.05641869  0.2069854 ]]\n",
            "            Next State: [[ 0.01979115 -0.38425142 -0.05227898  0.481351  ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.8187242 -2.2617054]]\n",
            "            Q Target: 0.2785448431968689\n",
            "            Q change: 1.097269058227539\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01979115 -0.38425142 -0.05227898  0.481351  ]]\n",
            "            Next State: [[ 0.01210612 -0.57859796 -0.04265196  0.7571095 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.71665996 -2.29111   ]]\n",
            "            Q Target: 0.3314363956451416\n",
            "            Q change: 1.0480964183807373\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01210612 -0.57859796 -0.04265196  0.7571095 ]]\n",
            "            Next State: [[ 5.3416484e-04 -7.7310693e-01 -2.7509773e-02  1.0360718e+00]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.66244924 -2.278116  ]]\n",
            "            Q Target: 0.34950023889541626\n",
            "            Q change: 1.0119495391845703\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 5.3416484e-04 -7.7310693e-01 -2.7509773e-02  1.0360718e+00]]\n",
            "            Next State: [[-0.01492797 -0.9678526  -0.00678834  1.3199928 ]]\n",
            "            Total Reward: 12.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.6480871 -2.2672038]]\n",
            "            Q Target: 0.3705565333366394\n",
            "            Q change: 1.0186436176300049\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01492797 -0.9678526  -0.00678834  1.3199928 ]]\n",
            "            Next State: [[-0.03428502 -1.162888    0.01961152  1.6105435 ]]\n",
            "            Total Reward: 13.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.6258575 -2.254614 ]]\n",
            "            Q Target: 0.39627891778945923\n",
            "            Q change: 1.0221364498138428\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.03428502 -1.162888    0.01961152  1.6105435 ]]\n",
            "            Next State: [[-0.05754279 -0.96800315  0.05182239  1.3240378 ]]\n",
            "            Total Reward: 14.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.60078037 -2.2408195 ]]\n",
            "            Q Target: 0.4760527014732361\n",
            "            Q change: 2.716872215270996\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.05754279 -0.96800315  0.05182239  1.3240378 ]]\n",
            "            Next State: [[-0.07690285 -0.7735727   0.07830314  1.0480126 ]]\n",
            "            Total Reward: 15.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.5302512 -2.1978564]]\n",
            "            Q Target: 0.5741651654243469\n",
            "            Q change: 2.772021532058716\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.07690285 -0.7735727   0.07830314  1.0480126 ]]\n",
            "            Next State: [[-0.0923743  -0.57957214  0.0992634   0.7809011 ]]\n",
            "            Total Reward: 16.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.4295882 -2.146397 ]]\n",
            "            Q Target: 0.7249445915222168\n",
            "            Q change: 2.8713417053222656\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.0923743  -0.57957214  0.0992634   0.7809011 ]]\n",
            "            Next State: [[-0.10396574 -0.38594463  0.11488142  0.52102506]]\n",
            "            Total Reward: 17.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.27729988 -2.053092  ]]\n",
            "            Q Target: 0.9077606797218323\n",
            "            Q change: 2.96085262298584\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.10396574 -0.38594463  0.11488142  0.52102506]]\n",
            "            Next State: [[-0.11168464 -0.5824804   0.12530191  0.84758633]]\n",
            "            Total Reward: 18.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.09698096 -1.9154787 ]]\n",
            "            Q Target: 0.7962110638618469\n",
            "            Q change: 0.8931920528411865\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.11168464 -0.5824804   0.12530191  0.84758633]]\n",
            "            Next State: [[-0.12333424 -0.77906835  0.14225364  1.1768988 ]]\n",
            "            Total Reward: 19.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.2001435 -1.9489006]]\n",
            "            Q Target: 0.7145267724990845\n",
            "            Q change: 0.9146702885627747\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.12333424 -0.77906835  0.14225364  1.1768988 ]]\n",
            "            Next State: [[-0.13891561 -0.5860514   0.16579162  0.93197954]]\n",
            "            Total Reward: 20.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.28188512 -1.9715282 ]]\n",
            "            Q Target: 0.9053853154182434\n",
            "            Q change: 2.876913547515869\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.13891561 -0.5860514   0.16579162  0.93197954]]\n",
            "            Next State: [[-0.15063664 -0.39350766  0.18443121  0.69564396]]\n",
            "            Total Reward: 21.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.0969261 -1.8023335]]\n",
            "            Q Target: 1.1443928480148315\n",
            "            Q change: 2.9467263221740723\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.15063664 -0.39350766  0.18443121  0.69564396]]\n",
            "            Next State: [[-0.1585068  -0.59064335  0.1983441   1.0402485 ]]\n",
            "            Total Reward: 22.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.14231294 -1.5470111 ]]\n",
            "            Q Target: 1.0134363174438477\n",
            "            Q change: 0.8711233735084534\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.1585068  -0.59064335  0.1983441   1.0402485 ]]\n",
            "            Next State: [[-0.17031966 -0.78776777  0.21914905  1.3880695 ]]\n",
            "            Total Reward: 23.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.01665106 -1.7085491 ]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.9833489656448364\n",
            "            \n",
            "Episode 1/30 | Ep. Total Reward: 24.0 | Epsilon : 0.900 | Eval Rwd Mean: 10.67 | Eval Rwd Var: 6.22\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03778699  0.00231729  0.0387683   0.01504419]]\n",
            "            Next State: [[-0.03774064 -0.19333859  0.03906918  0.3197025 ]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.48521197 -0.43824056]]\n",
            "            Q Target: 1.0422437191009521\n",
            "            Q change: 0.5570317506790161\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03774064 -0.19333859  0.03906918  0.3197025 ]]\n",
            "            Next State: [[-0.04160741 -0.38899454  0.04546323  0.6244459 ]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.1579531 -1.7058363]]\n",
            "            Q Target: 0.8010428547859192\n",
            "            Q change: 0.643089771270752\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.04160741 -0.38899454  0.04546323  0.6244459 ]]\n",
            "            Next State: [[-0.0493873  -0.58472073  0.05795215  0.9310934 ]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.20587677 -1.8722397 ]]\n",
            "            Q Target: 0.6846939325332642\n",
            "            Q change: 0.8905707001686096\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.0493873  -0.58472073  0.05795215  0.9310934 ]]\n",
            "            Next State: [[-0.06108172 -0.39042675  0.07657402  0.65717006]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.30891627 -1.9308378 ]]\n",
            "            Q Target: 0.9073549509048462\n",
            "            Q change: 2.8381927013397217\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.06108172 -0.39042675  0.07657402  0.65717006]]\n",
            "            Next State: [[-0.06889025 -0.5865264   0.08971743  0.9729484 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.0931582 -1.7468091]]\n",
            "            Q Target: 0.768157958984375\n",
            "            Q change: 0.8613161444664001\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.06889025 -0.5865264   0.08971743  0.9729484 ]]\n",
            "            Next State: [[-0.08062078 -0.7827301   0.10917639  1.2924118 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.22631226 -1.8295394 ]]\n",
            "            Q Target: 0.7152093648910522\n",
            "            Q change: 0.9415216445922852\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.08062078 -0.7827301   0.10917639  1.2924118 ]]\n",
            "            Next State: [[-0.09627538 -0.5891521   0.13502462  1.0358077 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.27736092 -1.861301  ]]\n",
            "            Q Target: 0.8926798701286316\n",
            "            Q change: 2.753980875015259\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.09627538 -0.5891521   0.13502462  1.0358077 ]]\n",
            "            Next State: [[-0.10805842 -0.78578544  0.15574078  1.3676498 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.10863563 -1.7038898 ]]\n",
            "            Q Target: 0.8223304748535156\n",
            "            Q change: 0.9309661388397217\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.10805842 -0.78578544  0.15574078  1.3676498 ]]\n",
            "            Next State: [[-0.12377413 -0.59291756  0.18309377  1.1274524 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.17228949 -1.7665834 ]]\n",
            "            Q Target: 1.0559780597686768\n",
            "            Q change: 2.822561502456665\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.12377413 -0.59291756  0.18309377  1.1274524 ]]\n",
            "            Next State: [[-0.13563249 -0.40060386  0.20564282  0.8973329 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.05528279 -1.627398  ]]\n",
            "            Q Target: 1.429116129875183\n",
            "            Q change: 3.056514263153076\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.13563249 -0.40060386  0.20564282  0.8973329 ]]\n",
            "            Next State: [[-0.14364456 -0.20877352  0.22358948  0.675684  ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.4253211 -1.3931415]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 2.393141508102417\n",
            "            \n",
            "Episode 2/30 | Ep. Total Reward: 11.0 | Epsilon : 0.900 | Eval Rwd Mean: 9.33 | Eval Rwd Var: 0.22\n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.0277782  -0.03667396  0.04165072  0.01413398]]\n",
            "            Next State: [[ 0.02704472  0.15782668  0.0419334  -0.2651222 ]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.6576418 -0.6871127]]\n",
            "            Q Target: 1.215213656425476\n",
            "            Q change: 1.9023263454437256\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.02704472  0.15782668  0.0419334  -0.2651222 ]]\n",
            "            Next State: [[ 0.03020125  0.35232583  0.03663096 -0.5442896 ]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.13959917 0.05091666]]\n",
            "            Q Target: 1.2265605926513672\n",
            "            Q change: 1.1756439208984375\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.03020125  0.35232583  0.03663096 -0.5442896 ]]\n",
            "            Next State: [[ 0.03724777  0.5469144   0.02574516 -0.82520956]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.23733483 0.11194038]]\n",
            "            Q Target: 1.2798759937286377\n",
            "            Q change: 1.1679356098175049\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.03724777  0.5469144   0.02574516 -0.82520956]]\n",
            "            Next State: [[ 0.04818605  0.35144997  0.00924097 -0.52454185]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.28134102 0.13201685]]\n",
            "            Q Target: 1.2595272064208984\n",
            "            Q change: 0.9781861901283264\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.04818605  0.35144997  0.00924097 -0.52454185]]\n",
            "            Next State: [[ 0.05521505  0.54644066 -0.00124986 -0.81429857]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.26998    0.14267656]]\n",
            "            Q Target: 1.3048590421676636\n",
            "            Q change: 1.1621824502944946\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.05521505  0.54644066 -0.00124986 -0.81429857]]\n",
            "            Next State: [[ 0.06614386  0.7415797  -0.01753584 -1.1073744 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.3067018  0.15551974]]\n",
            "            Q Target: 1.3267674446105957\n",
            "            Q change: 1.1712477207183838\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.06614386  0.7415797  -0.01753584 -1.1073744 ]]\n",
            "            Next State: [[ 0.08097546  0.93692774 -0.03968332 -1.4055066 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.32954004 0.16831362]]\n",
            "            Q Target: 1.3431357145309448\n",
            "            Q change: 1.1748220920562744\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.08097546  0.93692774 -0.03968332 -1.4055066 ]]\n",
            "            Next State: [[ 0.09971401  0.74232024 -0.06779346 -1.125489  ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.3467062  0.18105054]]\n",
            "            Q Target: 1.3503419160842896\n",
            "            Q change: 1.0036356449127197\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.09971401  0.74232024 -0.06779346 -1.125489  ]]\n",
            "            Next State: [[ 0.11456042  0.54814905 -0.09030323 -0.85481733]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.36192536 0.18971309]]\n",
            "            Q Target: 1.364619493484497\n",
            "            Q change: 1.0026941299438477\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.11456042  0.54814905 -0.09030323 -0.85481733]]\n",
            "            Next State: [[ 0.1255234   0.744378   -0.10739958 -1.1744745 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.3806698 0.1960408]]\n",
            "            Q Target: 1.3876255750656128\n",
            "            Q change: 1.191584825515747\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.1255234   0.744378   -0.10739958 -1.1744745 ]]\n",
            "            Next State: [[ 0.14041096  0.550803   -0.13088907 -0.9172998 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.3914045 0.2049289]]\n",
            "            Q Target: 1.4041351079940796\n",
            "            Q change: 1.012730598449707\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.14041096  0.550803   -0.13088907 -0.9172998 ]]\n",
            "            Next State: [[ 0.15142702  0.3576704  -0.14923507 -0.66845053]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.4162678  0.21339408]]\n",
            "            Q Target: 1.436232566833496\n",
            "            Q change: 1.0199646949768066\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.15142702  0.3576704  -0.14923507 -0.66845053]]\n",
            "            Next State: [[ 0.15858042  0.55451775 -0.16260408 -1.004152  ]]\n",
            "            Total Reward: 12.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.44878787 0.22684804]]\n",
            "            Q Target: 1.442850112915039\n",
            "            Q change: 1.216002106666565\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.15858042  0.55451775 -0.16260408 -1.004152  ]]\n",
            "            Next State: [[ 0.16967078  0.361897   -0.18268712 -0.7666275 ]]\n",
            "            Total Reward: 13.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.44724405 0.2308861 ]]\n",
            "            Q Target: 1.4685819149017334\n",
            "            Q change: 1.021337866783142\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.16967078  0.361897   -0.18268712 -0.7666275 ]]\n",
            "            Next State: [[ 0.17690872  0.16969712 -0.19801967 -0.536537  ]]\n",
            "            Total Reward: 14.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.48124307 0.25165847]]\n",
            "            Q Target: 1.493074893951416\n",
            "            Q change: 1.0118317604064941\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.17690872  0.16969712 -0.19801967 -0.536537  ]]\n",
            "            Next State: [[ 0.18030266 -0.0221705  -0.20875041 -0.3121978 ]]\n",
            "            Total Reward: 15.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.50524557 0.27674377]]\n",
            "            Q Target: 1.4953519105911255\n",
            "            Q change: 0.9901063442230225\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.18030266 -0.0221705  -0.20875041 -0.3121978 ]]\n",
            "            Next State: [[ 0.17985925 -0.21380238 -0.21499437 -0.09191814]]\n",
            "            Total Reward: 16.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[0.5101655  0.30954495]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.4898344874382019\n",
            "            \n",
            "Episode 3/30 | Ep. Total Reward: 17.0 | Epsilon : 0.900 | Eval Rwd Mean: 9.33 | Eval Rwd Var: 0.22\n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.03866478  0.0058923  -0.00465642 -0.02827025]]\n",
            "            Next State: [[ 0.03878263  0.20108071 -0.00522183 -0.3224187 ]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.12416738 -0.20773631]]\n",
            "            Q Target: 1.3000907897949219\n",
            "            Q change: 1.5078270435333252\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.03878263  0.20108071 -0.00522183 -0.3224187 ]]\n",
            "            Next State: [[ 0.04280424  0.39627662 -0.0116702  -0.6167438 ]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.30245197 0.20952323]]\n",
            "            Q Target: 1.3558493852615356\n",
            "            Q change: 1.1463261842727661\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.04280424  0.39627662 -0.0116702  -0.6167438 ]]\n",
            "            Next State: [[ 0.05072978  0.59155965 -0.02400508 -0.9130793 ]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.35917297 0.2210533 ]]\n",
            "            Q Target: 1.383909821510315\n",
            "            Q change: 1.1628565788269043\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.05072978  0.59155965 -0.02400508 -0.9130793 ]]\n",
            "            Next State: [[ 0.06256097  0.39677054 -0.04226666 -0.6280366 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.38832372 0.2342655 ]]\n",
            "            Q Target: 1.3846757411956787\n",
            "            Q change: 0.9963520169258118\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.06256097  0.39677054 -0.04226666 -0.6280366 ]]\n",
            "            Next State: [[ 0.07049638  0.5924561  -0.0548274  -0.93372554]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.39852142 0.24567401]]\n",
            "            Q Target: 1.415186882019043\n",
            "            Q change: 1.1695128679275513\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.07049638  0.5924561  -0.0548274  -0.93372554]]\n",
            "            Next State: [[ 0.0823455   0.78827316 -0.07350191 -1.2431209 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.42018905 0.2547872 ]]\n",
            "            Q Target: 1.4304749965667725\n",
            "            Q change: 1.1756877899169922\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.0823455   0.78827316 -0.07350191 -1.2431209 ]]\n",
            "            Next State: [[ 0.09811097  0.9842574  -0.09836432 -1.5578936 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.4353483  0.26798117]]\n",
            "            Q Target: 1.4426509141921997\n",
            "            Q change: 1.1746697425842285\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.09811097  0.9842574  -0.09836432 -1.5578936 ]]\n",
            "            Next State: [[ 0.11779612  0.7904413  -0.1295222  -1.2974473 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.4472041  0.28312883]]\n",
            "            Q Target: 1.4580392837524414\n",
            "            Q change: 1.0108351707458496\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.11779612  0.7904413  -0.1295222  -1.2974473 ]]\n",
            "            Next State: [[ 0.13360494  0.59717995 -0.15547115 -1.0479567 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.4743445  0.29063398]]\n",
            "            Q Target: 1.4890965223312378\n",
            "            Q change: 1.0147520303726196\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.13360494  0.59717995 -0.15547115 -1.0479567 ]]\n",
            "            Next State: [[ 0.14554854  0.4044242  -0.17643028 -0.807835  ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5057133  0.29826942]]\n",
            "            Q Target: 1.5284135341644287\n",
            "            Q change: 1.022700309753418\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.14554854  0.4044242  -0.17643028 -0.807835  ]]\n",
            "            Next State: [[ 0.15363702  0.6014683  -0.19258697 -1.1504147 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5452172 0.310523 ]]\n",
            "            Q Target: 1.5346932411193848\n",
            "            Q change: 1.224170207977295\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.15363702  0.6014683  -0.19258697 -1.1504147 ]]\n",
            "            Next State: [[ 0.16566639  0.7985092  -0.21559528 -1.496783  ]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[0.5535294  0.31374812]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.6862518787384033\n",
            "            \n",
            "Episode 4/30 | Ep. Total Reward: 12.0 | Epsilon : 0.900 | Eval Rwd Mean: 11.33 | Eval Rwd Var: 3.56\n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.02622732  0.03506488 -0.00806444  0.02264315]]\n",
            "            Next State: [[-0.02552602  0.23030154 -0.00761157 -0.27257326]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.2813469 -0.3568425]]\n",
            "            Q Target: 1.3981324434280396\n",
            "            Q change: 1.7549749612808228\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.02552602  0.23030154 -0.00761157 -0.27257326]]\n",
            "            Next State: [[-0.02091999  0.42553127 -0.01306304 -0.56764716]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.40049893 0.20976375]]\n",
            "            Q Target: 1.4133937358856201\n",
            "            Q change: 1.203629970550537\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.02091999  0.42553127 -0.01306304 -0.56764716]]\n",
            "            Next State: [[-0.01240936  0.620834   -0.02441598 -0.86441666]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.4189819  0.28170183]]\n",
            "            Q Target: 1.4486522674560547\n",
            "            Q change: 1.1669504642486572\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.01240936  0.620834   -0.02441598 -0.86441666]]\n",
            "            Next State: [[ 7.3156548e-06  8.1627965e-01 -4.1704316e-02 -1.1646754e+00]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.45330164 0.303543  ]]\n",
            "            Q Target: 1.4698277711868286\n",
            "            Q change: 1.1662847995758057\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 7.3156548e-06  8.1627965e-01 -4.1704316e-02 -1.1646754e+00]]\n",
            "            Next State: [[ 0.01633291  1.0119189  -0.06499782 -1.4701366 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.47434124 0.3233538 ]]\n",
            "            Q Target: 1.4851069450378418\n",
            "            Q change: 1.1617531776428223\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.01633291  1.0119189  -0.06499782 -1.4701366 ]]\n",
            "            Next State: [[ 0.03657129  1.2077731  -0.09440055 -1.7823933 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.48989978 0.34178162]]\n",
            "            Q Target: 1.4976378679275513\n",
            "            Q change: 1.1558562517166138\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.03657129  1.2077731  -0.09440055 -1.7823933 ]]\n",
            "            Next State: [[ 0.06072675  1.4038212  -0.13004842 -2.1028688 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.50278866 0.35924414]]\n",
            "            Q Target: 1.5087387561798096\n",
            "            Q change: 1.1494946479797363\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.06072675  1.4038212  -0.13004842 -2.1028688 ]]\n",
            "            Next State: [[ 0.08880317  1.2102221  -0.1721058  -1.8530489 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5142174  0.37604207]]\n",
            "            Q Target: 1.5235142707824707\n",
            "            Q change: 1.0092968940734863\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.08880317  1.2102221  -0.1721058  -1.8530489 ]]\n",
            "            Next State: [[ 0.11300761  1.0173601  -0.20916678 -1.6183796 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5400803  0.37974077]]\n",
            "            Q Target: 1.5411057472229004\n",
            "            Q change: 1.0010254383087158\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.11300761  1.0173601  -0.20916678 -1.6183796 ]]\n",
            "            Next State: [[ 0.13335481  0.8252268  -0.24153437 -1.3975087 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[0.55440354 0.37866655]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.44559645652770996\n",
            "            \n",
            "Episode 5/30 | Ep. Total Reward: 10.0 | Epsilon : 0.900 | Eval Rwd Mean: 9.33 | Eval Rwd Var: 0.22\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01392827 -0.01704143  0.02896043  0.02907268]]\n",
            "            Next State: [[-0.0142691  -0.21256647  0.02954188  0.33075044]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.02293993 -0.71887606]]\n",
            "            Q Target: 0.9092585444450378\n",
            "            Q change: 0.8863186240196228\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0142691  -0.21256647  0.02954188  0.33075044]]\n",
            "            Next State: [[-0.01852043 -0.4080962   0.03615689  0.63260114]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.08971456 -1.7776448 ]]\n",
            "            Q Target: 0.7174904346466064\n",
            "            Q change: 0.8072049617767334\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.01852043 -0.4080962   0.03615689  0.63260114]]\n",
            "            Next State: [[-0.02668236 -0.21349683  0.04880891  0.35152066]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.27591085 -1.8800447 ]]\n",
            "            Q Target: 1.0362204313278198\n",
            "            Q change: 2.9162650108337402\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.02668236 -0.21349683  0.04880891  0.35152066]]\n",
            "            Next State: [[-0.03095229 -0.40927768  0.05583933  0.6591863 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.04196261 -1.6633728 ]]\n",
            "            Q Target: 0.7884775400161743\n",
            "            Q change: 0.7465149164199829\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03095229 -0.40927768  0.05583933  0.6591863 ]]\n",
            "            Next State: [[-0.03913785 -0.6051305   0.06902306  0.9689159 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.19959207 -1.7995992 ]]\n",
            "            Q Target: 0.7156520485877991\n",
            "            Q change: 0.9152441024780273\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03913785 -0.6051305   0.06902306  0.9689159 ]]\n",
            "            Next State: [[-0.05124046 -0.8011078   0.08840137  1.2824585 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.27614814 -1.8403199 ]]\n",
            "            Q Target: 0.6909189224243164\n",
            "            Q change: 0.9670670628547668\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.05124046 -0.8011078   0.08840137  1.2824585 ]]\n",
            "            Next State: [[-0.06726261 -0.99723744  0.11405054  1.6014603 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.3018534 -1.8535261]]\n",
            "            Q Target: 0.6871399879455566\n",
            "            Q change: 0.9889934062957764\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.06726261 -0.99723744  0.11405054  1.6014603 ]]\n",
            "            Next State: [[-0.08720736 -0.8036357   0.14607975  1.3464026 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.30728242 -1.855485  ]]\n",
            "            Q Target: 0.7959808111190796\n",
            "            Q change: 2.651465892791748\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.08720736 -0.8036357   0.14607975  1.3464026 ]]\n",
            "            Next State: [[-0.10328007 -1.0002607   0.1730078   1.6809938 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.207469  -1.7515225]]\n",
            "            Q Target: 0.7664153575897217\n",
            "            Q change: 0.9738843441009521\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.10328007 -1.0002607   0.1730078   1.6809938 ]]\n",
            "            Next State: [[-0.12328529 -1.1969137   0.20662768  2.0221806 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.22783779 -1.7602726 ]]\n",
            "            Q Target: 0.7695364356040955\n",
            "            Q change: 0.9973742365837097\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.12328529 -1.1969137   0.20662768  2.0221806 ]]\n",
            "            Next State: [[-0.14722356 -1.3934914   0.2470713   2.371092  ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[-0.22539039 -1.7692506 ]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 1.2253904342651367\n",
            "            \n",
            "Episode 6/30 | Ep. Total Reward: 11.0 | Epsilon : 0.900 | Eval Rwd Mean: 9.00 | Eval Rwd Var: 0.00\n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.04417366  0.0018887  -0.01663312 -0.04370378]]\n",
            "            Next State: [[ 0.04421144  0.19724517 -0.0175072  -0.34158784]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.26030865 -0.02103069]]\n",
            "            Q Target: 1.4224942922592163\n",
            "            Q change: 1.443524956703186\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.04421144  0.19724517 -0.0175072  -0.34158784]]\n",
            "            Next State: [[ 0.04815634  0.00237662 -0.02433896 -0.05447668]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.42557845 0.36826155]]\n",
            "            Q Target: 1.302840232849121\n",
            "            Q change: 0.877261757850647\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.04815634  0.00237662 -0.02433896 -0.05447668]]\n",
            "            Next State: [[ 0.04820387 -0.19238804 -0.02542849  0.23042884]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.3114791  0.04747549]]\n",
            "            Q Target: 0.5580049753189087\n",
            "            Q change: 0.24652588367462158\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.04820387 -0.19238804 -0.02542849  0.23042884]]\n",
            "            Next State: [[ 0.04435611  0.00308787 -0.02081991 -0.0701654 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.44641188 -1.978016  ]]\n",
            "            Q Target: 1.312788486480713\n",
            "            Q change: 3.290804386138916\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.04435611  0.00308787 -0.02081991 -0.0701654 ]]\n",
            "            Next State: [[ 0.04441787  0.19850203 -0.02222322 -0.36934373]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.31046063 0.06213892]]\n",
            "            Q Target: 1.4440163373947144\n",
            "            Q change: 1.3818774223327637\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.04441787  0.19850203 -0.02222322 -0.36934373]]\n",
            "            Next State: [[ 0.04838791  0.39393258 -0.0296101  -0.66895026]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.44816792 0.377307  ]]\n",
            "            Q Target: 1.4916762113571167\n",
            "            Q change: 1.1143691539764404\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.04838791  0.39393258 -0.0296101  -0.66895026]]\n",
            "            Next State: [[ 0.05626656  0.19923459 -0.0429891  -0.38573536]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.49760416 0.40030402]]\n",
            "            Q Target: 1.4768059253692627\n",
            "            Q change: 0.9792017936706543\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.05626656  0.19923459 -0.0429891  -0.38573536]]\n",
            "            Next State: [[ 0.06025125  0.3949396  -0.05070381 -0.6916566 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.48941097 0.40190527]]\n",
            "            Q Target: 1.5207035541534424\n",
            "            Q change: 1.1187982559204102\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.06025125  0.3949396  -0.05070381 -0.6916566 ]]\n",
            "            Next State: [[ 0.06815004  0.59072703 -0.06453694 -0.9998608 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.52681935 0.4192496 ]]\n",
            "            Q Target: 1.534626841545105\n",
            "            Q change: 1.1153771877288818\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.06815004  0.59072703 -0.06453694 -0.9998608 ]]\n",
            "            Next State: [[ 0.07996459  0.39652428 -0.08453415 -0.72812384]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5385799  0.43048206]]\n",
            "            Q Target: 1.533475399017334\n",
            "            Q change: 0.9948955178260803\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.07996459  0.39652428 -0.08453415 -0.72812384]]\n",
            "            Next State: [[ 0.08789507  0.5927068  -0.09909663 -1.0461702 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.54725575 0.43257725]]\n",
            "            Q Target: 1.5485081672668457\n",
            "            Q change: 1.1159309148788452\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.08789507  0.5927068  -0.09909663 -1.0461702 ]]\n",
            "            Next State: [[ 0.09974921  0.78899443 -0.12002004 -1.3682439 ]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5546036  0.44115078]]\n",
            "            Q Target: 1.5551632642745972\n",
            "            Q change: 1.1140124797821045\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.09974921  0.78899443 -0.12002004 -1.3682439 ]]\n",
            "            Next State: [[ 0.1155291   0.98539644 -0.14738491 -1.6959289 ]]\n",
            "            Total Reward: 12.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.56235677 0.4469309 ]]\n",
            "            Q Target: 1.5629022121429443\n",
            "            Q change: 1.115971326828003\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.1155291   0.98539644 -0.14738491 -1.6959289 ]]\n",
            "            Next State: [[ 0.13523702  1.1818795  -0.1813035  -2.0306327 ]]\n",
            "            Total Reward: 13.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.56852835 0.45089146]]\n",
            "            Q Target: 1.5677114725112915\n",
            "            Q change: 1.116819977760315\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.13523702  1.1818795  -0.1813035  -2.0306327 ]]\n",
            "            Next State: [[ 0.15887462  0.98903453 -0.22191615 -1.7991182 ]]\n",
            "            Total Reward: 14.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[0.57347846 0.4564469 ]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.42652153968811035\n",
            "            \n",
            "Episode 7/30 | Ep. Total Reward: 15.0 | Epsilon : 0.900 | Eval Rwd Mean: 9.00 | Eval Rwd Var: 0.67\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.02257644 -0.00584615  0.03100338 -0.02533643]]\n",
            "            Next State: [[ 0.02245952 -0.20139869  0.03049665  0.27696493]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.06635489 -0.11415653]]\n",
            "            Q Target: 0.922113299369812\n",
            "            Q change: 0.9884681701660156\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.02245952 -0.20139869  0.03049665  0.27696493]]\n",
            "            Next State: [[ 0.01843154 -0.39694214  0.03603595  0.57910836]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.07833264 -1.7981085 ]]\n",
            "            Q Target: 0.7560000419616699\n",
            "            Q change: 0.8343327045440674\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.01843154 -0.39694214  0.03603595  0.57910836]]\n",
            "            Next State: [[ 0.0104927  -0.20234326  0.04761811  0.2979918 ]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.23626697 -1.8759868 ]]\n",
            "            Q Target: 1.0204132795333862\n",
            "            Q change: 2.896399974822998\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.0104927  -0.20234326  0.04761811  0.2979918 ]]\n",
            "            Next State: [[ 0.00644584 -0.3981105   0.05357795  0.60530424]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.02400488 -1.6757715 ]]\n",
            "            Q Target: 0.8265137076377869\n",
            "            Q change: 0.8025088310241699\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.00644584 -0.3981105   0.05357795  0.60530424]]\n",
            "            Next State: [[-0.00151637 -0.5939391   0.06568404  0.91437006]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.16629545 -1.7996343 ]]\n",
            "            Q Target: 0.7652018070220947\n",
            "            Q change: 0.9314972758293152\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.00151637 -0.5939391   0.06568404  0.91437006]]\n",
            "            Next State: [[-0.01339516 -0.7898851   0.08397144  1.2269524 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.227035  -1.8287389]]\n",
            "            Q Target: 0.7495520114898682\n",
            "            Q change: 0.9765869975090027\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.01339516 -0.7898851   0.08397144  1.2269524 ]]\n",
            "            Next State: [[-0.02919286 -0.5959384   0.10851049  0.96171606]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.24152143 -1.8348665 ]]\n",
            "            Q Target: 0.8736008405685425\n",
            "            Q change: 2.708467483520508\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.02919286 -0.5959384   0.10851049  0.96171606]]\n",
            "            Next State: [[-0.04111163 -0.7923381   0.12774481  1.2864224 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.12695998 -1.7249758 ]]\n",
            "            Q Target: 0.8413025736808777\n",
            "            Q change: 0.9682625532150269\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.04111163 -0.7923381   0.12774481  1.2864224 ]]\n",
            "            Next State: [[-0.05695839 -0.9888332   0.15347326  1.6162183 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.1500308 -1.7571591]]\n",
            "            Q Target: 0.843920111656189\n",
            "            Q change: 0.9939509034156799\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.05695839 -0.9888332   0.15347326  1.6162183 ]]\n",
            "            Next State: [[-0.07673505 -0.7958183   0.18579762  1.3750433 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.15078887 -1.777817  ]]\n",
            "            Q Target: 0.9882088303565979\n",
            "            Q change: 2.7660257816314697\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.07673505 -0.7958183   0.18579762  1.3750433 ]]\n",
            "            Next State: [[-0.09265142 -0.6034397   0.21329848  1.1457525 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[-0.01392715 -1.6925988 ]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 2.692598819732666\n",
            "            \n",
            "Episode 8/30 | Ep. Total Reward: 11.0 | Epsilon : 0.900 | Eval Rwd Mean: 9.33 | Eval Rwd Var: 0.22\n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[0.04455914 0.02705013 0.04370251 0.01537833]]\n",
            "            Next State: [[ 0.04510014  0.22151898  0.04401008 -0.26320198]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.15181819  0.10819528]]\n",
            "            Q Target: 1.4301908016204834\n",
            "            Q change: 1.321995496749878\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.04510014  0.22151898  0.04401008 -0.26320198]]\n",
            "            Next State: [[0.04953052 0.02579736 0.03874604 0.04303096]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.3335755  0.44279465]]\n",
            "            Q Target: 1.1088770627975464\n",
            "            Q change: 0.7753015756607056\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[0.04953052 0.02579736 0.03874604 0.04303096]]\n",
            "            Next State: [[ 0.05004647  0.2203429   0.03960666 -0.23717985]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.26142055  0.0937311 ]]\n",
            "            Q Target: 1.435929536819458\n",
            "            Q change: 1.3421984910964966\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.05004647  0.2203429   0.03960666 -0.23717985]]\n",
            "            Next State: [[ 0.05445332  0.4148773   0.03486306 -0.51711124]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.34360692 0.4398852 ]]\n",
            "            Q Target: 1.4446842670440674\n",
            "            Q change: 1.0047991275787354\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.05445332  0.4148773   0.03486306 -0.51711124]]\n",
            "            Next State: [[ 0.06275087  0.21928224  0.02452084 -0.2136493 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.44033805 0.45825392]]\n",
            "            Q Target: 1.4427675008773804\n",
            "            Q change: 1.002429485321045\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.06275087  0.21928224  0.02452084 -0.2136493 ]]\n",
            "            Next State: [[ 0.06713651  0.41404518  0.02024785 -0.49849752]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.35873967 0.44551572]]\n",
            "            Q Target: 1.4547951221466064\n",
            "            Q change: 1.0092793703079224\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.06713651  0.41404518  0.02024785 -0.49849752]]\n",
            "            Next State: [[ 0.07541741  0.6088759   0.0102779  -0.7847312 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.45955122 0.46499786]]\n",
            "            Q Target: 1.4998779296875\n",
            "            Q change: 1.0348800420761108\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.07541741  0.6088759   0.0102779  -0.7847312 ]]\n",
            "            Next State: [[ 0.08759493  0.8038551  -0.00541672 -1.074163  ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.50319874 0.48218834]]\n",
            "            Q Target: 1.5255770683288574\n",
            "            Q change: 1.0433887243270874\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.08759493  0.8038551  -0.00541672 -1.074163  ]]\n",
            "            Next State: [[ 0.10367204  0.99904823 -0.02689998 -1.3685409 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5299728 0.4960998]]\n",
            "            Q Target: 1.5475316047668457\n",
            "            Q change: 1.0514317750930786\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.10367204  0.99904823 -0.02689998 -1.3685409 ]]\n",
            "            Next State: [[ 0.123653   1.1944963 -0.0542708 -1.6695145]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5523275  0.50270355]]\n",
            "            Q Target: 1.557948350906372\n",
            "            Q change: 1.05524480342865\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.123653   1.1944963 -0.0542708 -1.6695145]]\n",
            "            Next State: [[ 0.14754292  1.0000455  -0.08766109 -1.3942156 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5604575 0.5100139]]\n",
            "            Q Target: 1.551867961883545\n",
            "            Q change: 0.9914104342460632\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.14754292  1.0000455  -0.08766109 -1.3942156 ]]\n",
            "            Next State: [[ 0.16754384  0.80611706 -0.1155454  -1.1301792 ]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5692214 0.5132436]]\n",
            "            Q Target: 1.5598180294036865\n",
            "            Q change: 0.9905966520309448\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.16754384  0.80611706 -0.1155454  -1.1301792 ]]\n",
            "            Next State: [[ 0.18366618  1.0025467  -0.13814898 -1.4567537 ]]\n",
            "            Total Reward: 12.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5770921 0.5175835]]\n",
            "            Q Target: 1.5821044445037842\n",
            "            Q change: 1.0645209550857544\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.18366618  1.0025467  -0.13814898 -1.4567537 ]]\n",
            "            Next State: [[ 0.20371711  0.80936384 -0.16728406 -1.210227  ]]\n",
            "            Total Reward: 13.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5881678 0.523091 ]]\n",
            "            Q Target: 1.5812938213348389\n",
            "            Q change: 0.9931260347366333\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.20371711  0.80936384 -0.16728406 -1.210227  ]]\n",
            "            Next State: [[ 0.2199044  1.0062032 -0.1914886 -1.5503168]]\n",
            "            Total Reward: 14.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5984862  0.52714187]]\n",
            "            Q Target: 1.6021382808685303\n",
            "            Q change: 1.0749964714050293\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.2199044  1.0062032 -0.1914886 -1.5503168]]\n",
            "            Next State: [[ 0.24002846  0.81382436 -0.22249493 -1.3229773 ]]\n",
            "            Total Reward: 15.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[0.6083823 0.5333776]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.39161771535873413\n",
            "            \n",
            "Episode 9/30 | Ep. Total Reward: 16.0 | Epsilon : 0.900 | Eval Rwd Mean: 9.00 | Eval Rwd Var: 0.00\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.02189491 -0.02367986 -0.03779038  0.03933532]]\n",
            "            Next State: [[-0.02236851 -0.2182401  -0.03700367  0.3198596 ]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.3617181 -1.0034602]]\n",
            "            Q Target: 0.8680807948112488\n",
            "            Q change: 0.5063626766204834\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.02236851 -0.2182401  -0.03700367  0.3198596 ]]\n",
            "            Next State: [[-0.02673331 -0.41281605 -0.03060648  0.6006471 ]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.13255045 -1.906344  ]]\n",
            "            Q Target: 0.7600809931755066\n",
            "            Q change: 0.8926314115524292\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.02673331 -0.41281605 -0.03060648  0.6006471 ]]\n",
            "            Next State: [[-0.03498963 -0.60749674 -0.01859354  0.88353455]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.2339049 -1.904686 ]]\n",
            "            Q Target: 0.751630961894989\n",
            "            Q change: 0.9855358600616455\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03498963 -0.60749674 -0.01859354  0.88353455]]\n",
            "            Next State: [[-4.7139566e-02 -8.0236137e-01 -9.2284830e-04  1.1703147e+00]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.24146926 -1.9093591 ]]\n",
            "            Q Target: 0.7509347796440125\n",
            "            Q change: 0.992404043674469\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-4.7139566e-02 -8.0236137e-01 -9.2284830e-04  1.1703147e+00]]\n",
            "            Next State: [[-0.06318679 -0.9974713   0.02248345  1.4627081 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.243283  -1.9087069]]\n",
            "            Q Target: 0.7599704265594482\n",
            "            Q change: 1.00325345993042\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.06318679 -0.9974713   0.02248345  1.4627081 ]]\n",
            "            Next State: [[-0.08313622 -1.1928614   0.05173761  1.7623289 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.23404796 -1.9031159 ]]\n",
            "            Q Target: 0.7749220132827759\n",
            "            Q change: 1.008970022201538\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.08313622 -1.1928614   0.05173761  1.7623289 ]]\n",
            "            Next State: [[-0.10699345 -0.9983615   0.08698419  1.4861734 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.21894383 -1.8943335 ]]\n",
            "            Q Target: 0.8492221832275391\n",
            "            Q change: 2.7435555458068848\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.10699345 -0.9983615   0.08698419  1.4861734 ]]\n",
            "            Next State: [[-0.12696068 -0.8044007   0.11670765  1.2218733 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.15528587 -1.8296039 ]]\n",
            "            Q Target: 0.9359441995620728\n",
            "            Q change: 2.7655482292175293\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.12696068 -0.8044007   0.11670765  1.2218733 ]]\n",
            "            Next State: [[-0.14304869 -0.61095965  0.14114513  0.96791977]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.06814118 -1.7434423 ]]\n",
            "            Q Target: 1.028085708618164\n",
            "            Q change: 2.7715280055999756\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.14304869 -0.61095965  0.14114513  0.96791977]]\n",
            "            Next State: [[-0.15526788 -0.41798598  0.16050352  0.72269684]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.02536354 -1.6226692 ]]\n",
            "            Q Target: 1.149405598640442\n",
            "            Q change: 2.7720746994018555\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.15526788 -0.41798598  0.16050352  0.72269684]]\n",
            "            Next State: [[-0.16362761 -0.614921    0.17495745  1.0612882 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.15360719 -1.4274697 ]]\n",
            "            Q Target: 1.080390214920044\n",
            "            Q change: 0.92678302526474\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.16362761 -0.614921    0.17495745  1.0612882 ]]\n",
            "            Next State: [[-0.17592603 -0.42249262  0.19618322  0.8282276 ]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.09090534 -1.5066627 ]]\n",
            "            Q Target: 1.3204084634780884\n",
            "            Q change: 2.827071189880371\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.17592603 -0.42249262  0.19618322  0.8282276 ]]\n",
            "            Next State: [[-0.18437588 -0.23051588  0.21274777  0.6030949 ]]\n",
            "            Total Reward: 12.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.32314593 -1.3258256 ]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 2.3258256912231445\n",
            "            \n",
            "Episode 10/30 | Ep. Total Reward: 13.0 | Epsilon : 0.900 | Eval Rwd Mean: 10.00 | Eval Rwd Var: 0.00\n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.04692357 -0.01313256 -0.01692016  0.04102673]]\n",
            "            Next State: [[ 0.04666092  0.18222788 -0.01609963 -0.2569463 ]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.15038094 -0.49881995]]\n",
            "            Q Target: 1.5264456272125244\n",
            "            Q change: 2.025265693664551\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.04666092  0.18222788 -0.01609963 -0.2569463 ]]\n",
            "            Next State: [[ 0.05030547 -0.01266055 -0.02123855  0.03061541]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.47818822 0.53514016]]\n",
            "            Q Target: 1.1998753547668457\n",
            "            Q change: 0.7216871380805969\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.05030547 -0.01266055 -0.02123855  0.03061541]]\n",
            "            Next State: [[ 0.05005226 -0.2074716  -0.02062624  0.3165224 ]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.225513   -0.31488085]]\n",
            "            Q Target: 0.7947415113449097\n",
            "            Q change: 0.5692285299301147\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.05005226 -0.2074716  -0.02062624  0.3165224 ]]\n",
            "            Next State: [[ 0.04590283 -0.40229377 -0.0142958   0.60262984]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.20666558 -1.638388  ]]\n",
            "            Q Target: 0.7302600145339966\n",
            "            Q change: 0.9369255900382996\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.04590283 -0.40229377 -0.0142958   0.60262984]]\n",
            "            Next State: [[ 0.03785696 -0.59721285 -0.0022432   0.8907758 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.2625159 -1.6982079]]\n",
            "            Q Target: 0.7245818376541138\n",
            "            Q change: 0.9870977401733398\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.03785696 -0.59721285 -0.0022432   0.8907758 ]]\n",
            "            Next State: [[ 0.0259127  -0.79230434  0.01557232  1.1827527 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.26985133 -1.7133656 ]]\n",
            "            Q Target: 0.7332408428192139\n",
            "            Q change: 1.0030921697616577\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.0259127  -0.79230434  0.01557232  1.1827527 ]]\n",
            "            Next State: [[ 0.01006661 -0.9876248   0.03922737  1.4802761 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.25753096 -1.7140326 ]]\n",
            "            Q Target: 0.7524107694625854\n",
            "            Q change: 1.0099416971206665\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01006661 -0.9876248   0.03922737  1.4802761 ]]\n",
            "            Next State: [[-0.00968588 -1.183203    0.06883289  1.7849474 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.2378079 -1.7083757]]\n",
            "            Q Target: 0.7755509614944458\n",
            "            Q change: 1.0133588314056396\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.00968588 -1.183203    0.06883289  1.7849474 ]]\n",
            "            Next State: [[-0.03334994 -1.3790274   0.10453184  2.0982094 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.21418296 -1.6989211 ]]\n",
            "            Q Target: 0.8011347651481628\n",
            "            Q change: 1.015317678451538\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.03334994 -1.3790274   0.10453184  2.0982094 ]]\n",
            "            Next State: [[-0.06093049 -1.1851      0.14649603  1.8395826 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.18817802 -1.6867546 ]]\n",
            "            Q Target: 0.8757633566856384\n",
            "            Q change: 2.5625178813934326\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.06093049 -1.1851      0.14649603  1.8395826 ]]\n",
            "            Next State: [[-0.08463249 -0.99186844  0.18328768  1.5957558 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.12418116 -1.6163036 ]]\n",
            "            Q Target: 0.9764704704284668\n",
            "            Q change: 2.592773914337158\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.08463249 -0.99186844  0.18328768  1.5957558 ]]\n",
            "            Next State: [[-0.10446986 -1.1886295   0.2152028   1.939539  ]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[-0.04561898 -1.5199535 ]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 1.045619010925293\n",
            "            \n",
            "Episode 11/30 | Ep. Total Reward: 12.0 | Epsilon : 0.798 | Eval Rwd Mean: 9.00 | Eval Rwd Var: 0.67\n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[0.03075667 0.02859914 0.01256936 0.00658883]]\n",
            "            Next State: [[ 0.03132865  0.22353859  0.01270113 -0.28210196]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.21824889 0.12464839]]\n",
            "            Q Target: 1.5152432918548584\n",
            "            Q change: 1.3905949592590332\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.03132865  0.22353859  0.01270113 -0.28210196]]\n",
            "            Next State: [[ 0.03579943  0.4184771   0.00705909 -0.5707521 ]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.4583721 0.5275819]]\n",
            "            Q Target: 1.5367774963378906\n",
            "            Q change: 1.0091955661773682\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.03579943  0.4184771   0.00705909 -0.5707521 ]]\n",
            "            Next State: [[ 0.04416897  0.61349934 -0.00435595 -0.86120284]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.53991544 0.5525897 ]]\n",
            "            Q Target: 1.5770349502563477\n",
            "            Q change: 1.0244452953338623\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.04416897  0.61349934 -0.00435595 -0.86120284]]\n",
            "            Next State: [[ 0.05643895  0.41843697 -0.02158001 -0.5698927 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.58365595 0.5621622 ]]\n",
            "            Q Target: 1.5617334842681885\n",
            "            Q change: 0.9780775308609009\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.05643895  0.41843697 -0.02158001 -0.5698927 ]]\n",
            "            Next State: [[ 0.06480769  0.22362423 -0.03297786 -0.28408563]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5712138  0.57022685]]\n",
            "            Q Target: 1.5551409721374512\n",
            "            Q change: 0.9839271903038025\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.06480769  0.22362423 -0.03297786 -0.28408563]]\n",
            "            Next State: [[ 0.06928018  0.41920063 -0.03865957 -0.58698446]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5394713 0.5617502]]\n",
            "            Q Target: 1.5871057510375977\n",
            "            Q change: 1.025355577468872\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.06928018  0.41920063 -0.03865957 -0.58698446]]\n",
            "            Next State: [[ 0.07766419  0.22464085 -0.05039926 -0.30672592]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5912607  0.58301336]]\n",
            "            Q Target: 1.5730388164520264\n",
            "            Q change: 0.9817781448364258\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.07766419  0.22464085 -0.05039926 -0.30672592]]\n",
            "            Next State: [[ 0.08215701  0.4204434  -0.05653378 -0.6148679 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.576254   0.59019995]]\n",
            "            Q Target: 1.6032224893569946\n",
            "            Q change: 1.013022541999817\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.08215701  0.4204434  -0.05653378 -0.6148679 ]]\n",
            "            Next State: [[ 0.09056588  0.6163078  -0.06883114 -0.9248072 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.60951716 0.5941252 ]]\n",
            "            Q Target: 1.6247470378875732\n",
            "            Q change: 1.0306217670440674\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.09056588  0.6163078  -0.06883114 -0.9248072 ]]\n",
            "            Next State: [[ 0.10289203  0.42217967 -0.08732728 -0.6545249 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.63147384 0.5927425 ]]\n",
            "            Q Target: 1.6139745712280273\n",
            "            Q change: 0.9825007319450378\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.10289203  0.42217967 -0.08732728 -0.6545249 ]]\n",
            "            Next State: [[ 0.11133563  0.618402   -0.10041778 -0.9733784 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.62971765 0.60516715]]\n",
            "            Q Target: 1.6423938274383545\n",
            "            Q change: 1.037226676940918\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.11133563  0.618402   -0.10041778 -0.9733784 ]]\n",
            "            Next State: [[ 0.12370367  0.42476025 -0.11988535 -0.7138523 ]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.6489693  0.60513556]]\n",
            "            Q Target: 1.635707139968872\n",
            "            Q change: 0.986737847328186\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.12370367  0.42476025 -0.11988535 -0.7138523 ]]\n",
            "            Next State: [[ 0.13219887  0.62131995 -0.1341624  -1.0417374 ]]\n",
            "            Total Reward: 12.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.65261513 0.6155794 ]]\n",
            "            Q Target: 1.6621651649475098\n",
            "            Q change: 1.0465857982635498\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.13219887  0.62131995 -0.1341624  -1.0417374 ]]\n",
            "            Next State: [[ 0.14462526  0.42821023 -0.15499714 -0.79400146]]\n",
            "            Total Reward: 13.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.6687581  0.61700124]]\n",
            "            Q Target: 1.659744143486023\n",
            "            Q change: 0.9909860491752625\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.14462526  0.42821023 -0.15499714 -0.79400146]]\n",
            "            Next State: [[ 0.15318947  0.62508136 -0.17087717 -1.131155  ]]\n",
            "            Total Reward: 14.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.67742765 0.62570226]]\n",
            "            Q Target: 1.6835752725601196\n",
            "            Q change: 1.057873010635376\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.15318947  0.62508136 -0.17087717 -1.131155  ]]\n",
            "            Next State: [[ 0.16569111  0.4325577  -0.19350027 -0.8965691 ]]\n",
            "            Total Reward: 15.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.69044465 0.62849987]]\n",
            "            Q Target: 1.6824476718902588\n",
            "            Q change: 0.9920030236244202\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.16569111  0.4325577  -0.19350027 -0.8965691 ]]\n",
            "            Next State: [[ 0.17434226  0.2405109  -0.21143165 -0.6704098 ]]\n",
            "            Total Reward: 16.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[0.70086753 0.6384258 ]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.29913246631622314\n",
            "            \n",
            "Episode 12/30 | Ep. Total Reward: 17.0 | Epsilon : 0.672 | Eval Rwd Mean: 10.00 | Eval Rwd Var: 0.00\n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.04518295  0.04202841  0.00736975 -0.02934241]]\n",
            "            Next State: [[-0.04434238  0.2370439   0.0067829  -0.31969103]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.43006712 0.00351867]]\n",
            "            Q Target: 1.6132862567901611\n",
            "            Q change: 1.6097675561904907\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.04434238  0.2370439   0.0067829  -0.31969103]]\n",
            "            Next State: [[-3.9601505e-02  4.3206859e-01  3.8907878e-04 -6.1022717e-01]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5724064 0.6308371]]\n",
            "            Q Target: 1.641722321510315\n",
            "            Q change: 1.010885238647461\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-3.9601505e-02  4.3206859e-01  3.8907878e-04 -6.1022717e-01]]\n",
            "            Next State: [[-0.03096013  0.6271851  -0.01181547 -0.90278757]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.6225987 0.658112 ]]\n",
            "            Q Target: 1.6593034267425537\n",
            "            Q change: 1.0011913776397705\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03096013  0.6271851  -0.01181547 -0.90278757]]\n",
            "            Next State: [[-0.01841643  0.4322252  -0.02987122 -0.6138417 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.66415375 0.66038746]]\n",
            "            Q Target: 1.664269208908081\n",
            "            Q change: 1.0001153945922852\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01841643  0.4322252  -0.02987122 -0.6138417 ]]\n",
            "            Next State: [[-0.00977193  0.2375331  -0.04214805 -0.33071473]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.65691155 0.67126215]]\n",
            "            Q Target: 1.6583034992218018\n",
            "            Q change: 1.001391887664795\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.00977193  0.2375331  -0.04214805 -0.33071473]]\n",
            "            Next State: [[-0.00502126  0.43322888 -0.04876234 -0.63638556]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.64599836 0.6707768 ]]\n",
            "            Q Target: 1.6685773134231567\n",
            "            Q change: 0.9978005290031433\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.00502126  0.43322888 -0.04876234 -0.63638556]]\n",
            "            Next State: [[ 0.00364331  0.6289958  -0.06149006 -0.9440173 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.6770942  0.67898095]]\n",
            "            Q Target: 1.6900649070739746\n",
            "            Q change: 1.011083960533142\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.00364331  0.6289958  -0.06149006 -0.9440173 ]]\n",
            "            Next State: [[ 0.01622323  0.4347537  -0.0803704  -0.6712715 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.69681644 0.6797091 ]]\n",
            "            Q Target: 1.6821033954620361\n",
            "            Q change: 0.9852869510650635\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01622323  0.4347537  -0.0803704  -0.6712715 ]]\n",
            "            Next State: [[ 0.0249183   0.24083558 -0.09379583 -0.40493673]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.69765955 0.6894385 ]]\n",
            "            Q Target: 1.693765640258789\n",
            "            Q change: 0.9961060881614685\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.0249183   0.24083558 -0.09379583 -0.40493673]]\n",
            "            Next State: [[ 0.02973501  0.43715385 -0.10189456 -0.72565526]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.6931315  0.70102346]]\n",
            "            Q Target: 1.7130351066589355\n",
            "            Q change: 1.0120116472244263\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.02973501  0.43715385 -0.10189456 -0.72565526]]\n",
            "            Next State: [[ 0.03847809  0.6335261  -0.11640767 -1.048591  ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.72235256 0.69608206]]\n",
            "            Q Target: 1.7301571369171143\n",
            "            Q change: 1.0340750217437744\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.03847809  0.6335261  -0.11640767 -1.048591  ]]\n",
            "            Next State: [[ 0.05114861  0.82998395 -0.1373795  -1.3754301 ]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.7374044 0.6987736]]\n",
            "            Q Target: 1.739157795906067\n",
            "            Q change: 1.0403841733932495\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.05114861  0.82998395 -0.1373795  -1.3754301 ]]\n",
            "            Next State: [[ 0.06774829  0.63681984 -0.1648881  -1.1286765 ]]\n",
            "            Total Reward: 12.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.74720937 0.705488  ]]\n",
            "            Q Target: 1.7409563064575195\n",
            "            Q change: 0.9937469363212585\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.06774829  0.63681984 -0.1648881  -1.1286765 ]]\n",
            "            Next State: [[ 0.08048469  0.44419575 -0.18746163 -0.891917  ]]\n",
            "            Total Reward: 13.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.75887346 0.710096  ]]\n",
            "            Q Target: 1.7537128925323486\n",
            "            Q change: 0.9948394298553467\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.08048469  0.44419575 -0.18746163 -0.891917  ]]\n",
            "            Next State: [[ 0.0893686   0.2520434  -0.20529996 -0.6635296 ]]\n",
            "            Total Reward: 14.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.77277106 0.7161251 ]]\n",
            "            Q Target: 1.7688252925872803\n",
            "            Q change: 0.9960542321205139\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.0893686   0.2520434  -0.20529996 -0.6635296 ]]\n",
            "            Next State: [[ 0.09440947  0.4493401  -0.21857056 -1.0131948 ]]\n",
            "            Total Reward: 15.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[0.7883232 0.7199971]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.2800028920173645\n",
            "            \n",
            "Episode 13/30 | Ep. Total Reward: 16.0 | Epsilon : 0.573 | Eval Rwd Mean: 9.67 | Eval Rwd Var: 0.22\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01665471  0.01535421  0.00033056  0.03552393]]\n",
            "            Next State: [[-0.01634763 -0.17977248  0.00104104  0.32831115]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.44572204 -0.24791875]]\n",
            "            Q Target: 1.2569878101348877\n",
            "            Q change: 0.811265766620636\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.01634763 -0.17977248  0.00104104  0.32831115]]\n",
            "            Next State: [[-0.01994308  0.01533463  0.00760726  0.03595669]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.26524493 -1.4278376 ]]\n",
            "            Q Target: 1.4204427003860474\n",
            "            Q change: 2.848280429840088\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01994308  0.01533463  0.00760726  0.03595669]]\n",
            "            Next State: [[-0.01963639 -0.17989558  0.0083264   0.33103004]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.429393   -0.27412057]]\n",
            "            Q Target: 1.2903940677642822\n",
            "            Q change: 0.8610010743141174\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01963639 -0.17989558  0.0083264   0.33103004]]\n",
            "            Next State: [[-0.0232343  -0.37513506  0.014947    0.62632704]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.22970404 -1.3338292 ]]\n",
            "            Q Target: 0.9405747652053833\n",
            "            Q change: 0.7108707427978516\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0232343  -0.37513506  0.014947    0.62632704]]\n",
            "            Next State: [[-0.030737   -0.5704624   0.02747354  0.92367965]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.05711906 -1.4598868 ]]\n",
            "            Q Target: 0.9108675122261047\n",
            "            Q change: 0.9679865837097168\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.030737   -0.5704624   0.02747354  0.92367965]]\n",
            "            Next State: [[-0.04214625 -0.37572217  0.04594713  0.63975567]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.07963318 -1.505964  ]]\n",
            "            Q Target: 1.0089837312698364\n",
            "            Q change: 2.5149478912353516\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.04214625 -0.37572217  0.04594713  0.63975567]]\n",
            "            Next State: [[-0.04966069 -0.5714536   0.05874225  0.9465467 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.01850284 -1.3833131 ]]\n",
            "            Q Target: 0.9775448441505432\n",
            "            Q change: 0.9590420126914978\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.04966069 -0.5714536   0.05874225  0.9465467 ]]\n",
            "            Next State: [[-0.06108976 -0.7673153   0.07767318  1.2570928 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.00379987 -1.4389786 ]]\n",
            "            Q Target: 0.9647374153137207\n",
            "            Q change: 0.9685372710227966\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.06108976 -0.7673153   0.07767318  1.2570928 ]]\n",
            "            Next State: [[-0.07643607 -0.5732687   0.10281504  0.98971343]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[-0.02568137 -1.4618813 ]]\n",
            "            Q Target: 1.060205340385437\n",
            "            Q change: 2.5220866203308105\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.07643607 -0.5732687   0.10281504  0.98971343]]\n",
            "            Next State: [[-0.08790144 -0.7696054   0.1226093   1.3128376 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.06927446 -1.3471508 ]]\n",
            "            Q Target: 1.0342206954956055\n",
            "            Q change: 0.9649462103843689\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.08790144 -0.7696054   0.1226093   1.3128376 ]]\n",
            "            Next State: [[-0.10329355 -0.9660475   0.14886606  1.6412456 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.05830693 -1.3771685 ]]\n",
            "            Q Target: 1.040938377380371\n",
            "            Q change: 0.9826314449310303\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.10329355 -0.9660475   0.14886606  1.6412456 ]]\n",
            "            Next State: [[-0.1226145  -1.1625669   0.18169098  1.9763696 ]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.05161063 -1.3898208 ]]\n",
            "            Q Target: 1.0397452116012573\n",
            "            Q change: 0.9881345629692078\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.1226145  -1.1625669   0.18169098  1.9763696 ]]\n",
            "            Next State: [[-0.14586584 -1.3590796   0.22121836  2.3194103 ]]\n",
            "            Total Reward: 12.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.05037319 -1.3936647 ]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.9496268033981323\n",
            "            \n",
            "Episode 14/30 | Ep. Total Reward: 13.0 | Epsilon : 0.502 | Eval Rwd Mean: 9.33 | Eval Rwd Var: 0.22\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03962845 -0.04120569  0.02181065 -0.02808898]]\n",
            "            Next State: [[-0.04045257 -0.23663351  0.02124887  0.27139488]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.49729487 -0.79593635]]\n",
            "            Q Target: 1.05234956741333\n",
            "            Q change: 0.5550546646118164\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.04045257 -0.23663351  0.02124887  0.27139488]]\n",
            "            Next State: [[-0.04518524 -0.04182112  0.02667677 -0.01451106]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.09025186 -1.5590466 ]]\n",
            "            Q Target: 1.519561767578125\n",
            "            Q change: 3.078608512878418\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.04518524 -0.04182112  0.02667677 -0.01451106]]\n",
            "            Next State: [[-0.04602166  0.1529083   0.02638654 -0.2986592 ]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.48112193 -0.93946785]]\n",
            "            Q Target: 1.6517565250396729\n",
            "            Q change: 2.591224431991577\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.04602166  0.1529083   0.02638654 -0.2986592 ]]\n",
            "            Next State: [[-0.04296349 -0.04257965  0.02041336  0.00222737]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.65721166 0.47839376]]\n",
            "            Q Target: 1.5301216840744019\n",
            "            Q change: 0.8729100227355957\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.04296349 -0.04257965  0.02041336  0.00222737]]\n",
            "            Next State: [[-0.04381509 -0.23798832  0.02045791  0.3012804 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.50640965 -0.9567871 ]]\n",
            "            Q Target: 1.1146459579467773\n",
            "            Q change: 0.6082363128662109\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.04381509 -0.23798832  0.02045791  0.3012804 ]]\n",
            "            Next State: [[-0.04857485 -0.4333958   0.02648352  0.6003445 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.11885463 -1.4580687 ]]\n",
            "            Q Target: 1.0481057167053223\n",
            "            Q change: 0.9292510747909546\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.04857485 -0.4333958   0.02648352  0.6003445 ]]\n",
            "            Next State: [[-0.05724277 -0.62887806  0.03849041  0.9012503 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.05771693 -1.4770905 ]]\n",
            "            Q Target: 1.0419703722000122\n",
            "            Q change: 0.984253466129303\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.05724277 -0.62887806  0.03849041  0.9012503 ]]\n",
            "            Next State: [[-0.06982033 -0.8244998   0.05651541  1.205779  ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.0499827 -1.4775391]]\n",
            "            Q Target: 1.050958514213562\n",
            "            Q change: 1.0009758472442627\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.06982033 -0.8244998   0.05651541  1.205779  ]]\n",
            "            Next State: [[-0.08631033 -1.0203047   0.08063099  1.515624  ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.06002511 -1.4737833 ]]\n",
            "            Q Target: 1.0647492408752441\n",
            "            Q change: 1.004724144935608\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.08631033 -1.0203047   0.08063099  1.515624  ]]\n",
            "            Next State: [[-0.10671642 -0.82624567  0.11094347  1.2491611 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.07401756 -1.4659814 ]]\n",
            "            Q Target: 1.115111231803894\n",
            "            Q change: 2.581092596054077\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.10671642 -0.82624567  0.11094347  1.2491611 ]]\n",
            "            Next State: [[-0.12324134 -1.022601    0.1359267   1.5744339 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.11700419 -1.3976527 ]]\n",
            "            Q Target: 1.1147934198379517\n",
            "            Q change: 0.997789204120636\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.12324134 -1.022601    0.1359267   1.5744339 ]]\n",
            "            Next State: [[-0.14369336 -1.2190568   0.16741537  1.9062389 ]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.12434305 -1.3938106 ]]\n",
            "            Q Target: 1.1262612342834473\n",
            "            Q change: 1.0019181966781616\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.14369336 -1.2190568   0.16741537  1.9062389 ]]\n",
            "            Next State: [[-0.16807449 -1.4155451   0.20554015  2.2458413 ]]\n",
            "            Total Reward: 12.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.13581045 -1.3863385 ]]\n",
            "            Q Target: 1.1386038064956665\n",
            "            Q change: 1.002793312072754\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.16807449 -1.4155451   0.20554015  2.2458413 ]]\n",
            "            Next State: [[-0.1963854 -1.6119297  0.250457   2.5942216]]\n",
            "            Total Reward: 13.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.14716253 -1.3766695 ]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.8528374433517456\n",
            "            \n",
            "Episode 15/30 | Ep. Total Reward: 14.0 | Epsilon : 0.436 | Eval Rwd Mean: 9.00 | Eval Rwd Var: 0.67\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.00129617 -0.0142974   0.01313154 -0.0317891 ]]\n",
            "            Next State: [[-0.00158211 -0.20960519  0.01249576  0.26500788]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.44831187 -0.24426462]]\n",
            "            Q Target: 1.1659936904907227\n",
            "            Q change: 0.7176818251609802\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.00158211 -0.20960519  0.01249576  0.26500788]]\n",
            "            Next State: [[-0.00577422 -0.40490323  0.01779592  0.56160575]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.17194702 -1.4216591 ]]\n",
            "            Q Target: 1.102569580078125\n",
            "            Q change: 0.9306225776672363\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.00577422 -0.40490323  0.01779592  0.56160575]]\n",
            "            Next State: [[-0.01387228 -0.21003549  0.02902803  0.27458212]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.11296653 -1.4583329 ]]\n",
            "            Q Target: 1.2326924800872803\n",
            "            Q change: 2.6910252571105957\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01387228 -0.21003549  0.02902803  0.27458212]]\n",
            "            Next State: [[-0.01807299 -0.40555933  0.03451967  0.5762774 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.2333825 -1.34352  ]]\n",
            "            Q Target: 1.140290379524231\n",
            "            Q change: 0.9069079160690308\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.01807299 -0.40555933  0.03451967  0.5762774 ]]\n",
            "            Next State: [[-0.02618418 -0.21093783  0.04604522  0.2946658 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.15067719 -1.3973508 ]]\n",
            "            Q Target: 1.299476146697998\n",
            "            Q change: 2.696826934814453\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.02618418 -0.21093783  0.04604522  0.2946658 ]]\n",
            "            Next State: [[-0.03040294 -0.40668496  0.05193854  0.6015078 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.30428243 -1.2451528 ]]\n",
            "            Q Target: 1.1800843477249146\n",
            "            Q change: 0.8758019208908081\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03040294 -0.40668496  0.05193854  0.6015078 ]]\n",
            "            Next State: [[-0.03853663 -0.6024935   0.0639687   0.9100876 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.18313359 -1.3208449 ]]\n",
            "            Q Target: 1.1585383415222168\n",
            "            Q change: 0.9754047393798828\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03853663 -0.6024935   0.0639687   0.9100876 ]]\n",
            "            Next State: [[-0.0505865  -0.79842013  0.08217044  1.2221705 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.17008328 -1.346986  ]]\n",
            "            Q Target: 1.1617001295089722\n",
            "            Q change: 0.9916168451309204\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0505865  -0.79842013  0.08217044  1.2221705 ]]\n",
            "            Next State: [[-0.0665549  -0.99449897  0.10661385  1.5394272 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.17221367 -1.354449  ]]\n",
            "            Q Target: 1.1707744598388672\n",
            "            Q change: 0.9985607862472534\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0665549  -0.99449897  0.10661385  1.5394272 ]]\n",
            "            Next State: [[-0.08644488 -1.1907297   0.1374024   1.8633872 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.18127556 -1.3536732 ]]\n",
            "            Q Target: 1.1835222244262695\n",
            "            Q change: 1.002246618270874\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.08644488 -1.1907297   0.1374024   1.8633872 ]]\n",
            "            Next State: [[-0.11025948 -1.387064    0.17467014  2.1953824 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.19428842 -1.34823   ]]\n",
            "            Q Target: 1.1987407207489014\n",
            "            Q change: 1.0044523477554321\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.11025948 -1.387064    0.17467014  2.1953824 ]]\n",
            "            Next State: [[-0.13800076 -1.5833894   0.21857779  2.5364816 ]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.20995264 -1.3396593 ]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.7900473475456238\n",
            "            \n",
            "Episode 16/30 | Ep. Total Reward: 12.0 | Epsilon : 0.387 | Eval Rwd Mean: 8.67 | Eval Rwd Var: 0.22\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.00771909 -0.01578354 -0.03349616 -0.0200682 ]]\n",
            "            Next State: [[ 0.00740342 -0.2104095  -0.03389753  0.26186097]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5119328  -0.19742596]]\n",
            "            Q Target: 1.1156278848648071\n",
            "            Q change: 0.6036950945854187\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.00740342 -0.2104095  -0.03389753  0.26186097]]\n",
            "            Next State: [[ 0.00319523 -0.4050316  -0.0286603   0.5436624 ]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.12643343 -1.4920386 ]]\n",
            "            Q Target: 1.113974928855896\n",
            "            Q change: 0.9875414967536926\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.00319523 -0.4050316  -0.0286603   0.5436624 ]]\n",
            "            Next State: [[-0.0049054  -0.5997393  -0.01778706  0.8271791 ]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.12025539 -1.4848987 ]]\n",
            "            Q Target: 1.1236968040466309\n",
            "            Q change: 1.0034414529800415\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0049054  -0.5997393  -0.01778706  0.8271791 ]]\n",
            "            Next State: [[-0.01690019 -0.7946136  -0.00124348  1.1142151 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.13377848 -1.4755639 ]]\n",
            "            Q Target: 1.1446512937545776\n",
            "            Q change: 1.0108728408813477\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01690019 -0.7946136  -0.00124348  1.1142151 ]]\n",
            "            Next State: [[-0.03279246 -0.9897192   0.02104083  1.4065077 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.15496275 -1.467429  ]]\n",
            "            Q Target: 1.1651983261108398\n",
            "            Q change: 1.0102355480194092\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.03279246 -0.9897192   0.02104083  1.4065077 ]]\n",
            "            Next State: [[-0.05258684 -0.7948646   0.04917098  1.1204761 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.17575179 -1.4573647 ]]\n",
            "            Q Target: 1.201671838760376\n",
            "            Q change: 2.659036636352539\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.05258684 -0.7948646   0.04917098  1.1204761 ]]\n",
            "            Next State: [[-0.06848413 -0.9905958   0.07158051  1.4281685 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.20275173 -1.410926  ]]\n",
            "            Q Target: 1.2073200941085815\n",
            "            Q change: 1.004568338394165\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.06848413 -0.9905958   0.07158051  1.4281685 ]]\n",
            "            Next State: [[-0.08829605 -0.79642725  0.10014387  1.1586882 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.21806249 -1.4001447 ]]\n",
            "            Q Target: 1.254789113998413\n",
            "            Q change: 2.6549339294433594\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.08829605 -0.79642725  0.10014387  1.1586882 ]]\n",
            "            Next State: [[-0.10422459 -0.6027427   0.12331764  0.89901   ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.2564704 -1.3355985]]\n",
            "            Q Target: 1.3123832941055298\n",
            "            Q change: 2.647981643676758\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.10422459 -0.6027427   0.12331764  0.89901   ]]\n",
            "            Next State: [[-0.11627945 -0.7993007   0.14129783  1.2277716 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.31442478 -1.2411356 ]]\n",
            "            Q Target: 1.2940794229507446\n",
            "            Q change: 0.9796546697616577\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.11627945 -0.7993007   0.14129783  1.2277716 ]]\n",
            "            Next State: [[-0.13226546 -0.9959297   0.16585328  1.5611793 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.307069  -1.2499236]]\n",
            "            Q Target: 1.297884225845337\n",
            "            Q change: 0.9908152222633362\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.13226546 -0.9959297   0.16585328  1.5611793 ]]\n",
            "            Next State: [[-0.15218405 -0.8031349   0.19707686  1.324493  ]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.31099877 -1.250028  ]]\n",
            "            Q Target: 1.364640712738037\n",
            "            Q change: 2.614668846130371\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.15218405 -0.8031349   0.19707686  1.324493  ]]\n",
            "            Next State: [[-0.16824676 -1.0001229   0.22356671  1.6718216 ]]\n",
            "            Total Reward: 12.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.36788845 -1.1448977 ]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.6321115493774414\n",
            "            \n",
            "Episode 17/30 | Ep. Total Reward: 13.0 | Epsilon : 0.340 | Eval Rwd Mean: 9.00 | Eval Rwd Var: 0.00\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[0.00720408 0.02419101 0.03173449 0.04886978]]\n",
            "            Next State: [[ 0.0076879  -0.17137127  0.03271189  0.35139388]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.25376275 -0.2907212 ]]\n",
            "            Q Target: 1.624381184577942\n",
            "            Q change: 1.370618462562561\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.0076879  -0.17137127  0.03271189  0.35139388]]\n",
            "            Next State: [[ 0.00426048 -0.3669428   0.03973977  0.6542098 ]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.64249456 -0.91526234]]\n",
            "            Q Target: 1.344131588935852\n",
            "            Q change: 0.7016370296478271\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.00426048 -0.3669428   0.03973977  0.6542098 ]]\n",
            "            Next State: [[-0.00307838 -0.5625949   0.05282396  0.9591366 ]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.35041034 -1.1116033 ]]\n",
            "            Q Target: 1.3158353567123413\n",
            "            Q change: 0.9654250144958496\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.00307838 -0.5625949   0.05282396  0.9591366 ]]\n",
            "            Next State: [[-0.01433027 -0.75838566  0.07200669  1.2679362 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.33046475 -1.1763345 ]]\n",
            "            Q Target: 1.3163522481918335\n",
            "            Q change: 0.9858875274658203\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01433027 -0.75838566  0.07200669  1.2679362 ]]\n",
            "            Next State: [[-0.02949799 -0.9543497   0.09736542  1.5822722 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.33081958 -1.2028489 ]]\n",
            "            Q Target: 1.3253369331359863\n",
            "            Q change: 0.9945173263549805\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.02949799 -0.9543497   0.09736542  1.5822722 ]]\n",
            "            Next State: [[-0.04858498 -1.1504861   0.12901086  1.9036636 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.33982977 -1.2132694 ]]\n",
            "            Q Target: 1.3388056755065918\n",
            "            Q change: 0.9989758729934692\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.04858498 -1.1504861   0.12901086  1.9036636 ]]\n",
            "            Next State: [[-0.0715947  -1.3467453   0.16708413  2.23343   ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.3535031 -1.2150067]]\n",
            "            Q Target: 1.3550716638565063\n",
            "            Q change: 1.0015685558319092\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0715947  -1.3467453   0.16708413  2.23343   ]]\n",
            "            Next State: [[-0.09852961 -1.5430125   0.21175273  2.5726254 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.37012196 -1.21128   ]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.629878044128418\n",
            "            \n",
            "Episode 18/30 | Ep. Total Reward: 8.0 | Epsilon : 0.313 | Eval Rwd Mean: 10.00 | Eval Rwd Var: 0.00\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01413488  0.04170343 -0.00752665 -0.01335363]]\n",
            "            Next State: [[ 0.01496894 -0.15330978 -0.00779372  0.27694508]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5929162  0.01942261]]\n",
            "            Q Target: 1.647984266281128\n",
            "            Q change: 1.055068016052246\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01496894 -0.15330978 -0.00779372  0.27694508]]\n",
            "            Next State: [[ 0.01190275 -0.34831968 -0.00225482  0.5671597 ]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.6649978 -1.1254448]]\n",
            "            Q Target: 1.344911813735962\n",
            "            Q change: 0.6799139976501465\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.01190275 -0.34831968 -0.00225482  0.5671597 ]]\n",
            "            Next State: [[ 0.00493636 -0.15316616  0.00908837  0.27376726]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.35179618 -1.2183986 ]]\n",
            "            Q Target: 1.7373151779174805\n",
            "            Q change: 2.9557137489318848\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.00493636 -0.15316616  0.00908837  0.27376726]]\n",
            "            Next State: [[ 0.00187303 -0.3484166   0.01456372  0.5693028 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.74896115 -1.0299958 ]]\n",
            "            Q Target: 1.3778977394104004\n",
            "            Q change: 0.6289365887641907\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.00187303 -0.3484166   0.01456372  0.5693028 ]]\n",
            "            Next State: [[-0.0050953  -0.54373974  0.02594977  0.86653805]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.3847236 -1.1537585]]\n",
            "            Q Target: 1.3600759506225586\n",
            "            Q change: 0.9753523468971252\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0050953  -0.54373974  0.02594977  0.86653805]]\n",
            "            Next State: [[-0.0159701  -0.73920506  0.04328053  1.1672657 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.37502664 -1.2018083 ]]\n",
            "            Q Target: 1.3663084506988525\n",
            "            Q change: 0.9912818074226379\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0159701  -0.73920506  0.04328053  1.1672657 ]]\n",
            "            Next State: [[-0.0307542  -0.9348626   0.06662585  1.4731977 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.38149732 -1.2189194 ]]\n",
            "            Q Target: 1.379262089729309\n",
            "            Q change: 0.9977647662162781\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0307542  -0.9348626   0.06662585  1.4731977 ]]\n",
            "            Next State: [[-0.04945145 -1.1307328   0.0960898   1.7859246 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.3947059 -1.2233824]]\n",
            "            Q Target: 1.3952641487121582\n",
            "            Q change: 1.0005582571029663\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.04945145 -1.1307328   0.0960898   1.7859246 ]]\n",
            "            Next State: [[-0.07206611 -1.3267937   0.1318083   2.1068664 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.41100088 -1.2211679 ]]\n",
            "            Q Target: 1.4132544994354248\n",
            "            Q change: 1.0022536516189575\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.07206611 -1.3267937   0.1318083   2.1068664 ]]\n",
            "            Next State: [[-0.09860198 -1.5229671   0.17394562  2.4372134 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.42942068 -1.2146764 ]]\n",
            "            Q Target: 1.4329993724822998\n",
            "            Q change: 1.0035786628723145\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.09860198 -1.5229671   0.17394562  2.4372134 ]]\n",
            "            Next State: [[-0.12906133 -1.7191008   0.22268988  2.7778568 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.4494738 -1.2051649]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.5505262017250061\n",
            "            \n",
            "Episode 19/30 | Ep. Total Reward: 11.0 | Epsilon : 0.280 | Eval Rwd Mean: 9.00 | Eval Rwd Var: 0.00\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[0.0293408  0.0147374  0.04949792 0.01998838]]\n",
            "            Next State: [[ 0.02963555 -0.18105818  0.04989769  0.3278685 ]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.1078223  -0.05412083]]\n",
            "            Q Target: 1.6849616765975952\n",
            "            Q change: 1.5771393775939941\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.02963555 -0.18105818  0.04989769  0.3278685 ]]\n",
            "            Next State: [[ 0.02601439 -0.37685367  0.05645506  0.63586   ]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.69842446 -0.8886289 ]]\n",
            "            Q Target: 1.5240647792816162\n",
            "            Q change: 0.8256403207778931\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.02601439 -0.37685367  0.05645506  0.63586   ]]\n",
            "            Next State: [[ 0.01847731 -0.18256266  0.06917226  0.36147678]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5327219 -1.0847965]]\n",
            "            Q Target: 1.7771589756011963\n",
            "            Q change: 2.8619556427001953\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.01847731 -0.18256266  0.06917226  0.36147678]]\n",
            "            Next State: [[0.01482606 0.01151139 0.0764018  0.09138231]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.7727869  -0.77217036]]\n",
            "            Q Target: 1.1558126211166382\n",
            "            Q change: 1.927983045578003\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[0.01482606 0.01151139 0.0764018  0.09138231]]\n",
            "            Next State: [[ 0.01505629 -0.18461779  0.07822944  0.40715814]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.15322585 -0.13348007]]\n",
            "            Q Target: 1.7891275882720947\n",
            "            Q change: 1.635901689529419\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01505629 -0.18461779  0.07822944  0.40715814]]\n",
            "            Next State: [[ 0.01136393 -0.3807568   0.08637261  0.72344285]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.8383379 -0.673314 ]]\n",
            "            Q Target: 1.5563699007034302\n",
            "            Q change: 0.7180320024490356\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01136393 -0.3807568   0.08637261  0.72344285]]\n",
            "            Next State: [[ 0.0037488  -0.57696044  0.10084146  1.0420132 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5598607  -0.91526204]]\n",
            "            Q Target: 1.5117974281311035\n",
            "            Q change: 0.9519367218017578\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.0037488  -0.57696044  0.10084146  1.0420132 ]]\n",
            "            Next State: [[-0.00779041 -0.7732666   0.12168173  1.3645737 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5278065 -1.0029312]]\n",
            "            Q Target: 1.5045454502105713\n",
            "            Q change: 0.9767389297485352\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.00779041 -0.7732666   0.12168173  1.3645737 ]]\n",
            "            Next State: [[-0.02325574 -0.57986057  0.1489732   1.112296  ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.52083653 -1.0416045 ]]\n",
            "            Q Target: 1.5817017555236816\n",
            "            Q change: 2.6233062744140625\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.02325574 -0.57986057  0.1489732   1.112296  ]]\n",
            "            Next State: [[-0.03485296 -0.77659124  0.17121913  1.4477599 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5887363  -0.89792323]]\n",
            "            Q Target: 1.556654453277588\n",
            "            Q change: 0.9679181575775146\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03485296 -0.77659124  0.17121913  1.4477599 ]]\n",
            "            Next State: [[-0.05038478 -0.97335464  0.20017432  1.7886821 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.57319915 -0.94657004]]\n",
            "            Q Target: 1.5550086498260498\n",
            "            Q change: 0.9818094968795776\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.05038478 -0.97335464  0.20017432  1.7886821 ]]\n",
            "            Next State: [[-0.06985188 -1.1700816   0.23594795  2.136339  ]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.5717274  -0.97128236]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.4282726049423218\n",
            "            \n",
            "Episode 20/30 | Ep. Total Reward: 12.0 | Epsilon : 0.249 | Eval Rwd Mean: 8.67 | Eval Rwd Var: 0.89\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01303074  0.01095332  0.02417858 -0.00155508]]\n",
            "            Next State: [[-0.01281167 -0.1845069   0.02414748  0.29865736]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.45537966 -0.34590042]]\n",
            "            Q Target: 1.8307018280029297\n",
            "            Q change: 1.3753221035003662\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.01281167 -0.1845069   0.02414748  0.29865736]]\n",
            "            Next State: [[-0.01650181  0.01026268  0.03012062  0.01368684]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.8477326 -0.9773464]]\n",
            "            Q Target: 1.4275144338607788\n",
            "            Q change: 2.4048609733581543\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01650181  0.01026268  0.03012062  0.01368684]]\n",
            "            Next State: [[-0.01629656 -0.185278    0.03039436  0.31571895]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.43061998 -0.40113363]]\n",
            "            Q Target: 1.878544807434082\n",
            "            Q change: 1.4479248523712158\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01629656 -0.185278    0.03039436  0.31571895]]\n",
            "            Next State: [[-0.02000212 -0.3808194   0.03670874  0.61783016]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.84951603 -0.88690525]]\n",
            "            Q Target: 1.5138416290283203\n",
            "            Q change: 0.6643255949020386\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.02000212 -0.3808194   0.03670874  0.61783016]]\n",
            "            Next State: [[-0.02761851 -0.18622896  0.04906534  0.33693105]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.521882  -1.0127958]]\n",
            "            Q Target: 1.9161161184310913\n",
            "            Q change: 2.9289119243621826\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.02761851 -0.18622896  0.04906534  0.33693105]]\n",
            "            Next State: [[-0.03134308 -0.38201356  0.05580396  0.64467394]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.9223466 -0.7756784]]\n",
            "            Q Target: 1.5504889488220215\n",
            "            Q change: 0.6281423568725586\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03134308 -0.38201356  0.05580396  0.64467394]]\n",
            "            Next State: [[-0.03898336 -0.577867    0.06869744  0.9543946 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.56374955 -0.92638505]]\n",
            "            Q Target: 1.517379641532898\n",
            "            Q change: 0.9536300897598267\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03898336 -0.577867    0.06869744  0.9543946 ]]\n",
            "            Next State: [[-0.05054069 -0.77384245  0.08778533  1.2678456 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5266536  -0.98321104]]\n",
            "            Q Target: 1.5107295513153076\n",
            "            Q change: 0.9840759634971619\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.05054069 -0.77384245  0.08778533  1.2678456 ]]\n",
            "            Next State: [[-0.06601755 -0.96996915  0.11314224  1.5866786 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5265271 -1.0070051]]\n",
            "            Q Target: 1.5187973976135254\n",
            "            Q change: 0.992270290851593\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.06601755 -0.96996915  0.11314224  1.5866786 ]]\n",
            "            Next State: [[-0.08541693 -1.1662395   0.14487581  1.9123948 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.53517294 -1.0156976 ]]\n",
            "            Q Target: 1.5317304134368896\n",
            "            Q change: 0.9965574741363525\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.08541693 -1.1662395   0.14487581  1.9123948 ]]\n",
            "            Next State: [[-0.10874172 -0.97294605  0.18312371  1.6679366 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.548434  -1.0162299]]\n",
            "            Q Target: 1.5863761901855469\n",
            "            Q change: 2.6026060581207275\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.10874172 -0.97294605  0.18312371  1.6679366 ]]\n",
            "            Next State: [[-0.12820064 -1.1696644   0.21648245  2.0116181 ]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.59369487 -0.92170376]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.40630513429641724\n",
            "            \n",
            "Episode 21/30 | Ep. Total Reward: 12.0 | Epsilon : 0.220 | Eval Rwd Mean: 8.67 | Eval Rwd Var: 0.22\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.0084006   0.02785476  0.03030659 -0.0090451 ]]\n",
            "            Next State: [[ 0.0089577  -0.16768841  0.03012569  0.29304376]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.4600859  -0.06120046]]\n",
            "            Q Target: 1.891596794128418\n",
            "            Q change: 1.4315109252929688\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.0089577  -0.16768841  0.03012569  0.29304376]]\n",
            "            Next State: [[ 0.00560393 -0.36322665  0.03598656  0.59507364]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.90713674 -0.8068028 ]]\n",
            "            Q Target: 1.5674697160720825\n",
            "            Q change: 0.660332977771759\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.00560393 -0.36322665  0.03598656  0.59507364]]\n",
            "            Next State: [[-0.0016606  -0.5588333   0.04788804  0.8988714 ]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.60146266 -0.9189217 ]]\n",
            "            Q Target: 1.569434404373169\n",
            "            Q change: 0.9679717421531677\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0016606  -0.5588333   0.04788804  0.8988714 ]]\n",
            "            Next State: [[-0.01283727 -0.7545704   0.06586546  1.2062142 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5861152  -0.97509086]]\n",
            "            Q Target: 1.5725016593933105\n",
            "            Q change: 0.9863864779472351\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01283727 -0.7545704   0.06586546  1.2062142 ]]\n",
            "            Next State: [[-0.02792868 -0.95047873  0.08998975  1.5187899 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5899222 -0.9965083]]\n",
            "            Q Target: 1.5830786228179932\n",
            "            Q change: 0.9931564331054688\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.02792868 -0.95047873  0.08998975  1.5187899 ]]\n",
            "            Next State: [[-0.04693825 -1.1465662   0.12036555  1.8381523 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.6006972 -1.0035481]]\n",
            "            Q Target: 1.5976612567901611\n",
            "            Q change: 0.9969640374183655\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.04693825 -1.1465662   0.12036555  1.8381523 ]]\n",
            "            Next State: [[-0.06986958 -1.3427949   0.15712859  2.1656678 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.6155339 -1.003036 ]]\n",
            "            Q Target: 1.6147631406784058\n",
            "            Q change: 0.9992292523384094\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.06986958 -1.3427949   0.15712859  2.1656678 ]]\n",
            "            Next State: [[-0.09672548 -1.5390657   0.20044194  2.502453  ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.6328222 -0.9978523]]\n",
            "            Q Target: 1.6334718465805054\n",
            "            Q change: 1.0006496906280518\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.09672548 -1.5390657   0.20044194  2.502453  ]]\n",
            "            Next State: [[-0.12750679 -1.7352006   0.250491    2.849301  ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.6517005 -0.9895307]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.348299503326416\n",
            "            \n",
            "Episode 22/30 | Ep. Total Reward: 9.0 | Epsilon : 0.201 | Eval Rwd Mean: 9.33 | Eval Rwd Var: 0.89\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.00507796 -0.03068129 -0.01387775 -0.04337658]]\n",
            "            Next State: [[ 0.00446433 -0.22560152 -0.01474528  0.24489568]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.60323757 -0.13264954]]\n",
            "            Q Target: 1.4575189352035522\n",
            "            Q change: 0.8542813658714294\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.00446433 -0.22560152 -0.01474528  0.24489568]]\n",
            "            Next State: [[-4.7700323e-05 -4.2050979e-01 -9.8473672e-03  5.3289133e-01]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.46278965 -1.2005192 ]]\n",
            "            Q Target: 1.545515775680542\n",
            "            Q change: 1.0827261209487915\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-4.7700323e-05 -4.2050979e-01 -9.8473672e-03  5.3289133e-01]]\n",
            "            Next State: [[-8.4578963e-03 -6.1549187e-01  8.1045984e-04  8.2245523e-01]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5533951 -1.1663744]]\n",
            "            Q Target: 1.5521914958953857\n",
            "            Q change: 0.9987964034080505\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-8.4578963e-03 -6.1549187e-01  8.1045984e-04  8.2245523e-01]]\n",
            "            Next State: [[-0.02076773 -0.8106249   0.01725956  1.1153929 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5686005 -1.1491097]]\n",
            "            Q Target: 1.5709874629974365\n",
            "            Q change: 1.0023870468139648\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.02076773 -0.8106249   0.01725956  1.1153929 ]]\n",
            "            Next State: [[-0.03698023 -1.0059692   0.03956742  1.4134396 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5882784 -1.1344268]]\n",
            "            Q Target: 1.5938514471054077\n",
            "            Q change: 1.005573034286499\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03698023 -1.0059692   0.03956742  1.4134396 ]]\n",
            "            Next State: [[-0.05709961 -1.2015585   0.06783622  1.7182238 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.61140096 -1.1224738 ]]\n",
            "            Q Target: 1.6166236400604248\n",
            "            Q change: 1.0052226781845093\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.05709961 -1.2015585   0.06783622  1.7182238 ]]\n",
            "            Next State: [[-0.08113078 -1.3973892   0.10220069  2.0312228 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.6343261 -1.1095504]]\n",
            "            Q Target: 1.6394016742706299\n",
            "            Q change: 1.0050755739212036\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.08113078 -1.3973892   0.10220069  2.0312228 ]]\n",
            "            Next State: [[-0.10907857 -1.5934067   0.14282516  2.3537097 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.6571934 -1.0957948]]\n",
            "            Q Target: 1.6621835231781006\n",
            "            Q change: 1.0049901008605957\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.10907857 -1.5934067   0.14282516  2.3537097 ]]\n",
            "            Next State: [[-0.1409467  -1.7894893   0.18989934  2.6866865 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.68001974 -1.081268  ]]\n",
            "            Q Target: 1.684926986694336\n",
            "            Q change: 1.004907250404358\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.1409467  -1.7894893   0.18989934  2.6866865 ]]\n",
            "            Next State: [[-0.17673649 -1.5962003   0.24363308  2.4574609 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.7027741 -1.0660472]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 2.066047191619873\n",
            "            \n",
            "Episode 23/30 | Ep. Total Reward: 10.0 | Epsilon : 0.182 | Eval Rwd Mean: 9.00 | Eval Rwd Var: 0.67\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.04616293  0.04384517  0.01331657 -0.00890372]]\n",
            "            Next State: [[ 0.04703984 -0.1514652   0.01313849  0.2879508 ]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.57612276 0.09958471]]\n",
            "            Q Target: 1.9897925853729248\n",
            "            Q change: 1.4136698246002197\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.04703984 -0.1514652   0.01313849  0.2879508 ]]\n",
            "            Next State: [[ 0.04401053 -0.34677204  0.01889751  0.5847484 ]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.9887408 -0.8564633]]\n",
            "            Q Target: 1.7020373344421387\n",
            "            Q change: 0.7132965326309204\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.04401053 -0.34677204  0.01889751  0.5847484 ]]\n",
            "            Next State: [[ 0.03707509 -0.15191983  0.03059248  0.2980778 ]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.711095   -0.91992384]]\n",
            "            Q Target: 2.027306079864502\n",
            "            Q change: 2.9472298622131348\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.03707509 -0.15191983  0.03059248  0.2980778 ]]\n",
            "            Next State: [[ 0.0340367  -0.3474642   0.03655403  0.6002499 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.0487357 -0.7568777]]\n",
            "            Q Target: 1.7313830852508545\n",
            "            Q change: 0.6826473474502563\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.0340367  -0.3474642   0.03655403  0.6002499 ]]\n",
            "            Next State: [[ 0.02708741 -0.54307795  0.04855903  0.90421903]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.75165004 -0.859739  ]]\n",
            "            Q Target: 1.7146543264389038\n",
            "            Q change: 0.9630042910575867\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.02708741 -0.54307795  0.04855903  0.90421903]]\n",
            "            Next State: [[ 0.01622585 -0.73882276  0.06664341  1.2117609 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.7308238 -0.9321426]]\n",
            "            Q Target: 1.7135236263275146\n",
            "            Q change: 0.9826998114585876\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01622585 -0.73882276  0.06664341  1.2117609 ]]\n",
            "            Next State: [[ 1.4493981e-03 -9.3473870e-01  9.0878628e-02  1.5245610e+00]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.7311584  -0.96211696]]\n",
            "            Q Target: 1.7220532894134521\n",
            "            Q change: 0.9908949136734009\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 1.4493981e-03 -9.3473870e-01  9.0878628e-02  1.5245610e+00]]\n",
            "            Next State: [[-0.01724537 -0.740824    0.12136985  1.2615708 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.7401607  -0.97449154]]\n",
            "            Q Target: 1.7798330783843994\n",
            "            Q change: 2.7543246746063232\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01724537 -0.740824    0.12136985  1.2615708 ]]\n",
            "            Next State: [[-0.03206186 -0.9372708   0.14660126  1.5896686 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.78538626 -0.87173015]]\n",
            "            Q Target: 1.7683794498443604\n",
            "            Q change: 0.9829931855201721\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03206186 -0.9372708   0.14660126  1.5896686 ]]\n",
            "            Next State: [[-0.05080727 -1.1337982   0.17839463  1.9242442 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.78729177 -0.8898345 ]]\n",
            "            Q Target: 1.7768031358718872\n",
            "            Q change: 0.9895113706588745\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.05080727 -1.1337982   0.17839463  1.9242442 ]]\n",
            "            Next State: [[-0.07348324 -1.3303308   0.21687952  2.2665348 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.79569334 -0.89730805]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.20430666208267212\n",
            "            \n",
            "Episode 24/30 | Ep. Total Reward: 11.0 | Epsilon : 0.163 | Eval Rwd Mean: 9.67 | Eval Rwd Var: 0.22\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.02397287 -0.01653222  0.01368118 -0.03560355]]\n",
            "            Next State: [[ 0.02364223 -0.21184766  0.01296911  0.26136434]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.5124978 -0.0561979]]\n",
            "            Q Target: 1.6524757146835327\n",
            "            Q change: 1.1399779319763184\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.02364223 -0.21184766  0.01296911  0.26136434]]\n",
            "            Next State: [[ 0.01940528 -0.40715232  0.01819639  0.5581095 ]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.65945166 -1.0271518 ]]\n",
            "            Q Target: 1.719433307647705\n",
            "            Q change: 1.0599815845489502\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01940528 -0.40715232  0.01819639  0.5581095 ]]\n",
            "            Next State: [[ 0.01126223 -0.60252494  0.02935858  0.85646933]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.73550594 -1.0249369 ]]\n",
            "            Q Target: 1.717796802520752\n",
            "            Q change: 0.9822908639907837\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01126223 -0.60252494  0.02935858  0.85646933]]\n",
            "            Next State: [[-7.8827003e-04 -7.9803431e-01  4.6487968e-02  1.1582372e+00]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.73447835 -1.0338621 ]]\n",
            "            Q Target: 1.7293354272842407\n",
            "            Q change: 0.9948570728302002\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-7.8827003e-04 -7.9803431e-01  4.6487968e-02  1.1582372e+00]]\n",
            "            Next State: [[-0.01674896 -0.9937303   0.06965271  1.4651266 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.74671316 -1.035978  ]]\n",
            "            Q Target: 1.7445216178894043\n",
            "            Q change: 0.9978084564208984\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01674896 -0.9937303   0.06965271  1.4651266 ]]\n",
            "            Next State: [[-0.03662356 -1.1896328   0.09895524  1.7787291 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.7623684 -1.0321553]]\n",
            "            Q Target: 1.7617855072021484\n",
            "            Q change: 0.9994171261787415\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03662356 -1.1896328   0.09895524  1.7787291 ]]\n",
            "            Next State: [[-0.06041622 -1.3857197   0.13452983  2.100466  ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.7797654 -1.0250332]]\n",
            "            Q Target: 1.7801480293273926\n",
            "            Q change: 1.000382661819458\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.06041622 -1.3857197   0.13452983  2.100466  ]]\n",
            "            Next State: [[-0.08813061 -1.5819122   0.17653915  2.4315283 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.798179 -1.015668]]\n",
            "            Q Target: 1.7991678714752197\n",
            "            Q change: 1.0009889602661133\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.08813061 -1.5819122   0.17653915  2.4315283 ]]\n",
            "            Next State: [[-0.11976885 -1.7780579   0.2251697   2.7728074 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.817235  -1.0045813]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.18276500701904297\n",
            "            \n",
            "Episode 25/30 | Ep. Total Reward: 9.0 | Epsilon : 0.149 | Eval Rwd Mean: 9.67 | Eval Rwd Var: 0.22\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.039251   -0.01201494 -0.03113394 -0.00396514]]\n",
            "            Next State: [[-0.0394913  -0.20667687 -0.03121324  0.27873436]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.7102718  -0.37389407]]\n",
            "            Q Target: 1.9148476123809814\n",
            "            Q change: 1.204575777053833\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0394913  -0.20667687 -0.03121324  0.27873436]]\n",
            "            Next State: [[-0.04362484 -0.40133998 -0.02563855  0.56141156]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.92662877 -1.1396239 ]]\n",
            "            Q Target: 1.7412919998168945\n",
            "            Q change: 0.8146632313728333\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.04362484 -0.40133998 -0.02563855  0.56141156]]\n",
            "            Next State: [[-0.05165164 -0.5960929  -0.01441032  0.84590805]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.74299496 -1.1012768 ]]\n",
            "            Q Target: 1.736481785774231\n",
            "            Q change: 0.9934868216514587\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.05165164 -0.5960929  -0.01441032  0.84590805]]\n",
            "            Next State: [[-0.0635735  -0.7910153   0.00250784  1.1340249 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.7535384 -1.0982766]]\n",
            "            Q Target: 1.7523460388183594\n",
            "            Q change: 0.9988076090812683\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0635735  -0.7910153   0.00250784  1.1340249 ]]\n",
            "            Next State: [[-0.0793938  -0.98617     0.02518833  1.4274932 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.7696376 -1.0931202]]\n",
            "            Q Target: 1.7719788551330566\n",
            "            Q change: 1.0023412704467773\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0793938  -0.98617     0.02518833  1.4274932 ]]\n",
            "            Next State: [[-0.0991172 -1.1815939  0.0537382  1.7279407]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.78929204 -1.0873059 ]]\n",
            "            Q Target: 1.791705846786499\n",
            "            Q change: 1.0024137496948242\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0991172 -1.1815939  0.0537382  1.7279407]]\n",
            "            Next State: [[-0.12274908 -1.3772873   0.08829701  2.0368485 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.80928236 -1.0787987 ]]\n",
            "            Q Target: 1.8117830753326416\n",
            "            Q change: 1.0025007724761963\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.12274908 -1.3772873   0.08829701  2.0368485 ]]\n",
            "            Next State: [[-0.15029483 -1.5732006   0.12903398  2.3554993 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.82957447 -1.0681266 ]]\n",
            "            Q Target: 1.8321301937103271\n",
            "            Q change: 1.0025557279586792\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.15029483 -1.5732006   0.12903398  2.3554993 ]]\n",
            "            Next State: [[-0.18175884 -1.7692186   0.17614396  2.6849127 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.85020083 -1.0555786 ]]\n",
            "            Q Target: 1.8527617454528809\n",
            "            Q change: 1.0025608539581299\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.18175884 -1.7692186   0.17614396  2.6849127 ]]\n",
            "            Next State: [[-0.21714321 -1.9651421   0.22984222  3.0257695 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.871168  -1.0413115]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.12883198261260986\n",
            "            \n",
            "Episode 26/30 | Ep. Total Reward: 10.0 | Epsilon : 0.135 | Eval Rwd Mean: 9.33 | Eval Rwd Var: 0.22\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.0393644   0.03838549  0.02908734 -0.00131577]]\n",
            "            Next State: [[ 0.04013211 -0.15714128  0.02906102  0.3004008 ]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.5794381  0.10007481]]\n",
            "            Q Target: 2.12957763671875\n",
            "            Q change: 1.5501395463943481\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.04013211 -0.15714128  0.02906102  0.3004008 ]]\n",
            "            Next State: [[ 0.03698929 -0.35266513  0.03506904  0.6021055 ]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.1439041  -0.79940253]]\n",
            "            Q Target: 1.8772375583648682\n",
            "            Q change: 0.7333334684371948\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.03698929 -0.35266513  0.03506904  0.6021055 ]]\n",
            "            Next State: [[ 0.02993598 -0.5482596   0.04711115  0.905625  ]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.8881669 -0.8922481]]\n",
            "            Q Target: 1.873499870300293\n",
            "            Q change: 0.9853329658508301\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.02993598 -0.5482596   0.04711115  0.905625  ]]\n",
            "            Next State: [[ 0.01897079 -0.7439868   0.06522365  1.2127355 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.89174604 -0.9495977 ]]\n",
            "            Q Target: 1.8821547031402588\n",
            "            Q change: 0.9904086589813232\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01897079 -0.7439868   0.06522365  1.2127355 ]]\n",
            "            Next State: [[ 0.00409106 -0.93988705  0.08947836  1.5251234 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.9001494  -0.97287184]]\n",
            "            Q Target: 1.8929080963134766\n",
            "            Q change: 0.9927586913108826\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.00409106 -0.93988705  0.08947836  1.5251234 ]]\n",
            "            Next State: [[-0.01470669 -1.1359681   0.11998083  1.8443397 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.91085213 -0.9820099 ]]\n",
            "            Q Target: 1.9048821926116943\n",
            "            Q change: 0.9940300583839417\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01470669 -1.1359681   0.11998083  1.8443397 ]]\n",
            "            Next State: [[-0.03742605 -1.3321913   0.15686762  2.1717484 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.92287195 -0.9836024 ]]\n",
            "            Q Target: 1.9176356792449951\n",
            "            Q change: 0.9947637319564819\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03742605 -1.3321913   0.15686762  2.1717484 ]]\n",
            "            Next State: [[-0.06406987 -1.5284569   0.20030259  2.5084622 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.93571854 -0.98051727]]\n",
            "            Q Target: 1.930908203125\n",
            "            Q change: 0.9951896667480469\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.06406987 -1.5284569   0.20030259  2.5084622 ]]\n",
            "            Next State: [[-0.09463901 -1.7245858   0.25047183  2.8552694 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 0.94695973 -0.97518885]]\n",
            "            Q Target: 1.0\n",
            "            Q change: 0.053040266036987305\n",
            "            \n",
            "Episode 27/30 | Ep. Total Reward: 9.0 | Epsilon : 0.123 | Eval Rwd Mean: 9.33 | Eval Rwd Var: 0.22\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.03861572 -0.02455227 -0.03389036 -0.0377423 ]]\n",
            "            Next State: [[ 0.03812468 -0.21917225 -0.03464521  0.24405819]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[0.7425894  0.02405581]]\n",
            "            Q Target: 1.6917290687561035\n",
            "            Q change: 0.9491396546363831\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.03812468 -0.21917225 -0.03464521  0.24405819]]\n",
            "            Next State: [[ 0.03374123 -0.41378266 -0.02976405  0.525615  ]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.6979962 -1.2271838]]\n",
            "            Q Target: 1.8158873319625854\n",
            "            Q change: 1.1178910732269287\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.03374123 -0.41378266 -0.02976405  0.525615  ]]\n",
            "            Next State: [[ 0.02546558 -0.6084734  -0.01925175  0.8087724 ]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.8352938 -1.1654079]]\n",
            "            Q Target: 1.8455897569656372\n",
            "            Q change: 1.0102958679199219\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[ 0.02546558 -0.6084734  -0.01925175  0.8087724 ]]\n",
            "            Next State: [[ 0.01329611 -0.41309303 -0.0030763   0.5100965 ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.8634812 -1.1440231]]\n",
            "            Q Target: 1.8535380363464355\n",
            "            Q change: 2.997560977935791\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01329611 -0.41309303 -0.0030763   0.5100965 ]]\n",
            "            Next State: [[ 0.00503425 -0.6081715   0.00712563  0.80180836]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.8661119 -1.1229923]]\n",
            "            Q Target: 1.881923794746399\n",
            "            Q change: 1.0158119201660156\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.00503425 -0.6081715   0.00712563  0.80180836]]\n",
            "            Next State: [[-0.00712918 -0.80339044  0.0231618   1.0967243 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.91571075 -1.0866529 ]]\n",
            "            Q Target: 1.920945644378662\n",
            "            Q change: 1.005234956741333\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.00712918 -0.80339044  0.0231618   1.0967243 ]]\n",
            "            Next State: [[-0.02319699 -0.608581    0.04509628  0.81139743]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.9385443 -1.0687369]]\n",
            "            Q Target: 1.9393210411071777\n",
            "            Q change: 3.0080580711364746\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.02319699 -0.608581    0.04509628  0.81139743]]\n",
            "            Next State: [[-0.03536861 -0.8042908   0.06132423  1.1179174 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.9532428 -1.012284 ]]\n",
            "            Q Target: 1.9511842727661133\n",
            "            Q change: 0.9979414939880371\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03536861 -0.8042908   0.06132423  1.1179174 ]]\n",
            "            Next State: [[-0.05145442 -1.0001614   0.08368258  1.4291892 ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.97022927 -0.99900573]]\n",
            "            Q Target: 1.9655065536499023\n",
            "            Q change: 0.9952772855758667\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.05145442 -1.0001614   0.08368258  1.4291892 ]]\n",
            "            Next State: [[-0.07145765 -1.1962111   0.11226637  1.7468086 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.98353785 -0.9887495 ]]\n",
            "            Q Target: 1.9788379669189453\n",
            "            Q change: 0.9953001141548157\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.07145765 -1.1962111   0.11226637  1.7468086 ]]\n",
            "            Next State: [[-0.09538188 -1.392416    0.14720254  2.0722003 ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.99699    -0.97722083]]\n",
            "            Q Target: 1.9923030138015747\n",
            "            Q change: 0.9953129887580872\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.09538188 -1.392416    0.14720254  2.0722003 ]]\n",
            "            Next State: [[-0.1232302  -1.5886953   0.18864654  2.4065564 ]]\n",
            "            Total Reward: 11.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.0091513 -0.9653145]]\n",
            "            Q Target: 1.9972702264785767\n",
            "            Q change: 0.9881188869476318\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.1232302  -1.5886953   0.18864654  2.4065564 ]]\n",
            "            Next State: [[-0.1550041  -1.7848945   0.23677768  2.750768  ]]\n",
            "            Total Reward: 12.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 1.0212362  -0.95487475]]\n",
            "            Q Target: 1.0\n",
            "            Q change: -0.021236181259155273\n",
            "            \n",
            "Episode 28/30 | Ep. Total Reward: 13.0 | Epsilon : 0.108 | Eval Rwd Mean: 10.00 | Eval Rwd Var: 0.67\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.00403501 -0.04420159  0.03538175  0.04683781]]\n",
            "            Next State: [[-0.00491904 -0.23981257  0.03631851  0.3504707 ]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.92553484 -0.6751288 ]]\n",
            "            Q Target: 2.022027015686035\n",
            "            Q change: 1.0964921712875366\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.00491904 -0.23981257  0.03631851  0.3504707 ]]\n",
            "            Next State: [[-0.00971529 -0.4354317   0.04332792  0.65438116]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.0577354  -0.87970805]]\n",
            "            Q Target: 2.0039358139038086\n",
            "            Q change: 0.9462003707885742\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.00971529 -0.4354317   0.04332792  0.65438116]]\n",
            "            Next State: [[-0.01842393 -0.63112926  0.05641555  0.9603865 ]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.0105221  -0.90895617]]\n",
            "            Q Target: 1.998899221420288\n",
            "            Q change: 0.9883770942687988\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.01842393 -0.63112926  0.05641555  0.9603865 ]]\n",
            "            Next State: [[-0.03104651 -0.8269623   0.07562327  1.270246  ]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.0196596  -0.93107337]]\n",
            "            Q Target: 2.010167121887207\n",
            "            Q change: 0.9905074834823608\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03104651 -0.8269623   0.07562327  1.270246  ]]\n",
            "            Next State: [[-0.04758576 -1.0229639   0.1010282   1.5856202 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.0299577 -0.9388044]]\n",
            "            Q Target: 2.016909599304199\n",
            "            Q change: 0.9869519472122192\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.04758576 -1.0229639   0.1010282   1.5856202 ]]\n",
            "            Next State: [[-0.06804504 -1.2191315   0.1327406   1.908023  ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.0430961 -0.9395241]]\n",
            "            Q Target: 2.0306975841522217\n",
            "            Q change: 0.9876015186309814\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.06804504 -1.2191315   0.1327406   1.908023  ]]\n",
            "            Next State: [[-0.09242767 -1.4154133   0.17090106  2.2387667 ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.0573132 -0.9353551]]\n",
            "            Q Target: 2.0509250164031982\n",
            "            Q change: 0.9936118125915527\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.09242767 -1.4154133   0.17090106  2.2387667 ]]\n",
            "            Next State: [[-0.12073593 -1.6116917   0.2156764   2.578896  ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 1.0718063 -0.9280014]]\n",
            "            Q Target: 1.0\n",
            "            Q change: -0.07180631160736084\n",
            "            \n",
            "Episode 29/30 | Ep. Total Reward: 8.0 | Epsilon : 0.100 | Eval Rwd Mean: 9.67 | Eval Rwd Var: 0.22\n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.02347091 -0.00799606 -0.02444621  0.0173887 ]]\n",
            "            Next State: [[ 0.02331099 -0.20275904 -0.02409843  0.30225942]]\n",
            "            Total Reward: 0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 0.8008933  -0.21912724]]\n",
            "            Q Target: 2.060901641845703\n",
            "            Q change: 1.2600083351135254\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.02331099 -0.20275904 -0.02409843  0.30225942]]\n",
            "            Next State: [[ 0.01925581 -0.3975294  -0.01805324  0.5872459 ]]\n",
            "            Total Reward: 1.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.0761908  -0.96813554]]\n",
            "            Q Target: 2.0035367012023926\n",
            "            Q change: 0.927345871925354\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01925581 -0.3975294  -0.01805324  0.5872459 ]]\n",
            "            Next State: [[ 0.01130522 -0.59239393 -0.00630833  0.87418765]]\n",
            "            Total Reward: 2.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.017229   -0.97639036]]\n",
            "            Q Target: 2.0228610038757324\n",
            "            Q change: 1.0056320428848267\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[ 0.01130522 -0.59239393 -0.00630833  0.87418765]]\n",
            "            Next State: [[-5.4265902e-04 -7.8742957e-01  1.1175425e-02  1.1648806e+00]]\n",
            "            Total Reward: 3.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.041469  -0.9857747]]\n",
            "            Q Target: 2.0375638008117676\n",
            "            Q change: 0.996094822883606\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-5.4265902e-04 -7.8742957e-01  1.1175425e-02  1.1648806e+00]]\n",
            "            Next State: [[-0.01629125 -0.98269516  0.03447304  1.4610463 ]]\n",
            "            Total Reward: 4.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.056791   -0.98974884]]\n",
            "            Q Target: 2.052307367324829\n",
            "            Q change: 0.9955164194107056\n",
            "            \n",
            "\n",
            "            Action Taken: 1\n",
            "            Current State: [[-0.01629125 -0.98269516  0.03447304  1.4610463 ]]\n",
            "            Next State: [[-0.03594515 -0.7880124   0.06369396  1.1793287 ]]\n",
            "            Total Reward: 5.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.0719634 -0.9873327]]\n",
            "            Q Target: 2.0768208503723145\n",
            "            Q change: 3.0641536712646484\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.03594515 -0.7880124   0.06369396  1.1793287 ]]\n",
            "            Next State: [[-0.0517054  -0.9839009   0.08728053  1.491279  ]]\n",
            "            Total Reward: 6.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.0891949 -0.9201584]]\n",
            "            Q Target: 2.081120014190674\n",
            "            Q change: 0.9919251203536987\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.0517054  -0.9839009   0.08728053  1.491279  ]]\n",
            "            Next State: [[-0.07138342 -1.17997     0.11710612  1.8098911 ]]\n",
            "            Total Reward: 7.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.1015574  -0.91762495]]\n",
            "            Q Target: 2.0918407440185547\n",
            "            Q change: 0.9902833700180054\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.07138342 -1.17997     0.11710612  1.8098911 ]]\n",
            "            Next State: [[-0.09498282 -1.3761868   0.15330394  2.136551  ]]\n",
            "            Total Reward: 8.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.109995  -0.9152139]]\n",
            "            Q Target: 2.0972371101379395\n",
            "            Q change: 0.9872421026229858\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.09498282 -1.3761868   0.15330394  2.136551  ]]\n",
            "            Next State: [[-0.12250656 -1.5724581   0.19603495  2.4724002 ]]\n",
            "            Total Reward: 9.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: False\n",
            "            Q Values: [[ 1.1192096  -0.91040343]]\n",
            "            Q Target: 2.1066503524780273\n",
            "            Q change: 0.9874407052993774\n",
            "            \n",
            "\n",
            "            Action Taken: 0\n",
            "            Current State: [[-0.12250656 -1.5724581   0.19603495  2.4724002 ]]\n",
            "            Next State: [[-0.15395571 -1.7686138   0.24548295  2.818264  ]]\n",
            "            Total Reward: 10.0\n",
            "            Reward: 1.0\n",
            "            Is terminated: True\n",
            "            Q Values: [[ 1.1289362 -0.9037828]]\n",
            "            Q Target: 1.0\n",
            "            Q change: -0.12893617153167725\n",
            "            \n",
            "Episode 30/30 | Ep. Total Reward: 11.0 | Epsilon : 0.100 | Eval Rwd Mean: 9.33 | Eval Rwd Var: 0.22\n",
            "Training time: 32.8621 seconds per episode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Results"
      ],
      "metadata": {
        "id": "qZ86BPQR3AhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write code to plot\n",
        "# 1) Moving Averaged Training Reward, 2) Evaluation Mean, 3) Evaluation Variance\n",
        "# [Write Code]\n",
        "\n",
        "plot_smoothed_training_rwd(eval_reward_mean_lst)\n",
        "\n",
        "plot_eval_rwd_mean(eval_reward_mean_lst)\n",
        "\n",
        "plot_eval_rwd_var(eval_reward_var_lst)"
      ],
      "metadata": {
        "id": "It8u9fyj3AL5",
        "outputId": "5ab9ccf9-3a74-4c5e-833f-a1e76203f9fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAHHCAYAAAC4BYz1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAfdZJREFUeJzt3Xd4VGXaP/DvlMxk0kN6I1QJXUBlQYoKCohKs4IKuK6ri/uzrPrqvq/oWl52fVd03VVY17a6dkAUFBBREBRRgQAKRDqkJ5Bepp7fH5NzMpM65cycM5nv57rmgkw558lkkrnnee7nvjWCIAggIiIiCjNapQdAREREpAQGQURERBSWGAQRERFRWGIQRERERGGJQRARERGFJQZBREREFJYYBBEREVFYYhBEREREYYlBEBEREYUlBkFEPZhGo8Hjjz+uyLm3bt0KjUaDrVu3KnL+nu6NN96ARqPByZMnlR4KUchiEEQUYOKbVWeX7777Tukh+uWll17CG2+8ofQw3FxyySVuz7HJZMKIESPw/PPPw+FwKD28oHr88ceh0Wig1Wpx5syZdrfX1tbCZDJBo9Hg7rvvVmCERMrRKz0AonDxxBNPoG/fvu2uHzBggAKjkc9LL72E5ORkLFq0yO36SZMmoampCQaDQZFxZWdnY9myZQCAyspKvPPOO7jvvvtQUVGBp59+WpExKcloNOLdd9/FQw895Hb9mjVrFBoRkfIYBBEFyYwZM3DBBRcoPYyg0Wq1iIyMVOz88fHxuPnmm6Wv77zzTuTl5eHvf/87nnjiCeh0OsXG5gmHwwGLxSLbc3jllVd2GAS98847mDlzJlavXi3LeYhCCZfDiFTAarWiV69eWLx4cbvbamtrERkZiQceeAAAYLFYsHTpUowZMwbx8fGIjo7GxIkT8dVXX3V7nkWLFqFPnz7trheXTFy9/vrruOyyy5Camgqj0YghQ4ZgxYoVbvfp06cPfv75Z2zbtk1aerrkkksAdJ4T9OGHH2LMmDEwmUxITk7GzTffjKKionbjjImJQVFREWbPno2YmBikpKTggQcegN1u7/b77EhkZCQuvPBC1NXVoby83O22//znP9KYevXqhRtvvNFt6eiFF16ATqdDdXW1dN2zzz4LjUaD+++/X7rObrcjNjYW//Vf/yVd99e//hXjx49HUlISTCYTxowZg1WrVrUbn7gc9fbbb2Po0KEwGo3YuHEjAODnn3/GZZddBpPJhOzsbDz11FNeL+vNnz8f+fn5OHz4sHRdaWkpvvzyS8yfP7/Dx5jNZjz22GMYMGAAjEYjcnJy8NBDD8FsNrvdz5PXCuB8vVx11VXYsWMHLrroIkRGRqJfv3548803vfpeiOTCmSCiIKmpqUFlZaXbdRqNBklJSYiIiMCcOXOwZs0a/POf/3RbQlq7di3MZjNuvPFGAM6g6JVXXsFNN92E3/zmN6irq8Orr76KadOm4fvvv8f5558vy3hXrFiBoUOH4pprroFer8e6devwu9/9Dg6HA0uWLAEAPP/88/j973+PmJgY/Pd//zcAIC0trdNjvvHGG1i8eDEuvPBCLFu2DGVlZfjb3/6Gb775Bnv37kVCQoJ0X7vdjmnTpmHs2LH461//ii+++ALPPvss+vfvj7vuusun7+nkyZPQaDRu53n66afx6KOP4vrrr8ftt9+OiooK/P3vf8ekSZOkMU2cOBEOhwM7duzAVVddBQDYvn07tFottm/fLh1r7969qK+vx6RJk6Tr/va3v+Gaa67BggULYLFY8N577+G6667D+vXrMXPmTLfxffnll/jggw9w9913Izk5GX369EFpaSkuvfRS2Gw2PPzww4iOjsbLL78Mk8nk1fc+adIkZGdn45133sETTzwBAHj//fcRExPTbhyAcybqmmuuwY4dO3DHHXdg8ODBOHDgAJ577jn88ssvWLt2rXRfT14roqNHj+Laa6/Fr3/9ayxcuBCvvfYaFi1ahDFjxmDo0KFefU9EfhOIKKBef/11AUCHF6PRKN1v06ZNAgBh3bp1bo+/8sorhX79+klf22w2wWw2u92nqqpKSEtLE2677Ta36wEIjz32mPT1woULhdzc3HZjfOyxx4S2fw4aGxvb3W/atGluYxEEQRg6dKgwefLkdvf96quvBADCV199JQiCIFgsFiE1NVUYNmyY0NTUJN1v/fr1AgBh6dKlbuMEIDzxxBNuxxw1apQwZsyYdudqa/LkyUJeXp5QUVEhVFRUCIcPHxYefPBBAYAwc+ZM6X4nT54UdDqd8PTTT7s9/sCBA4Jer5eut9vtQlxcnPDQQw8JgiAIDodDSEpKEq677jpBp9MJdXV1giAIwvLlywWtVitUVVVJx2r7PFosFmHYsGHCZZdd5nY9AEGr1Qo///yz2/X33nuvAEDYtWuXdF15ebkQHx8vABBOnDjR5XMh/mwrKiqEBx54QBgwYIB024UXXigsXrxYOv+SJUuk29566y1Bq9UK27dvdzveypUrBQDCN9980+n3KAgdv1Zyc3MFAMLXX3/t9r0YjUbhD3/4Q5ffB1EgcDmMKEhefPFFbN682e2yYcMG6fbLLrsMycnJeP/996XrqqqqsHnzZtxwww3SdTqdTpopcjgcOHfuHGw2Gy644ALs2bNHtvG6zjSIs1iTJ0/G8ePHUVNT4/XxfvzxR5SXl+N3v/udW57LzJkzkZeXh08//bTdY+688063rydOnIjjx497dL7Dhw8jJSUFKSkpyMvLw//93//hmmuucdvJtmbNGjgcDlx//fWorKyULunp6Rg4cKC0xKjVajF+/Hh8/fXXAIBDhw7h7NmzePjhhyEIAnbu3AnAOTs0bNgwt5km1+exqqoKNTU1mDhxYoc/q8mTJ2PIkCFu13322Wf41a9+hYsuuki6LiUlBQsWLPDoeXA1f/58HD16FD/88IP0b2dLYR9++CEGDx6MvLw8t+fmsssuAwC35VdvXitDhgzBxIkT3b6XQYMGefxzJZITl8OIguSiiy7qMjFar9dj3rx5eOedd2A2m2E0GrFmzRpYrVa3IAgA/v3vf+PZZ5/F4cOHYbVapes72n3mq2+++QaPPfYYdu7cicbGRrfbampqEB8f79XxTp06BQAYNGhQu9vy8vKwY8cOt+siIyORkpLidl1iYiKqqqo8Ol+fPn3wr3/9Cw6HA8eOHcPTTz+NiooKtwDsyJEjEAQBAwcO7PAYERER0v8nTpyIxx9/HE1NTdi+fTsyMjIwevRojBw5Etu3b8fll1+OHTt24Prrr3c7xvr16/HUU08hPz/fLZembQ4W0PHP79SpUxg7dmy76zt6HrszatQo5OXl4Z133kFCQgLS09OloKatI0eO4NChQ+1+BiLXvCpvXiu9e/dudyxvfq5EcmIQRKQiN954I/75z39iw4YNmD17Nj744APk5eVh5MiR0n3+85//YNGiRZg9ezYefPBBpKamQqfTYdmyZTh27FiXx+/ojRdAu2TjY8eOYcqUKcjLy8Py5cuRk5MDg8GAzz77DM8991xQau34u3srOjoaU6dOlb6++OKLMXr0aPzxj3/ECy+8AMA5k6bRaLBhw4YOzxcTEyP9f8KECbBardi5cye2b98uzWZMnDgR27dvx+HDh1FRUeE2y7F9+3Zcc801mDRpEl566SVkZGQgIiICr7/+Ot5555125/M2z8cX8+fPx4oVKxAbG4sbbrgBWm3HCwIOhwPDhw/H8uXLO7w9JycHgPevlc5+roIg+PFdEfmGQRCRikyaNAkZGRl4//33MWHCBHz55ZdSwrFo1apV6NevH9asWeMW1Dz22GPdHj8xMdFth5NInKURrVu3DmazGZ988onbJ/eOdqB1Fli1lZubCwAoKChoN/tQUFAg3R4oI0aMwM0334x//vOfeOCBB9C7d2/0798fgiCgb9++OO+887p8/EUXXQSDwYDt27dj+/btePDBBwE4f2b/+te/sGXLFulr0erVqxEZGYlNmzbBaDRK17/++usejzs3NxdHjhxpd31BQYHHx3A1f/58LF26FCUlJXjrrbc6vV///v2xb98+TJkypcufsTevFSK1YU4QkYpotVpce+21WLduHd566y3YbLZ2S2HiJ2nXT867du2S8lK60r9/f9TU1GD//v3SdSUlJfjoo4+6PUdNTU2Hb97R0dEdBlZtXXDBBUhNTcXKlSvdloU2bNiAQ4cOdbhDSW4PPfQQrFarNLsxd+5c6HQ6/OlPf2o3EyEIAs6ePSt9LW6xf/fdd3H69Gm3maCmpia88MIL6N+/PzIyMqTH6HQ6aDQat5m2kydPuu2s6s6VV16J7777Dt9//710XUVFBd5++22vvndR//798fzzz2PZsmVueUZtXX/99SgqKsK//vWvdrc1NTWhoaEBgHevFSK14UwQUZBs2LDBrUaLaPz48ejXr5/09Q033IC///3veOyxxzB8+HAMHjzY7f5XXXUV1qxZgzlz5mDmzJk4ceIEVq5ciSFDhqC+vr7LMdx44434r//6L8yZMwf/7//9PzQ2NmLFihU477zz3BJ1r7jiChgMBlx99dX47W9/i/r6evzrX/9CamoqSkpK3I45ZswYrFixAk899RQGDBiA1NTUDvNMIiIi8Je//AWLFy/G5MmTcdNNN0lb5Pv06YP77rvPo+fRH0OGDMGVV16JV155BY8++ij69++Pp556Co888ghOnjyJ2bNnIzY2FidOnMBHH32EO+64Q6rPBDgDnj//+c+Ij4/H8OHDAQCpqakYNGgQCgoK2lXNnjlzJpYvX47p06dj/vz5KC8vx4svvogBAwa4BaJdeeihh/DWW29h+vTpuOeee6Qt8rm5uR4fo6177rmn2/vccsst+OCDD3DnnXfiq6++wsUXXwy73Y7Dhw/jgw8+wKZNm3DBBRd49VohUh3F9qURhYmutsgDEF5//XW3+zscDiEnJ0cAIDz11FPtjudwOIT//d//FXJzcwWj0SiMGjVKWL9+fYfb39Fmi7wgCMLnn38uDBs2TDAYDMKgQYOE//znPx1ukf/kk0+EESNGCJGRkUKfPn2Ev/zlL8Jrr73Wblt2aWmpMHPmTCE2NlYAIG2Xb7tFXvT+++8Lo0aNEoxGo9CrVy9hwYIFQmFhodt9Fi5cKERHR7f73jsaZ0cmT54sDB06tMPbtm7d2u55Wb16tTBhwgQhOjpaiI6OFvLy8oQlS5YIBQUFbo/99NNPBQDCjBkz3K6//fbbBQDCq6++2u58r776qjBw4EDBaDQKeXl5wuuvv97h94E2W9Rd7d+/X5g8ebIQGRkpZGVlCU8++aTw6quver1Fvisdnd9isQh/+ctfhKFDhwpGo1FITEwUxowZI/zpT38SampqpPt5+lrJzc11K1Egmjx5codlFogCTSMIzEYjIiKi8MOcICIiIgpLDIKIiIgoLDEIIiIiorDEIIiIiIjCEoMgIiIiCksMgoiIiCgssVhiBxwOB4qLixEbG+txSwAiIiJSliAIqKurQ2ZmZqd98VwxCOpAcXGx1ByQiIiIQsuZM2eQnZ3d7f0YBHUgNjYWgPNJjIuLU3g0RERE5Ina2lrk5ORI7+PdYRDUAXEJLC4ujkEQERFRiPE0lYWJ0URERBSWGAQRERFRWGIQRERERGGJQRARERGFJQZBREREFJYYBBEREVFYYhBEREREYYlBEBEREYUlBkFEREQUlhgEERERUVhiEERERERhiUEQERERhSUGQeSxJotd6SEQERHJhkEQeeS5zb9gxJ82If9MtdJDISIikgWDIPLIDyfPwWoXsI9BEBER9RAMgsgjtc1W579NVoVHQkREJA8GQeSRumab81+zTeGREBERyYNBEHlEnAHiTBAREfUUDIKoW4IgoLZlJkhcFiMiIgp1DIKoW40WO+wOAQBQ28TlMCIi6hkYBFG3xHwg5/85E0RERD0DgyDqlusSWG0zZ4KIiKhnYBBE3XJNhmZiNBER9RQMgqhb7jNBVgiCoOBoiIiI5MEgiLrlmgxttQtotjoUHA0REZE8GARRt9omQzM5moiIegIGQdSttsnQrBVEREQ9AYMg6lbbZOga1goiIqIegEEQdavtzA9ngoiIqCdgEETdalslmtvkiYioJ2AQRN1qO/NTx4KJRETUAzAIom6JidG9og0tX3MmiIiIQh+DIOpWXcvyV3aiCQCbqBIRUc/AIIi6Jc78ZCWY3L4mIiIKZQyCqFvizI8UBDExmoiIegAGQdSlZqsdFruzTYa4HMbEaCIi6gkYBFGXxKUvrQZIj+dyGBER9RwMgqhL4lJYbGQEEqIiWq5jEERERKGPQRB1SZz1iY3UIzZS33Idl8OIiCj0MQiiLomzPnGREYiL5EwQERH1HAyCqEtiEnScSY84kzMIMtscMNvsSg6LiIjIbwyCqEviclhcZARijXpoNM7ruUOMiIhCHYMg6pKYGB1nioBWq0GMsSUviEtiREQU4hgEUZdcE6MBtOYFcSaIiIhCHIMg6pJrYjTQGgxxJoiIiEIdgyDqUmtidITbv8wJIiKiUMcgiLrUmhjddjmMM0FERBTaGARRl6TlMGkmiMthRETUMzAIoi6JCdDtE6MZBBERUWhjEERdapsYHSclRjMniIiIQhuDIOqSmAAd3y4xmjNBREQU2hgEUacsNgearM72GK0zQawTREREPYOiQdDXX3+Nq6++GpmZmdBoNFi7dq3b7WvWrMEVV1yBpKQkaDQa5Ofne3TcDz/8EHl5eYiMjMTw4cPx2WefyT/4MOA62xMj5gQxMZqIiHoIRYOghoYGjBw5Ei+++GKnt0+YMAF/+ctfPD7mt99+i5tuugm//vWvsXfvXsyePRuzZ8/GTz/9JNeww4Y42xNj1EOndTYNi2ViNBER9RB6JU8+Y8YMzJgxo9Pbb7nlFgDAyZMnPT7m3/72N0yfPh0PPvggAODJJ5/E5s2b8Y9//AMrV670a7zhpjUpuvVlIi2HMTGaiIhCXI/LCdq5cyemTp3qdt20adOwc+fOTh9jNptRW1vrdqH21aKd/9e33MaZICIiCm09LggqLS1FWlqa23VpaWkoLS3t9DHLli1DfHy8dMnJyQn0MENCa7VolyCo5f8NFjtsdoci4yIiIpJDjwuCfPHII4+gpqZGupw5c0bpIalCa7Xo1uWwWJelMfYPIyKiUKZoTlAgpKeno6yszO26srIypKend/oYo9EIo9EY6KGFHHEmKNZlJkiv0yLKoEOjxY7aZisSow1KDY+IiMgvPW4maNy4cdiyZYvbdZs3b8a4ceMUGlHoEpOfXROjnV8zOZqIiEKfojNB9fX1OHr0qPT1iRMnkJ+fj169eqF37944d+4cTp8+jeLiYgBAQUEBAOdsjzizc+uttyIrKwvLli0DANxzzz2YPHkynn32WcycORPvvfcefvzxR7z88stB/u5Cn5j87JoY7fxaj9JaJkcTEVFoU3Qm6Mcff8SoUaMwatQoAMD999+PUaNGYenSpQCATz75BKNGjcLMmTMBADfeeCNGjRrlttX99OnTKCkpkb4eP3483nnnHbz88ssYOXIkVq1ahbVr12LYsGFB/M56BrFOkGtitOvXrBVEREShTNGZoEsuuQSCIHR6+6JFi7Bo0aIuj7F169Z211133XW47rrr/BwdiYnRsW2Ww2LZRJWIiHqAHpcTRPKp7XQ5jDNBREQU+hgEUadaE6M7Ww7jTBAREYUuBkHUqdbE6Da7w9hElYiIegAGQdQpJkYTEVFPxiCIOmSzO1BvdgZB7ROjWSeIiIhCH4Mg6pAYAAHuFaMBl+UwzgQREVEIYxBEHRL7gpkidDDo3V8m4nIYe4cREVEoYxBEHarpoHmqSNoiz8RoIiIKYQyCqENSjaA2S2HO67gcRkREoY9BEHVITHpumxTtvM4ZGNWbbXA4Oq/4TUREpGYMgqhDnVWLBloDI0EA6szMCyIiotDEIIg6VNdJjSAAiIzQwdiSLM1O8kREFKoYBFGHartIjHZez1pBREQU2hgEUYe6Sox2Xs/kaCIiCm0MgqhDrYnRHQdBrVWjGQQREVFoYhBEHartpHmqSFoOY8FEIiIKUQyCqEN1Hi6HMTGaiIhCFYMg6pC4HNbRFnnX65kYTUREoYpBEHWoNTG6k+UwMSeIM0FERBSiGARRh8SE584To/Vu9yMiIgo1DIKoHYdDkCpBd58YzSCIiIhCE4MgaqfBYoPQ0hKs+8Ro5gQREVFoYhBE7Yjb3g16LSIjdB3ehzNBREQU6hgEUTtSy4xOZoFcb+PuMCIiClUMgqid1iCo43wg19s4E0RERKGKQRC1Iy6HxXZSIwhoXQ6ra7ZBEBOIiIiIQgiDIGqnrpsaQc7bnEGQ3SGg0WIPyriIiIjkxCCI2pGWw7qYCYqM0CJCp3Hen0tiREQUghgEUTviclhXidEajYbJ0UREFNIYBFE7niRGAy5VozkTREREIYhBELUj9Q3rYjnM9Xa2ziAiolDEIIjaqZOWw7qeCRKXw1g1moiIQhGDIGrH85kgLocREVHo6vqjPsnKanegst4Mu0NAdmKU0sPplJjoHNtdTpCRy2FERBS6OBMURGv2FGLcsi+x9OOflR5Kl6SZoC52hwGuM0FcDiMiotDDICiIkmOMAICKOrPCI+maJ3WCANf+YZwJIiKi0MMgKIhSYtUfBAmC4JIY7dnuMCZGExFRKGIQFERiEFRZb4bDoc5+W01WO2wtYxOXuzrDxGgiIgplDIKCKCnaGQTZHAJqVLqEJCZF67QamCJ0Xd6XidFERBTKGAQFkUGvRUKUM3CoqFfnklitS/NUjUbT5X2lYolcDiMiohDEICjIUlSeHO1pUrTzPnq3xxAREYUSBkFB5poXpEaeJkW73qeu2QZBUGeOExERUWcYBAWZ2rfJt1aL7r6OpjhbZLE7YLY5AjouIiIiuTEICjK1b5MXl7bEpOeuRBt00GrcH0dERBQqGAQFmRQEqXQ5TExy9mQmSKPRIFYsmMht8kREFGIYBAWZ6pfDmjxrmSFi6wwiIgpVDIKCTPXLYdJMkIdBEFtnEBFRiGIQFGTiFvnKeovCI+mYa50gT0hBEGeCiIgoxDAICrLkWAMA4FyDGXYVts6QEqM9XA6LjWStICIiCk0MgoIsKdoIrQZwCMDZBvUtiXm9HGZiYjQREYUmBkFBptNq0CtavXlBdT4uh7GTPBERhRoGQQpIjnEuiakxL0hsoOr5TBCXw4iIKDQpGgR9/fXXuPrqq5GZmQmNRoO1a9e63S4IApYuXYqMjAyYTCZMnToVR44c6fKYjz/+ODQajdslLy8vgN+F99S8Q6y1YrSXu8M4E0RERCFG0SCooaEBI0eOxIsvvtjh7c888wxeeOEFrFy5Ert27UJ0dDSmTZuG5ubmLo87dOhQlJSUSJcdO3YEYvg+U2sQ1Gy1w9LS/iLWw+UwJkYTEVGo8uydLkBmzJiBGTNmdHibIAh4/vnn8T//8z+YNWsWAODNN99EWloa1q5dixtvvLHT4+r1eqSnpwdkzHJQaxNVcRZIowFiDB7mBDExmoiIQpRqc4JOnDiB0tJSTJ06VbouPj4eY8eOxc6dO7t87JEjR5CZmYl+/fphwYIFOH36dJf3N5vNqK2tdbsEUopKq0aLyc2xRj20YlOwbjAxmoiIQpVqg6DS0lIAQFpamtv1aWlp0m0dGTt2LN544w1s3LgRK1aswIkTJzBx4kTU1dV1+phly5YhPj5euuTk5MjzTXRCrcthUssMD/OBnPflchgREYUm1QZBvpoxYwauu+46jBgxAtOmTcNnn32G6upqfPDBB50+5pFHHkFNTY10OXPmTEDH2Fo1WmVBkFgjyMNCia735XIYERGFGtUGQWJOT1lZmdv1ZWVlXuX7JCQk4LzzzsPRo0c7vY/RaERcXJzbJZCSVdpJvrVatOepYmIQ1Gx1wGyzB2RcREREgaDaIKhv375IT0/Hli1bpOtqa2uxa9cujBs3zuPj1NfX49ixY8jIyAjEMH0izgRVN1ql3Vhq4O32eACIcQmYmBdEREShRNEgqL6+Hvn5+cjPzwfgTIbOz8/H6dOnodFocO+99+Kpp57CJ598ggMHDuDWW29FZmYmZs+eLR1jypQp+Mc//iF9/cADD2Dbtm04efIkvv32W8yZMwc6nQ433XRTkL+7zsWbIhChcyYeq6l1Rp0Py2E6rQaxRr3b44mIiEKBolvkf/zxR1x66aXS1/fffz8AYOHChXjjjTfw0EMPoaGhAXfccQeqq6sxYcIEbNy4EZGRkdJjjh07hsrKSunrwsJC3HTTTTh79ixSUlIwYcIEfPfdd0hJSQneN9YNrVaDpGgjSmubUVFnRka8SekhAXBNjPbuZRFnikCd2cbkaCIiCimKBkGXXHIJBKHzTuoajQZPPPEEnnjiiU7vc/LkSbev33vvPbmGF1Apsa1BkFpIy2FezAQBLgUTmRxNREQhRLU5QT2dGgsmin3DvEmMBlx2iDVxOYyIiEIHgyCFiE1UVTkT5EVitPP+nAkiIqLQwyBIIWosmOhLYrTr/esYBBERUQhhEKQQqXWGqpbDfE+Mdj6ey2FERBQ6GAQpJCXWucOtss6i8EhaMTGaiIjCCYMghUg5QaqaCfJvOYxb5ImIKJQwCFKI2nKCrHYHmqzOthfeL4eJM0FcDiMiotDBIEghYhBUb7ahyaJ8zy3Xas8xRt+2yDMxmoiIQgmDIIXEGPUw6p1PvxpqBYlLWTFGPfQ6714WTIwmIqJQxCBIIRqNRpoNKlfBkpiY1OxtoUTXxzAxmoiIQgmDIAWpqWq0r0nRro9hYjQREYUSr4OgsrIy3HLLLcjMzIRer4dOp3O7kOeSY9STHN1aLdr7mSBxOazBYofN7pB1XERERIHi9TveokWLcPr0aTz66KPIyMiARqMJxLjCgpp2iNX5WCMIcF9CqzfbkBBlkG1cREREgeJ1ELRjxw5s374d559/fgCGE17EqtGqWg7zsm8YAETotIgy6NBosaO2iUEQERGFBq+Xw3JyciAIQiDGEnaSVTQT5E9itOvjmBxNREShwusg6Pnnn8fDDz+MkydPBmA44UVN/cOkvmE+LIe5Po7J0UREFCq8/th/ww03oLGxEf3790dUVBQiItzfNM+dOyfb4Ho6NeUEidWefUmMdj6uJQjiTBAREYUIr9/xnn/++QAMIzylumyRFwRB0SRzfxKjnY9j6wwiIgotXgdBCxcuDMQ4wpK4Rb7Z6kC92YZYHwMQOfiTGO36OC6HERFRqPBt7aNFc3MzLBaL23VxcXF+DSicmAw6xBj1qDfbUFFnVjYIki0xmjNBREQUGrxOjG5oaMDdd9+N1NRUREdHIzEx0e1C3mmtGm3p5p6BxcRoIiIKN14HQQ899BC+/PJLrFixAkajEa+88gr+9Kc/ITMzE2+++WYgxtijJcc4a+oonRzdmhjt53IYE6OJiChEeL32sW7dOrz55pu45JJLsHjxYkycOBEDBgxAbm4u3n77bSxYsCAQ4+yxWneINSs2BrtDQL1Z7B3m4+6wlpmgOi6HERFRiPB6JujcuXPo168fAGf+j7glfsKECfj666/lHV0YaK0ardxyWL1L4OJrXpK4tZ7LYUREFCq8DoL69euHEydOAADy8vLwwQcfAHDOECUkJMg6uHCghiaq4hJWZIQWBr3XLwkArcETE6OJiChUeP2Ot3jxYuzbtw8A8PDDD+PFF19EZGQk7rvvPjz44IOyD7Cnk5bDFKwaXeNnUrTzsZwJIiKi0OJ1Ash9990n/X/q1Kk4fPgwdu/ejQEDBmDEiBGyDi4cpMQq30RVnAnyNSna9bFMjCYiolDhd52g3Nxc5ObmyjWesKOG5TAxmdnXpGjnY51BUL3ZBodDgFarXPVrIiIiT3i9HGa32/Hkk08iKysLMTExOH78OADg0Ucfxauvvir7AHs615kgh0NQZAxSjSA/ZoLEYomCANRbmBdERETq53UQ9PTTT+ONN97AM888A4PBIF0/bNgwvPLKK7IOLhwktdQJstoFKTcn2MRkZn8qVkdG6KSkauYFERFRKPA6CHrzzTfx8ssvY8GCBdDpdNL1I0eOxOHDh2UdXDgw6nVIiHIGH0rlBbVWi/ZrddSlajRngoiISP28DoKKioowYMCAdtc7HA5YrZwB8IXSeUF1flaLFom1guqYHE1ERCHA6yBoyJAh2L59e7vrV61ahVGjRskyqHAjFkxUapu8tDvMzwaucawVREREIcTr9Y+lS5di4cKFKCoqgsPhwJo1a1BQUIA333wT69evD8QYe7zW1hkKL4eZ/FwOM7GJKhERhQ6vZ4JmzZqFdevW4YsvvkB0dDSWLl2KQ4cOYd26dbj88ssDMcYeL1klM0H+JEY7H693Ox4REZGa+fTRf+LEidi8ebPcYwlbys8E+V8nyPl4JkYTEVHo8K1RFMmqtVaQMk1U68z+1wlyPp6J0UREFDo8/ugvdo7vjlg8kTyX3FIrSPmZILkSoxkEERGR+nkcBJ08eRK5ubmYP38+UlNTAzmmsKPkcpjDIUgzN/4vh4lNVLkcRkRE6ufxu97777+P1157DcuXL8eMGTNw22234corr4RWyxU1f4lB0LkGM+wOAbog9t1qsNggduvwfzmMM0FERBQ6PI5grrvuOmzYsAFHjx7FmDFjcN999yEnJwcPP/wwjhw5Esgx9ni9ogzQaACHAJxrCG5ekFjTx6DTwqj3L6DlchgREYUSr9/1srKy8N///d84cuQI3nnnHezatQt5eXmoqqoKxPjCgl6nRVK0MnlB0lKYSQ+Nxr8ZqNbEaC6HERGR+vmUBNLc3IxVq1bhtddew65du3DdddchKipK7rGFleQYIyrrLUHvHyZXUrTrMVgskYiIQoFXQdCuXbvw6quv4oMPPkC/fv1w2223YfXq1UhMTAzU+MJGSqwRh0vrgj4TJAYssX4mRTuP0do2QxAEv2eWiIiIAsnjd76hQ4eivLwc8+fPx7Zt2zBy5MhAjivsKNU/TOob5mdStPMYzpeT3SGg0WJHtNH/wIqIiChQPH6XOnToEKKjo/Hmm2/irbfe6vR+586dk2Vg4UapbfJS3zAZlsNMETrotRrYHAJqm60MgoiISNU8fpd6/fXXAzmOsNdaNTrYidEtOUF+Nk8FAI1GgzhTBM41WFDXbENGvN+HJCIiChiP3/kWLlwYyHGEPamJarBngprlmwlyHkePcw0WJkcTEZHqsdKhSii3HOacCZIjMdp5HNYKIiKi0MAgSCWUWg6TMzHaeRy2ziAiotDAIEglxOWwqkYrLDZH0M4r/3IYZ4KIiCg0MAhSiQRTBPQtPcPONgRvNkjOxGigNQhi1WgiIlI7RYOgr7/+GldffTUyMzOh0Wiwdu1at9sFQcDSpUuRkZEBk8mEqVOnetSn7MUXX0SfPn0QGRmJsWPH4vvvvw/QdyAfrVYjzQZV1gWvf5icW+QB1+UwzgQREZG6efTx//777/f4gMuXL/f4vg0NDRg5ciRuu+02zJ07t93tzzzzDF544QX8+9//Rt++ffHoo49i2rRpOHjwICIjIzs85vvvv4/7778fK1euxNixY/H8889j2rRpKCgoQGpqqsdjU0JyrAGltc2oqG8GEJz95WID1ViZgiAmRhMRUajwKAjau3ev29d79uyBzWbDoEGDAAC//PILdDodxowZ49XJZ8yYgRkzZnR4myAIeP755/E///M/mDVrFgDgzTffRFpaGtauXYsbb7yxw8ctX74cv/nNb7B48WIAwMqVK/Hpp5/itddew8MPP+zV+IItJcjb5AVBaJ0Jkm05jInRcmqy2GEy6BQ5t83ugFajgVbL9ifBYrU7IAiAQc9MBQo8i80R9q81j777r776SrpcffXVmDx5MgoLC7Fnzx7s2bMHZ86cwaWXXoqZM2fKNrATJ06gtLQUU6dOla6Lj4/H2LFjsXPnzg4fY7FYsHv3brfHaLVaTJ06tdPHAIDZbEZtba3bRQmtO8SCsxzWZLXD5hAAyLkcxpkgufxw8hyGPb4JL2zpfglYbqfONmDoY5uw9JOfgn7ucOVwCLj67ztw+XPbYLUHb3MEhadP95fgvP/ZgFW7C5UeiqK8DgGfffZZLFu2zK1pamJiIp566ik8++yzsg2stLQUAJCWluZ2fVpamnRbW5WVlbDb7V49BgCWLVuG+Ph46ZKTk+Pn6H0T7FpBYvKyTqtBlEyzDXEuTVTJPzuPnYXdIWDH0UpFzm22OfDe92dwNshlG8JVZb0Zh0vrcOpsIwqrmpQeDvVwn/1UAgBYue0YBEFQeDTK8ToIqq2tRUVFRbvrKyoqUFdXJ8uggu2RRx5BTU2NdDlz5owi4wh21ejWpGi9bB3fxZmgOiZG+62wqhEAUKTAG6L4JmxzCFi3rzjo5w9HZ1x+zuLPnihQDpU4VzyOltfjQFGNwqNRjtdB0Jw5c7B48WKsWbMGhYWFKCwsxOrVq/HrX/+6w+RmX6WnpwMAysrK3K4vKyuTbmsrOTkZOp3Oq8cAgNFoRFxcnNtFCcGeCRKXrORKinYeS+92bPJdUbXzTbG0thm2IC+PiOcGgNV7ioJ67nDl+pwrEfhS+Gi02HCiskH6enUYL4l5HQStXLkSM2bMwPz585Gbm4vc3FzMnz8f06dPx0svvSTbwPr27Yv09HRs2bJFuq62tha7du3CuHHjOnyMwWDAmDFj3B7jcDiwZcuWTh+jJmJidLCqRovJy3IlRTuPFSEdO5ynWOUgzsbYHQJKapqDfO7WmYgDRTX4pSw0Z3lDietzzuUwCqSC0jq4/nn+ZF9xUIv0qolXQZDdbsePP/6Ip59+GmfPnsXevXuxd+9enDt3Di+99BKio6O9Onl9fT3y8/ORn58PwJkMnZ+fj9OnT0Oj0eDee+/FU089hU8++QQHDhzArbfeiszMTMyePVs6xpQpU/CPf/xD+vr+++/Hv/71L/z73//GoUOHcNddd6GhoUHaLaZmyQrNBMmVFO08ljOgstgdMIfpL5UcHA4Bxa4zA9XBfVMUZyKyEkwAwvuTYrC4zv4E++dN4eVgy1LYxQOSkBprRFWjFV8eLld4VMrwKgjS6XS44oorUF1djejoaIwYMQIjRozwOvgR/fjjjxg1ahRGjRoFwBnAjBo1CkuXLgUAPPTQQ/j973+PO+64AxdeeCHq6+uxceNGtxpBx44dQ2Vla+LoDTfcgL/+9a9YunQpzj//fOTn52Pjxo3tkqXVSFwOqzPb0Gy1B/x8YvKynEFQtEEPcUc1l8R8V15nhtXe+lEtmDMDFpsDpbXOmae7LukPAPhob1HQl+TCTSFzgihIxHygYZnxmDMqCwCwek94ftDxeh1k2LBhOH78OPr27ev3yS+55JIul0w0Gg2eeOIJPPHEE53e5+TJk+2uu/vuu3H33Xf7Pb5gizXqYdRrYbY5UFFnRk6vqICeT+4aQYCz8nVsZARqmqyobbIhNVa2Q4eVtm+CwXxTLK1phkMAjHotrrsgG3/9vADldWZ8c+wsJp+XErRxhBsuh1GwHCpxLm8PyYzD4Iw4/PPr4/jqcDnONVjQK9qg8OiCy+ucoKeeegoPPPAA1q9fj5KSElXU1+kpNJrW1hkVQcgLCkRitPN4TI72V9vlkGAmyhZWO9+MsxJMMOp1uGZkJgAuiQWSIAhuP/Oy2uawzdGgwHI4BGkmaHBGHM5Li8XwrHjYHAI+yQ+/TRBeB0FXXnkl9u3bh2uuuQbZ2dlITExEYmIiEhIS3GoHkW+CuUNMSoyWOQiSagVxm7zPxJmAyAit29fBPHdWojMfaN7obADApp9LGdgGyNkGC5qtDmg0zmrRDsE5I0ckt9PnGtFoscOg16JfsjOVZe5ocUks/IIgr9dBvvrqq0CMg1q0Vo0O3kyQnMthrsdjwUTfiYHImNxEfHP0bFATZcVZp+xE53LsiOx4DEiNwdHyeny2vwQ3XtQ7aGMJF+JznhYbiSiDDscrG1BY3YjeSYFdEqfwIyZFD0qLhV7n/JB1zchMPP3pIWkn6Hlp4ZPH4PW73+TJkwMxDmoRzIKJdQFIjHY9Xh1nDXwm5oeM7ZuEb46eRXF1E+wOAbog9PEqlIIg50yQRqPBvNHZ+MvGw1izp4hBUAC4PucmMQhiXhAFQOtSWGugkxRjxKV5qdh8sAyr9xTikRmDlRpe0PncOa2xsRGHDx/G/v373S7kn+Auh4kzQTIHQS61gsg34szA6N6J0Gs1sDkElNUGZ3lEDMDEIAgAZo/KhEYDfH/yHE6f5c4luYnPeVaiSXreGQRRIIhB0JAM96LA4rL32r1FsDvCp8ab10FQRUUFrrrqKsTGxmLo0KHSFnfXre7kOyWWw8REZrkwMdo/rkmyvXtFIbOlVk+wlsTE84g1ggAgI96ECQOSAYTvVtpAEp/z7ESTtAzJqtEUCAeLW5OiXV2Wl4qEqAiU1ZoV6VeoFK+DoHvvvRfV1dXYtWsXTCYTNm7ciH//+98YOHAgPvnkk0CMMaykBHE5jInR6lRRb4bZ5oBWA6THR7rMDAR+BsZmd0jVqcU3Y5H4SXHN3kI4wuiTYjAUuuRhBfPnTeGlutGC4pbf77w2QZBBrw3LnaBeB0Fffvklli9fjgsuuABarRa5ubm4+eab8cwzz2DZsmWBGGNYSYl11mgI5hZ5+ROj2UneH1KSbFwkDHqtNCMTjJmBsjoz7A4BEToNUltmJUXThqYjxqjHmXNN+PFUVcDHEk5cK3RnBXnmj8KHmBSdnWhCfAdpEK47QcMlp9PrIKihoQGpqakAgMTERKmj/PDhw7Fnzx55RxeGUmKc1bAr6ywB7b3VbLVLdUhkzwlqWQ4Ll18iubVNTBZnZIKRI1J4zjn7kJlggrZNErbJoMOVw52NiMPpk2KgCYLglocl/rxLaoLfOJd6NrFIYtulMJG4E9Rsc+CzAyXBHJpivA6CBg0ahIKCAgDAyJEj8c9//hNFRUVYuXIlMjIyZB9guElumQlqstrRYAlc6wxxZ5hGA8QY5M4J4nKYP9rm5GQFMVG2bQDW1tyWT4qfHihBUwBfn+GkutEq/a5nJpiQGmtEhE4Du0OQ2pcQyaGzpGiRuBMUAFbvDo+aQV4HQffccw9KSpwR4mOPPYYNGzagd+/eeOGFF/C///u/sg8w3EQZ9Ig26AAENi9IXAqLMerbfeL3F+sE+ad1ViCq5d/gLY90lBTt6qI+vZCdaEK92YbPD5YGfDzhQHzOU2KNiIzQQavVtCbDMzmaZNRZUrSrcNsJ6nUQdPPNN2PRokUAgDFjxuDUqVP44YcfcObMGdxwww1yjy8sBWObvLQ9XuakaNdjcibIN21nY1xzggKdkNw2AGtLq9VIs0HhWF02EDoqScBt8iQ3q92Bo+X1ADqfCQLcd4Ku2dvzl729DoKOHz/u9nVUVBRGjx6N5ORk2QYV7oKxTV4qlChzPhAAKeGujjNBPilq07YiIz4SOq0GFrsj4KUTupsJAoB5LSX2dxypCFrtop6ssKr9c87kaJLbsYp6WOwOxBr1nS53i6SdoHuKApqbqgZeB0EDBgxA7969ccstt+DVV1/F0aNHAzGusBaMqtHSzjCZawQ5j+kMgppckq/JM84kWfe2FXqdFulxzoT5MwGeGeguJwgAcpOicUFuIhwC8NFezgb5q+3P2/X/3CZPchGXwvIyYrtNgZg2NB3RBh1On2vEDyd79k5Qr4OgM2fOYNmyZTCZTHjmmWdw3nnnITs7GwsWLMArr7wSiDGGneAshzlnaeTuIA8AMS6BFXeIeaeq0YomqzNJNiM+Uro+Kwh5QQ6HgGKxaF+vrntWzRsjJk8W9vhPioEmzb4lciaIAqe7pGhXzp2gzo1OPX0nqNdBUFZWFhYsWICXX34ZBQUFKCgowNSpU/HBBx/gt7/9bSDGGHbEgomBXPoIVI0gANBpNYgxMjnaF+In/9SWJFlRMAroldeZYbU7+5OltakR1NbMERkw6rU4Ul6Pn4pqAzamcNDR7BtzgkhuB0u6T4p2JX7Q+fRACZqtPXcnqNdBUGNjIz7//HP88Y9/xPjx4zFixAjs27cPd999N9asWROIMYad5BBPjHYeV+92HvJMZ8tR2QmBf1MUA6yM+Eipu3Rn4iIjcMXQlppBbKPhF/F5z3ENglpm4oqrA58MTz2fIAjd1ghqy3Un6Kafe+5OUK+DoISEBNxyyy1obm7Gww8/jOLiYuzduxfPPfccZs2aFYgxhh2pdUaIJka7HpfJ0d5pTYp2X44KRj8pT5KiXYkJ0h/nFzH3y0c1TVbpdyTT5XlPizVCp9XAahdQHoQWOtSzldeZca7BAq0GGJQe2/0DED47Qb0Ogq688krY7Xa89957eO+99/Dhhx/il19+CcTYwpa0OyxEE6OdxxVbZ3AmyBsdbZd2/TqQy2EdJeh2ZcKAZKTEGlHVaMVXBeUBG1dPJga1SdEGRLkULdXrtFJOGJOjyV9iUnS/lBi3ZfbuzB3V83eCeh0ErV27FpWVldi4cSPGjRuHzz//HBMnTpRyhch/UmJ0vTlgSaeBXg6L5XKYTzqbjXFNjA7Ua8KTnWGu9Dot5rT8kezpyZOB0lFStIjJ0SSXg14kRbvqk9zzd4J6HQSJhg8fjosvvhjjxo3DhRdeiPLycrz//vtyji1sJcU4W2dY7QJqAhRE1ErLYQGaCTJxJsgXnQUiGfEmaDRAs9WBsw2WAJ3bOePQ0RtyZ8R6Il8VlONcgMbVk3U28+e8Lng946hn8zYp2lVP3wnqdRC0fPlyXHPNNUhKSsLYsWPx7rvv4rzzzsPq1aulZqrkH6NeJxUcDNQOseAlRjMnyFPuNYLc3xQNei3SYsXlkcC8KRZ5ORMEOPMLhmXFwWoXsG5fcUDG1ZN1VChRlBWEJVAKD4ekIMizfCBXPX0nqNdBkBj0vPnmm6isrMSPP/4oBUaJiYmBGGNYEpfEApUUGbzEaM4Eeaq2yYZ6s/PnkpXQPi9H6iEWgCBIEARp2SW7g3N3Ze4oMXmSS2LeKuoiD4vb5EkOjRYbTlQ2AACGZHo/E9TTd4J6HQT98MMP+Otf/4qrrroK8fHxgRgTAUhuWRIL1Db51sToQM0EicthnAny1JmWT/zJMQaYDO2TFwM5M1BRb4bZ5oBWA6S7FGn0xKzzM6HXarC/sAZHyupkH1tPVljd1XIYm6iS/wpK6yAIzr8rqbHe/W6L5vbgnaA+5QRt374dN998M8aNG4eiImey1FtvvYUdO3bIOrhwltLyYg1EEGS1O9BocRa/ig3Q7jAmRnuvuy3qgewmL77RpsVFwqD37s9CUowRlwxKBdCzt9IGQts+ca7EGblAJsNTz+dtfaCOTHTZCbq1h+0E9ToIWr16NaZNmwaTyYS9e/fCbHa+SdfU1OB///d/ZR9guGqtGi1/sqlr7Z5ABUFMjPZed1vUA5ko6+3OsLauHeP8pPjR3kLYWdzPI/VmG6oanb8fHQW+6fGR0GoAs80R0Jph1LN50y6jM247QXvYkpjXQdBTTz2FlStX4l//+hciIlqXUi6++GLs2bNH1sGFs+TYwC2HibMz0QZdt5WBfSUthzEx2mNdzQoArW+UgVgO87ZGUFuX5qUi3hSBslozvjlaKefQeizx5x1viuiwh59Br0VaXGCT4ann82dnmCtxJ+iXh8tR1YN2gnr9DlhQUIBJkya1uz4+Ph7V1dVyjIkQ2KrRgU6Kdh5b33IuzgR5qqvt0q7XF1XJvzxS1JKb4mm16LaMeh2uGZkJoOd9UgyUoi7ygUTMCyJ/OBwCDoszQT4kRbsalB6LoZnOnaCf9KCdoF4HQenp6Th69Gi763fs2IF+/frJMigKbNXoQCdFux6bidGe625JSmyr0GCxo7pR3uDS3+UwoLWeyKafSxn8esCT55y1gsgfp881osFih0GvRb/kaL+PJ84GrelBH3S8DoJ+85vf4J577sGuXbug0WhQXFyMt99+Gw888ADuuuuuQIwxLCUHcCZIXA4LVD6Q67HrzTbY7D1rN0GgtCZGd7wkFRmhk4JjuZOju1uK88TI7Hj0T4lGs9WBDQd6bsNFuUjPeRclCVqrRrNWEHlPzAcalBYrS+qDuBN0X2ENjpb3jJ2gXj8rDz/8MObPn48pU6agvr4ekyZNwu23347f/va3+P3vfx+IMYal1JY3u7P1ZtkTTaWZoAAuh7nmOIi1b6hzdc1WqTp4V4FIIHqIuRdp9C0nCAA0Go00G7SqB31SDBTPZoJYK4h850+RxI647gRdtbtn7AT1OgjSaDT47//+b5w7dw4//fQTvvvuO1RUVODJJ59EUxN/UeXSK9oAjQZwCEBVo7xJaGKycqCapwLOpE5TS6M+Jkd3T5zZSYiKQIyx859La3K0fL9r5xosaLI6SyZkJvhWR0Q0Z1QWNBrg+xPncOYcZy+64kmbkiwGQeQHuZKiXc0b3bN2gvo8P2YwGDBkyBBcdNFFiIiIwPLly9G3b185xxbW9DotkqIDs0OsLggzQc7jt9QKYn5ItwrPeZaTE4gcETEAS401wqj3vMN0RzLiTbi4fzIAYA1rBnVJqtDtQU5QIJLhqecTawT5sz2+rcsGt+4E/fZY6O8E9TgIMpvNeOSRR3DBBRdg/PjxWLt2LQDg9ddfR9++ffHcc8/hvvvuC9Q4w5KUFyRzECQ1Tw1gYrTr8RkEdU/aGdZNy4pAzAzIkRTtal5LzaA1e3tmw0U5NFnsUg2wrpYgxZm5JqudDWoDRBAElNY0o7Cq0eeLGmdEqhstUqCdJ2MQ5LYTdHfoL3t7vB6ydOlS/POf/8TUqVPx7bff4rrrrsPixYvx3XffYfny5bjuuuug0/n3KZLcpcQacbi0TvYmqsFIjHY9PpfDuiclRXc7EyR/1ejWpGjf84FcTRuajmjDTzh1thE/nqrChX16yXLcnkT8+cUa9VKz5I4Y9TqkxhpRXmdGUXUTklo+GJF8lm04jJe/Pu7XMcb27YX3fztOphHJQ5wFyk40dfka88W8Mdl467tT2NiyE7SjOlehwuOZoA8//BBvvvkmVq1ahc8//xx2ux02mw379u3DjTfeyAAoAFICNhMUrOUwzgR5ytPZmOwAFEzsrj6Rt6IMeswYngGgZ3xSDARP8oFETI4OrM0HywAABp0WRr33FwDYdeIcfi6uUfLbaOdQAPKBRD1pJ6jHUwGFhYUYM2YMAGDYsGEwGo247777oNFoAja4cJccG6AgqCnIy2HsH9at7vqGicQ3zbpmG2qarLJ8wvMkN8Vb80ZnY9XuQny6vwSPXzMUkRH8kOTKmyXIrMQo7DldHZBK4eGuwWzDybPODuvfPnKZlILgjSVv78GnB0qwencRhmaqp6l4IJKiRRqNBnNHZ+P/NhVg1Z5CXH9hjuznCBaPZ4LsdjsMBoP0tV6vR0xMTEAGRU6t/cMCNRMU2OWw1qrRXA7rjqdb1KMMeilhXq4qwoVVngVg3hjbtxeyEkyoM9vwecsnbWrVGnh2vwTJqtGBc7ilw3pqrNGnAAhozYH7ZF8RrCqqiSZHz7CuzB3dM3aCevwuKAgCFi1aBKPR+UJpbm7GnXfeieho9yqUa9askXeEYUwsjCd3wcQ6JkarSqPFJiW9erI8kpVowtkGCwqrGv0uhS9XjaC2tFoN5o3OwgtfHsXq3YVSIiU5eTMTxOWwwJFjyWjiwBQkxxhQWW/B179UYMrgNLmG5zOr3YEjZfUAAhcEiTtBdxytxJo9Rbhn6sCAnCfQPJ4JWrhwIVJTUxEfH4/4+HjcfPPNyMzMlL4WLySfgO0OC1piNJuoekL8hB8b2XWSrEjO5OjaJptUzFLOmSAAmNtSYn/7kQqU1TbLeuxQV1Tlea+21qrRDILkdlCGvloROi1mna+uDuvHKuphsTsQY9TLuszdVk/YCerxu+Drr78eyHFQB1ICkBNkdwioMwe+garz+KwT5AlvZ2LkLJh4puXNODnGAJNB3rydPsnRGJObiN2nqrB2bxF+O7m/rMcPZd78zF1rQwmCwDxMGcmVPDxvdDZe3XECXxwsR3WjBQlRhu4fFECulaK12sC9XnrCTlD/m4lQwIhBUFWjVba15nqX/JxAzwQxMdozhR4mRYtcC+j5q3VrvnxLYa7Ehour94TuJ0W5mW12lLd8sPFo+bPldVFvtnFWVUZ2h4CCUrGYoH9tJYZkxmFwRhwsdgfW7y+RY3h+OVgcuKRoV647QUO1qSqDIBVLMEVA1xLFn62Xp1CaOCsTGaH1uzpwd8SZJiZGd83bLepSjogMTTWlGQmZl8JEM0dkwKDX4peyevzc8oc53BVXO5cGoww6JEZ1PxtrMuiQHOOcWTjDHWKyOXW2AY0WOyIjtOib7P8mH7GdhBqWxAJRKboz4ged9ftK0NzSfieUMAhSMa1WI/3xk2tJTAyCglHcSiqWyOWwLhV5WbFZzqrRctcIaiveFIErhjgTRVexZhAA9+fc06WtrAC0Swl3YqAwKC1W+rDpj1nnZ0Gn1WDv6Wocq6j3+3i+EgQhoDWC2gr1naAMglROXBKTa5t8MJqnirgc5hlv21aIyyPVjVYpqdlXrdWiA5g82fJJ8ZN9xbDY1LOFWClFPpQkyGZytOwOljiLG/q7w1KUEmvE5PNSACi7NFReZ8bZBgu0GmBQujzd47ui1WowV5wFC8EPOgyCVE7uqtHBqhbtPEdLnSCzDQ4V9tZRC28To2MjI6RdZP7mBcndN6wjEwcmIyXWiHMNFmwtKA/YeUKFLyUJWrfJczlMLuJMkLwd1p0B/0d7ihT7myfueOuXEhO0IqWuO0HLQ2wnKIMglZO2ycs2E9QSBAVhOUw8hyAA9RbmBXWk2WqXZvm8mhmQtsn796bYWqk6MInRAKDXaTH7fGedIHaW97xPnKssFkyUXSCWjKYMTkVcpB7FNc347vhZ2Y7rjWAlRbvq27IT1CEAa/ND63ecQZDKyb1NXiqUGISZoMgIHQwtvXWYHN0x8Q0x2qBDggdJsiI5tsnXNltR0xIUB3I5DHA2XASALYfLUBXm3dB9ycNiwUR5VTVYUFLjnLHIk3HJKDJCh6taCoOuUmhJLNCVojsj7QTdXRRSO0EZBKmc3FWjWxOjA58TBLTmHjEvqGOuOTne1H/JliFRVjx3YlQEYoyBfT3kpcdhSEYcrHYB6/YXB/RcaudLmxJxpo7LYfIQA4XevaJk3yQiBgMbfypFg585e75wrREUTOJO0IKyupDaCcogSOXkrhodrOapIiZHd83XlhVy9JMKRlK0K3E2KBSTJ+VisTmk6tne/MzFn1Fts427LWVwMICzJaN7J6BvcjQaLXZs+Cm4HdabLHacqHQ2hA32TFC8KQKXh+BOUAZBKif77rAgNU8VxZrE/mFcDuuIr1vUs2RIlJXOHcB8IFezzs+EXqvBvsIaHC2vC8o51aa0phkOATDqtVL5C0/EGPVSTSHmBfkv0B3WxZpBwd4lVlBWB4fgrAAvvncE07UuO0HV1Ey2KwyCVE7unKBgJkY7z8PlsK4UeVktWiRH/zBfEnT9kRxjxCWDnFuIV4dpgrRY4NLb5U/xMQCDIDm07gwLzJLR7FHOIGjn8bNBLWvgmhStRHsV952gFUE/vy9UHwTV1dXh3nvvRW5uLkwmE8aPH48ffvih0/tv3boVGo2m3aW0NLjTknIRl8Pqmm2yVOMMZmK063nqOIXfIZ+Xw1pmbyrrLWiy+Pa6CMb2+Lbmumwhtodh2QRff95A68+ceUH+sdgc0kykXDWC2spOjMK4fkkQBOCjIM4GKZUULXLdCRoqy96qD4Juv/12bN68GW+99RYOHDiAK664AlOnTkVRUdefJAsKClBSUiJdUlNTgzRiecVF6qUdVnLMBimWGM3lsA75mpcTZ9IjtiWZ2ddt8v68IftqyuBUxJsiUFrbjG+PVQbtvGrhS1K0SM5K4eHsaHk9rHYBcZF6n34OnpJy4PYEb7dUMCtFd0b8oBMqO0FVHQQ1NTVh9erVeOaZZzBp0iQMGDAAjz/+OAYMGIAVK1Z0+djU1FSkp6dLF61W1d9qpzQajVQwUY68ICkniInRijPb7CirE5NkvftjrNFo/H5T9HUpzh9GvQ5Xj3Q2XAyVT4py8rZFiis5lkCpNR8oL8BLRjOGpcMUocOJygbsOV0dsPOIHI7gtsvozOCM1p2g60NgJ6iqIwObzQa73Y7IyEi3600mE3bs2NHlY88//3xkZGTg8ssvxzfffNPlfc1mM2pra90uapIsY16QuDssPkiJ0XFSYjSDoLZKqpshCM5mtknRnifJivypHdNoseFcy6e0YOUEiaQtxD+X+t32I9T406tNjrIIFLwlo2ijHjOGpQMIToL0mapGNFjsMOi16JcSHfDzdUWcBVsVArl/qg6CYmNjMW7cODz55JMoLi6G3W7Hf/7zH+zcuRMlJSUdPiYjIwMrV67E6tWrsXr1auTk5OCSSy7Bnj17Oj3PsmXLEB8fL11ycnIC9S35JEWmqtGCIEi5OcFOjGaxxPZcZ2J8+UQqvin6MjMgzkjERuqlFhzBcn5OAvolR6PZ6sBnBzr+Pe6pxJ+VL0FQFvuHySKYeTNiMLBuX3HAO6yL39d5aTGI0Cn71j7r/EzotBrsO1ONo+XKNZP1hKqDIAB46623IAgCsrKyYDQa8cILL+Cmm27qdHlr0KBB+O1vf4sxY8Zg/PjxeO211zB+/Hg899xznZ7jkUceQU1NjXQ5c+ZMoL4dn0jb5Ov8W19tsNgh5qIGOzGaM0Httc4K+JaT40/VaCXygUQajSYsawbZ7A6pSrEvz7s4Y3euwaJIEb6eQBCE1hpBAUqKdjWuXxIy4yNR22zDlkOB7Zsn7gxTKinaVXKMEZecJ+4EVffvuOqDoP79+2Pbtm2or6/HmTNn8P3338NqtaJfv34eH+Oiiy7C0aNHO73daDQiLi7O7aImrVWj/WtMJ+blROg0MOqD86OPlbbI8492W/4WK/SnqaY/yzJymDMqCxoNsOvEOZw5Fx67nUprm2F3CDDotNLsrjfiTRHS7xNng3xTWtuM6kYrdFoNBqTGBPx8Wq0Gc8QO6wEOBg4GoCGsP8QPOmrfCar6IEgUHR2NjIwMVFVVYdOmTZg1a5bHj83Pz0dGRkYARxdYKS1F1fzNCXJNig5WDQkpMZozQe34u0Xdn7oxhQokRbvKTDBhfP8kAOHTVFX8OWUmREKr9e33T1oCZV6QT8TZkv4p0UHvsL7tlwrZ6r11RA1J0a5cd4LuPKZMM1lPqD4I2rRpEzZu3IgTJ05g8+bNuPTSS5GXl4fFixcDcC5l3XrrrdL9n3/+eXz88cc4evQofvrpJ9x777348ssvsWTJEqW+Bb+1Vo32bzlMapkRxBwQaTmMu8PaKaz2b0lKfFx5ndnrfAMlagS1JSZIr9lbGFINF30lxxKkP7N/pEwdnf4pMTg/JwF2h4CPA9RhvabRKs0OqiUIctsJquIlMdUHQTU1NViyZAny8vJw6623YsKECdi0aRMiIpxvriUlJTh9+rR0f4vFgj/84Q8YPnw4Jk+ejH379uGLL77AlClTlPoW/CZX1ejWpOjg7AxznksslmgLizc6bxT5UTMGcDY+jTI4P82KuSbenlvJIGja0HREGXQ4dbYRu09VKTaOYJGjJIGUB8blMJ8cUmjJyLVmUCAcKnUGd1kJpqBvdOiKazNZte4EVX0QdP311+PYsWMwm80oKSnBP/7xD8THx0u3v/HGG9i6dav09UMPPYSjR4+iqakJZ8+exVdffYVLL71UgZHLR64mqq19w4I5E+QMuGwOAU0B3h0RSqx2B0pqnG9kOT4GIhqNxiU52ruZASUTo0XOLcTq/6QoFznysPwpi0AIalK0q6tHZMCg0+JQSa20JCcnKSk6yN9Xd8SdoE1Wu2p3gqo+CKLWIKjJavdrV4i4HBasatEAYIrQQdeS/8Dk6FZiI02DTiv9fH3hSzf5ZqtdKrypVE6QaN4YZ9Lo+n0lAd9CrLRCPxPhAQZB/mgw23DyrLPDerBnghKiDJg6xNm1IBABv9rygUSuO0GD3UzWUwyCQkC0UY/olmUPf2aDgt08FXD+ErS2zmBekMj1DdHXJFnx8a7H84S4LBNt0CEhStmp81/1TUJWggl1Zhs+P1im6FgCrcjPHDDXxzIx2nuHS+sgCM70An8+ePhq7ihnMPBxfhFsMndYl2a4AtQQ1h/iTtDvjqtzJyiDoBAhVY32o2CiEsthrudjcnQrf4rmuWqtIuz5HxfXpTAlOk270mo1mNPScVutnxTl4HAIKJbhZy4+trLe+2T4cKd0c9HJg1KQFG1AZb0FXx+Rr8O61e7AkTJnQcIhGfHd3Dv4XHeCfrRXfTtBGQSFCKl/mB8zQVIH+SAuhznP15ocTU5i0OLvcpQv/aT8rU8kt7ktdVS+/qUC5bX+1cJSq/I6M6x2AXqtBmlxkd0/oBPxpghpVpi1gryj9JJRhE6LWee31AzaLV8wcLyiARa7AzFGvaIbHboizoKt2aO+naAMgkJESkjPBHE5rC25tqj7UjVa6UKJbfVLicHo3glwCMDaAG0hVpr4nGckREo5cr7QaDTsIeajg1IQpNySkZgDt/lgGWoa5fl7eLCkBoDz+/JnaT2Qpg9z7gQ9ebYRe06raycog6AQIccOMSUSowEg1sjlsLbkmo0R3xDLapthsXmWZ6BE9/jutLbRKFLdJ0U5FPpZDsFVFmsFec3uEFBQ6tweP1TBHVRDM+ORlx4Li92BdTJ1WFdq2783XHeCrpJxFkwODIJChBy1gmqD3DxV1DoTxOUwUWG1f33DRMkxBhj1WjgE544zj86tgu3xbV01PBMGvRYFZXX4OQBbiJUmR1K0yJcdgeHu1NkGNFrsMOq16JOkcIf10fLulhK3x6s5CAJcdoLuD3wzWW8wCAoRrVWjZdgdFuzlsEjOBLmyOwSUVDsDFn9nBjQajdczA2pbDgOA+KgIXD44DUDPrBkkVw6Y6zG4HOY5cbYkLz0WeqU7rI9ydljfc7oaxyv867AuCILiCd+eknaCNtuwWUU7QRkEhYgUGZbDWhOjFdodxpkgAM6lK5vD/yRZkTdVhM02O8pbXkNqSYwWiZ8UP8kvhlXmLcRKk7NNibRNnonRHlM6KdpVamwkJg1MBuB/37yKOjPONlig1QCD0tW3Pd6V605QNX3QYRAUIpL9XA4TBMElMTrYu8OYGO2qUGqkafIrSVbkTaJsSXUzBAGIjNAiKdrg97nlNGlgCpJjDDjbYMHWAvm2EKtBkYxLkOwf5r2DKgqCAJcO63uL4PCjw/rPLd9Xv5SYoDWE9YfbTtA6dewEZRAUIlybqPqSONpsdcBqdz4uNsgzQbFcDnNTVC3f0gjgXY6Ia1K00jWC2tK7bSFWzydFfwmCIFtdKKB1Bq+8zgyzTT25FWp2SKF2GZ2ZOjgNsZF6FFU34bsTvndYV9MMlydcd4J+vFeexHB/MQgKEckxzk/tFrvDp/YT4iyMVgOpzkiwcDnMXeE5eZuXejMz0JoPpJ6kaFdi0uiWw2WobrQoPBp5VNSbYbY5oNUA6fH+L38mRRsQGaGFIEDKLaPOVTVYpAbDeSpZMoqM0OGqEZkA/KsZ1LozTB3flydam8mqo2ZQcNdFyGdGvQ5xkXrUNtvwc3ENeid59yZ26qzzzS/OFBH0GQBxOawuRGeCmq12WaeapdkY2YOg7meC5MxNCYQhmXEYnBGHQyW1WLevGLeM66P0kPwmPufpcZGIkCEpV2yce6yiAYVVTeiTrOxuJzkIggCrXYBBL//ncnG2pHevqKDPgnfl2jFZePf709jwUwmWXNrfp+/95yJnjSC1J0W7ump4Jv607iAOlzp3gg7LUrbKNYOgEJISa0Rtsw3zX9nl8zGCXSMIaJ0Jqmp0LuWpbRmmK5/uL8GSd/bg6TnDsGBsrizHlHuLelaC8ziltc2w2R1d7n5RW7XojswbnYWnPq3Fqj1FPSIIkjMfSJSdGIVjFQ3S0mqoe3DVfnz+cyk+uXuC7EGdGookdmR070T0SYrCybONuOzZbX4dK5SCIHEn6KcHSrBmT5HiQRCXw0LI3NHZiDLoYNRrfbqYInSY05JzEUy9e0UhMkKLqkYr8s9UB/38/nj562Mt/x6XbepWzvwQAEiNNSJCp4HdIaC0m7YTaqwR1Nas87Og02qw70w1jpb7t4VYDQIx+9aTusk7HAI2/lSK2mYb3vn+tOzHV1tStEij0eD3lw1EbKTe57/pRr0W04emSzmjoWLeGOfvuBo2y3AmKIQsuXQAllw6QOlheC3aqMf0oelYm1+M1XsKMap3otJD8sjR8jrsK3RON58624gfT1Xhwj69/DqmwyG0zsbIlBit1TqXR06ebURRVVOXAY4aq0W3lRJrxOTzUvDl4XKs2VOIh6bnKT0kv0iJ8DIGQVk9qGBiYVUT6s3OfMGP9hbhoWmDZK3lI+bNqHG2ZN6YbClHJpxMGpiCnY9chtRY/3Pk/MWZIAoK8Rd93b6SkNnRsrpNDQ85KrxW1JthsTug02qQIUOSrCjLg5kBq92Bkhrn7TkqXg4DWhOkP9pbBLsfW4jVIDAzQT2nf5jY+wpwlgDZcbRStmNbbA4cLVd/W4lwo9dpVREAAQyCKEjG909Gelwkapqs2HKoXOnhdMvuEPBRSxC0aHwfAMD6fSV+l3t3TZKV89NudkL3b4qlNc1wCIBBr5V60anVlMGpiIvUo6SmGTuP+b6FWA1a+4bJtwTZWjU69HOCDrbM1Ijafvjwx9HyeljtAmIj1dthnZTFIIiCQqfVYM7o0KkB8+2xSpTWNiPeFIGHZ+Q5y72bbfjcz3LvUvsEmf8gS8sjXSTKujbxVGu3aVFkhA5Xj2zZQqyi6rLeEgTBJTFavp+5OJNXWtsc8tW1xd5Xc1uqCX/+c6lsuSKudXRCaUMGBQ+DIAqaeS1B0NZfKvzqgRYMYqB29cgMREbopEqn/gZwcidFizxJlFVjz7CuzG1ZEtv4U6mUMxJqzjVY0GS1Q6MBMhLkm/5PjjHC4GXjXLUSA5XrL8zBwNQYmG0OfLq/RJZjHwyRvlqkHAZBFDQDUmMxMjsedoeAj/PVUS20I/VmGzb+XAqgNTdFfEPefqQC5d3swOqKlB8ic2KyuDzSVT+pUEiKdjW6dwL6JkejyWrHhgPyvCkGm/icp8YaYdTLV2tKTIYHQjsvqKbJKj1HgzPipNxBuTqsh0pzUVIOgyAKKqlaqIqXxD47UIJmqwP9UqJxfk4CAKBvcjTG5CbCIQBr833PWQjUFvXsXs7jFVc3ddqLSO2FEtvSaDTS7GGoLokFsiRBT+ghJgYpWQkmxJsiMGdUFrQa4IeTVTh1tsGvY7t2WGdSNHWGQRAF1dUjMhGh0+BgSa30B0ptxABt3uhstzwCcVZo9e4in2sGFQUoJygt1gi9VgOrXZC6xLc/t/oLJbY1Z3Q2NBrgu+PncOZc6L3ZSzlgAZh96wkzQW2DlLS4SFw8wNlh3d8E6dLaZlQ1WqHTajAwLca/gVKPxSCIgiox2oApeWkA1DkbdOZcI3adOAeNBpgzyr2w5MwRGTDotSgoc5Z795bcjTRd6XVaqS9VZzMDhdXq7hvWkawEE8b1SwLg3C4fagKRFC2SGud2sQSqdmJStGtj02tdlsT86bAuBlj9U6JDosM6KYNBEAWdmGS8Nr8YNpXtbFnT8ulzfP8kZLb59B5visDlQ1oCOB+WZ842WNBsdTiTZOMD96bY0cyA3SFIzTZDZTlMJOZjrVFJw0VvBHY5TCyLEHozZKJDpWLOTmtLiyuGpCPGqEdhVRN+OHnO52OLARaXwqgrDIIo6C4ZlIpe0QZU1pux/Yh8hdH8JQgC1uxtXQrryLUt13+SX+z11mTxDTEtNjIgjSLFOjQdzQyU1TbD5hCg12pUU6TMUzOGpSPKoMPJs43Yc7pK6eF4Re5mua6yQnwmyGp34JcyZ1uUIRmt/aNMBh1mDs8A4F8umJorRZN6MAiioDPotbimpQbMKhUlvO4+VYVTZxsRbdBh+rD0Du8zcWAykmOMONtgwdaCCq+OH+gt6l0lyooBWGaCCTqV1whqK9qol34eq3aHzpKYIAgBTUYXj1lS3ay6GVVPHK9ogMXmQIyxfSFDcQPFZwdK0WTxrUApk6LJEwyCSBHiuv/mg2WoaVS+iR7Q+qlzxvAMRBk6bqun12kx+/yWIn5e5jQFOjG5q+UwqX9ViGyPb0ucgVu/v9jvqt3BUtNkleobBeJ5T42NhF6rgc0hoKyTZHg1E4OUvPTYdsU7L8hNRE4vE+rNNmxqKVfhjUaLDSdadpcxCKKuMAgiRQzNjMN5aTGw2Bz4VAU1YJqtdqzf5xxHZ0thIvFT6pbDZahqsHh8jkBvUe+qqWbhudDaHt/Wr/olITM+EnXNNnxxyL+q3cEi/ryTY4wBSczVaTVS3looNlKVChlmtg9StFoN5o5q2Y3pw2zx4dI6CIKzGW+odVin4GIQRIpw1oDx/Y+c3DYfLEOd2YasBBPG9u26U/zgjDgMyYiD1S5g/X7Piz627gwLzO6sHDFRtoNaQYFM0A0GbYi1XQGCU5cplGsFdbdcJf59+OZopddVsZkUTZ5iEESKEQuj7T5VhROV/hVG85cYiM0dneVRXy1xNmiVF7VMAlkzBgDS4yOh1Tg7Z1c2uC+PBDJBN1jEXWJfH6lEeZ36W0UE4znPCtGZIEEQug1UeidF4aI+veAQvC+PwErR5CkGQaSY1LhITByYAkC+Mvm+KK9txte/OJOc53azFCaadX4mdFoN9p2pxtHy+m7vH6hGmq4idFqkx4m1gtzfFEOtb1hH+qfEYFTvBGfblb3qbbsiCsZz3rpNPrSCoIo6M842WKDVAIPSYju931yXiuHelEdonWXq/NhEAIMgUlhrr6Aivwqj+WNtfhEcAjAmNxF9k6M9ekxyjBGXnOcM4DxZzqtutKKhZZdL2/pDcuooL8jhEFDcUiMoVBOjRWpaQu1OoPrEuRJ/3mIhzFAh5gP1TY6GydB5vtSVIzJg1GtxtLweB4pqPDq2wyHgcCm3x5NnGASRoq4YkoZYox5F1U3YdcL3wmi+EgQBq1u2XYufOj0lBnBr9xbB3k0AJ74hpsQGJklW1NHMQEW9GRa7AzqtBhnxoVUjqK2rRmTAoNPicGkdfi727E1RKUVByMPK7iIZXs2kGj6Z8V3eLy4yAtOGOssjeJoLdupcIxotdhj1Wo8/1FD4YhBEioqM0GHmCP8Lo/nq5+JaFJTVwaDX4qoRmV49dsrgVMSbIlBS04ydx852ed9gbVHvKFFW/H96XCT0utD+lU+IMmDqkFQAkIJXtSoMUJ84V+Lrqbi6WbGZVF8c9GK5Svyw8cm+Ylhs3ddDEnONBqXHhvzrnQKPrxBSnPhHbsOBEjRabEE9txh4XT4kDfGmCK8ea9TrcPVIzwK4YHVwlxJlXaoIF4Zg49SuiEtiH+cXeV21O1hqm62obQ5cjSBRRnwkdFoNLHYHKupDp1aQN4UMJwxIRmqsEVWNVnx5uNzzY6dzKYy6xyCIFHdBbiJyk6LQYLFj40/eF0bzldXuwCf5zgTbaz1MiG5LTKTe+FOpVBivI8Haot7RcliwArBgmXReCpJjDDjbYJES2tVGXJ7qFW1AtLHjwpty0Lslw4dGXlCz1Y7jFc7NBEM9CIJ0Wo3UzNiT2eJDXdQfImqLQRApTqPxrzCar7YWVOBsgwXJMUZMHJjs0zFG5SSgX3I0mqx2fNZF0cdgzca4JkaLu2mk+kQhnhQtitBpMet8z98UlSBVBw/Cc57VRaVwNSoorYNDAJKiDR4XMhRni786XI5z3RQoPch2GeQFBkGkCmJS8rfHzqI4SA0hxW35s8/P9Dl3QKPRuOxw6/wNOVhb1DMTnLMCTVa79GYR6oUSOyK+Xr44WI7qRs+rdgdLMEsSdNUuRY1cZ2o0Gs/62J2XFovhWfGwOQR8kt95LlhVgwUlLYUV87g9njzAIIhUIadXFC7q2wuCD4XRfFHdaMGWQ878AjGI8dXsUVnQaIDvjp/DmXMdL0kEazbGqNchLc756Vp8UwxGgm6wDc2MR156LCx2B9btV77tSluFQZwJEl9ToRIE+TpT01ozqPO/D2KAldPLhLhI73L8KDwxCCLVuNalBow3hdF8sW5fMSx2B4ZkxPk9bZ6VYMK4fkkAOg7gapqsqBOTZIMQiLgmRwejSKNSxCa8amyj0doiJRgzQVFu51Q7XwsZXjMyE3qtBgeKavBLWV2H9znIpGjyEoMgUo0Zw9MRGaHF8YoG5J+pDui5xHYX/s4CicQdS2s6CODEICQp2tBpd3o5tSZHN6Ky3gKzzQGNBsiI71lB0DUtVbvzz1TjWEX3VbuDKZhLkKHUP8zhEFprBGV0XSOoraQYIy7NaymP0MnSc2v9IQZB5BkGQaQasa6F0QKY8Hq0vB77zlRDp9XgmpHe1QbqzPRh6Ygy6HDybCP2nK5yuy3Yy1GuydHi7EBabCQM+p71654aG4lJLQntSrZd6Ugwe7V1lAyvVoVVTag322DQadEvxftChuKHjc4KlDIpmrzVs/4qUsgT/8it21cCs80ekHOIb5iXnJfi8e6U7kQb9ZgxzFkzaFWbIn7B3qLumijbE3qGdUWcyftIwbYrbTWYbVJSejCCoIx4EzQawGxzoLJefUnirsQgZWBaDCJ82IxwWV4qEqIiUFZrxo6jlW63WWwOHC1nuwzyDoMgUpWLByQjPS4SNU1WfHmo+8Jo3rI7BClvR66lMNG8lsTN9fuL0WxtDeCkWYEgbVHPSnANgnpWocS2pg5OQ1ykHsU1zdh5vOuq3cEi/rzjIvVBSc416LVIiw2NWkEH/ezubtBrpdnbtrlgR8vrYbULiI3U99ign+THIIhURafVYLYXhdG8tfPYWZTUNCPeFIEpg1NlPfav+iUhK8GEumYbNh8sk65vnY0JzhZ110TZnj4TFBmhw1Xim6JKlsSC0TOsLamHmMqTo72pFN0ZcbZ408+lqGu2tj92uudb74kYBJHqiDMqWwsqUClzKwDxjfLqkRkw6uVtZKrtpLJtMHcKuZ6n3myT+ij1pBpBbc1zqdrd0EXV7mBRIvAMlVpBclRzHpEdjwGpMTDbHG4FSlkpmnzBIIhUZ2BaLEZki4XRimU7br3ZJrXlmOtjm4zuiLVMvv6lAuV1zqJtwV6SiozQITnGAADYX+jstB6spTgljO6dgL7J0Wi02LEhiG1XOlMYxKRokWtytFrVNFml3wV/trBrNBop8HVtoutNU1YiEYMgUqV5o+Vvo7HhQAmarHb0S47GqJwE2Y7rql9KDEb1ToBDAD7eW4x6sw3Vjc4p+2AGIlktMz+2lmThnrocBohtV1pm4FRQM0iJCt2uZRHU6nBLkJKVYEJ8lH+5UrNHZUKjAb4/eQ6nzzZCEARZltoo/DAIIlW6ZmQmInQa/Fxci8OltbIcUwyo5o3JDmjOgGsAJ74pxZsiEBvECrZtK1Nn9uCZIACY0zIDt/P4WcUDgWBWixZlhUDVaDm3r2fEmzBhQEt5hL2FKK1tRlWjFTqtBuelcSaIPMcgiFQpMdqAy8TCaDJ8uj9zrhHfHT8HjQZS3k6gXD0iEwa9FodL67D5Z2eCdLBnYlzPlxJrRGSEvPlPapOdGCVV7V4bhLYrXVGiQrdrYrRaawVJOTsyLVe1FigtknLf+iVH9/jXOsmLQRCplvhH7qO9xbDZHX4dS9wWP75/UsBnReKjInD54DQAwCs7TgBQNgjqyUthrsSSB6v3FCkWCDRb7VIyf04Ql8PE13SjxY6qRms391aGWM1ZruWqaUPTEW3Q4fS5Rry58xQAJkWT91QfBNXV1eHee+9Fbm4uTCYTxo8fjx9++KHLx2zduhWjR4+G0WjEgAED8MYbbwRnsCSrSwalIjEqApX1ZmxvUxjNG4IgSAUS544KTEJ0W2KCdE2TmA8U3N1Zrkm5PTkp2tX0YekwRehworIBe05XKzIGcSdgjFGPOFPgW6SIIiN0UuFPNSZH2+wOFJTJ29LCZNDhyuHOAqXbfqkAwHwg8p7qg6Dbb78dmzdvxltvvYUDBw7giiuuwNSpU1FU1PGU94kTJzBz5kxceumlyM/Px7333ovbb78dmzZtCvLIyV8GvRazzvc/4XXP6SqcPNuIKIMO04elyzW8Lk06L0XaoQUoMRMU1eH/e7IYox4zWn6+SrXRcK0OHuxaNWruIXa8sgEWmwPRBp2sM2RtC54yCCJvqToIampqwurVq/HMM89g0qRJGDBgAB5//HEMGDAAK1as6PAxK1euRN++ffHss89i8ODBuPvuu3HttdfiueeeC/LoSQ7iktjnB8twtLwOhVWNXl/e2XUGADBjWAaijcH5dB6haw3ggOBXbHad/emp1aI7Ir4prtvnXrU7WKQ+cQrMvqk5OVrM2RmcEQetVr7g8KI+vdw+YLBdBnkrePO1PrDZbLDb7YiMjHS73mQyYceOHR0+ZufOnZg6darbddOmTcO9997b6XnMZjPM5taifLW18uxGIv8Ny4rDeWkx+KWsHlOXf+3XseaNCWxCdLvzjc7GqwrlBEUb9UiMikBVozVscoIAYFy/JGTGR6K4phlbDpVj5oiMoJ7/9DnlKnSLM36nzjUE/dzdCdT2da1Wg7mjs/HCliNIjjHK1guQwoeqZ4JiY2Mxbtw4PPnkkyguLobdbsd//vMf7Ny5EyUlJR0+prS0FGlpaW7XpaWloba2Fk1NHX9CWrZsGeLj46VLTk6O7N8L+Uaj0eDuywYiNlIPo17r82XiwGT8qm9SUMc+JDMO80ZnY8KAZEW27V5/QQ7y0mMxJjcx6OdWijbAbVe6IggCPm/ZDTg8OyGo5waA83PiAQBfHCzvsMO6kgLZ3f3msb0xNDMOi8bnyn5s6vlUPRMEAG+99RZuu+02ZGVlQafTYfTo0bjpppuwe/du2c7xyCOP4P7775e+rq2tZSCkIteMzJSaJoaaZ68fqdi5H7lyMB65crBi51fKvDHZeGnrMWz7pQIVdeagzQ7sOV2NE5UNMEUEL/fM1aV5qYg3RaC0thnfHqvExIEpQR9DZwLZ0iI1LhKf/r+Jsh+XwoOqZ4IAoH///ti2bRvq6+tx5swZfP/997BarejXr1+H909PT0dZWZnbdWVlZYiLi4PJ1PEUtdFoRFxcnNuFiEJT/5QYnJ+TALtDwMf5wasZJM48zRiWjpgg5Z65Mup1uHqkc/lPDZWzReV1zaist0CrAQaxkCGpjOqDIFF0dDQyMjJQVVWFTZs2YdasWR3eb9y4cdiyZYvbdZs3b8a4ceOCMUwiUgHXmkHB0Gy1Y/2+YrdzK0FqJvtzKepV0EwWaE2K7pscDZOBhQxJXVQfBG3atAkbN27EiRMnsHnzZlx66aXIy8vD4sWLATiXsm699Vbp/nfeeSeOHz+Ohx56CIcPH8ZLL72EDz74APfdd59S3wIRBdnVIzJg0GlxqKRWehMOpC2HylHbbENmfKRUuVoJ5+ckoF9KNJqt7h3WlSR3kUQiOak+CKqpqcGSJUuQl5eHW2+9FRMmTMCmTZsQEeHsw1RSUoLTp09L9+/bty8+/fRTbN68GSNHjsSzzz6LV155BdOmTVPqWyCiIEuIMmDK4Ja2K0FIkBbPMXtUlqxbwL3l3mFdHUtibGxKaqYR1NpoRkG1tbWIj49HTU0N84OIQtQXB8tw+5s/IjnGgO8emQK9LjCf+SrqzPjVsi2wOwRs+cNk9E+JCch5PFVc3YSL//IlBAHY/tClyOmlbLHMqcu34Wh5PV5ffCEuHZSq6Fio5/P2/Vv1M0FERL6YPCgFSdEGVNZb8PWRioCd5+P8ItgdAs7PSVA8AAKcfcTG93cuyX2kcDPZZqsdxyvqAbCQIakTgyAi6pFcq3av3h24YEBMvlYyIbqt1g7rhYp2lf+lrA4OAegVbUAqCxmSCjEIIqIeS2xku/lgGWoC0F39YHEtDpXUwqDT4uogV6fuyrSh6Ygy6HDybCN2n6pSbBxiUvqQjLig91Ij8gSDICLqsYZmxiEvPRYWuwPrDxTLfnwxIXrK4FQkRBm6uXfwRBv1mDGspWaQQs1kAdekaNYHInViEEREPVYgd0tZ7Q6pGKN4DjURe+Wt31eiSDNZoLVdRiAqRRPJgUEQEfVos0ZlQqtxtrUQk3TlsP1IBSrrLUiKNmDyIPW0qBD9qm8SshJMqDPbsPlgWfcPkJkgCDjMGkGkcgyCiKhHS42NxKTznEHKGhkrSIvJ1rPOz0JEgLbf+0Or1WCOQs1kAaCwqgl1ZhsMOq0qds0RdUR9v7lERDITl6s+2lsEhwwd1msardLsiph8rUbi2L7+pQLltc1BPffPLUnRA9NiVBkkEgEMgogoDFw+JA2xkXoUVTfhuxNn/T7euv3FsNgdyEuPxVAV57v0S4nB6N4JcAjA2iA2kwVYKZpCA4MgIurxIiN0uGpEJgB5agaJy0vzRmerfuu31Ex2d1FQawZJSdEMgkjFGAQRUViY17I0tOGnEjT40WH9eEU99p6uhk6rwaxRmXINL2CuGp4Jg16LgrI6aYkqGDgTRKGAQRARhYUxuYnokxSFRosdG38q9fk4YnL1pIHJSI2NlGt4ARMfFYHLB6cBCF6CdE2TFYVVTQA4E0TqxiCIiMKCRqPBXLGdxF7fggGHQ5D6cc1VYW2gzog1gz7JL4bV7gj4+Q63zAJlJZgQHxUR8PMR+YpBEBGFDXHL+LfHzqK4usnrx393/CyKqpsQG6nH5UPS5B5ewEwamILkGAPONliwrSBwzWRFrBRNoYJBEBGFjZxeURjbtxcEwbcO66talpOuGpGJyAid3MMLGL1rM9kgLIkdYpFEChEMgogorLTulvKuw3qD2SblEl07Rr21gToj1kracqgc1Y2WgJ6LO8MoVDAIIqKwcuXwDJgidDhe2YD8M9UeP27jT6VotNjRJykKo3snBm6AATIkMw6DM+JgsTuwbp/8zWRFNrsDBWWcCaLQwCCIiMJKjFGP6cPSAXi3NCTed24I1AbqjFgmYJWM7UPaOl7ZAIvNgWiDDr17RQXsPERyYBBERGFHXBpat68EZlv3HdaLqpuw87iz0rSYXB2KZp2fBZ1Wg31nqnG0XL5msq7EpOi8jDhotaEZLFL4YBBERGFnXP8kpMdFoqbJii2Hyru9/9q9RRAE4Ff9eiEnhGc3UmKNmCw1kw1MgvRB7gyjEMIgiIjCjk6rwZyWpaHuggFBELB6d2ubjFDn2kzWLkMz2bYOFotJ0fGyH5tIbgyCiCgsicHA1oIKVNabO73f3jPVOF7ZAFOEDjOGZwRreAEzZXAq4iL1KKlpxs5j/jeTbat1ezxngkj9GAQRUVgakBqDkTkJsDkEfJzf+W4pcRZo+rB0xBj1wRpewERG6HD1SGfPM7mXxMrrmlFZb4ZWA+Slc2cYqR+DICIKW+JuKTHQaavZape2k/eEpTCR2PJjw0+lqPejmWxb4ixQn+RomAyhU0ySwheDICIKW1ePyESEToODJbXSriZXXx4uR22zDRnxkRjXP0mBEQbG6N4J6JscjSarHRsOlMh2XHaOp1DDIIiIwlZitAFT8pw9wDpaGhJniOaMcm4t7yk0Gk3rLJiMS2KtSdEMgig0MAgiorAmttH4aG8xbC4d1ivqzNj6i7PZaCh1jPfUnJbv6bvj53DmXKMsxzzEdhkUYhgEEVFYm3xeCnpFG1BZb8b2I5XS9R/nO7eQj8xJwIDUGAVHGBhZCSaM6+dc4lvrQzPZtpqtdhyrcBZg5HIYhQoGQUQU1gx6La5p2S21ymVpaHVLa4lrR4duhejuiLNga/YWedVMtiO/lNXBIQC9og1IizPKMTyigGMQRERh79qWYGDzwTLUNFlxsNiZKG3QaaXt5D3RjGHpiDLocKKyAXtOV/l1rEMulaJDtbcahR8GQUQU9oZmxmFQWiwsNgc+3V8iJUlPGZyKhCiDwqMLnGiXZrKrdvu3JMakaApFDIKIKOxpNBrMbVn2+uDHM1jbUjyxJyZEtyXWP1q/vxjN1u6byXamtVI0gyAKHQyCiIjg3Aav1QD5Z6pRWW9GUrQBlwxKUXpYATeuXxIy4yNR12zDF4fKfDqGIAisEUQhKfRrwBMRySA1LhITB6ZgW8u2+GvOz0SErud/TtS2NJN98atjeP+HMzg/J8HrY5TVmlFntsGg06J/Ss/bSUc9F4MgIqIW88ZkS0FQT2qT0Z25o7Px4lfHsP1IJSb85SufjzMgNQYGfc8PHKnnYBBERNTiiiFpGNcvCalxRgzNDJ9lnf4pMZg3Ohvr93feSLY7ETotbrwoR8ZREQWeRvC3OEQPVFtbi/j4eNTU1CAuLnz+EBIREYUyb9+/OW9JREREYYlBEBEREYUlBkFEREQUlhgEERERUVhiEERERERhiUEQERERhSUGQURERBSWGAQRERFRWGIQRERERGGJQRARERGFJQZBREREFJYYBBEREVFYYhBEREREYYlBEBEREYUlvdIDUCNBEAAAtbW1Co+EiIiIPCW+b4vv491hENSBuro6AEBOTo7CIyEiIiJv1dXVIT4+vtv7aQRPw6Uw4nA4UFxcjNjYWGg0GlmPXVtbi5ycHJw5cwZxcXGyHrun4nPmGz5vvuHz5hs+b97jc+abrp43QRBQV1eHzMxMaLXdZ/xwJqgDWq0W2dnZAT1HXFwcX/Re4nPmGz5vvuHz5hs+b97jc+abzp43T2aAREyMJiIiorDEIIiIiIjCEoOgIDMajXjsscdgNBqVHkrI4HPmGz5vvuHz5hs+b97jc+YbOZ83JkYTERFRWOJMEBEREYUlBkFEREQUlhgEERERUVhiEERERERhiUFQEL344ovo06cPIiMjMXbsWHz//fdKD0nVHn/8cWg0GrdLXl6e0sNSna+//hpXX301MjMzodFosHbtWrfbBUHA0qVLkZGRAZPJhKlTp+LIkSPKDFZFunveFi1a1O71N336dGUGqxLLli3DhRdeiNjYWKSmpmL27NkoKChwu09zczOWLFmCpKQkxMTEYN68eSgrK1NoxOrgyfN2ySWXtHu93XnnnQqNWHkrVqzAiBEjpIKI48aNw4YNG6Tb5XqdMQgKkvfffx/3338/HnvsMezZswcjR47EtGnTUF5ervTQVG3o0KEoKSmRLjt27FB6SKrT0NCAkSNH4sUXX+zw9meeeQYvvPACVq5ciV27diE6OhrTpk1Dc3NzkEeqLt09bwAwffp0t9ffu+++G8QRqs+2bduwZMkSfPfdd9i8eTOsViuuuOIKNDQ0SPe57777sG7dOnz44YfYtm0biouLMXfuXAVHrTxPnjcA+M1vfuP2envmmWcUGrHysrOz8ec//xm7d+/Gjz/+iMsuuwyzZs3Czz//DEDG15lAQXHRRRcJS5Yskb622+1CZmamsGzZMgVHpW6PPfaYMHLkSKWHEVIACB999JH0tcPhENLT04X/+7//k66rrq4WjEaj8O677yowQnVq+7wJgiAsXLhQmDVrliLjCRXl5eUCAGHbtm2CIDhfWxEREcKHH34o3efQoUMCAGHnzp1KDVN12j5vgiAIkydPFu655x7lBhUCEhMThVdeeUXW1xlngoLAYrFg9+7dmDp1qnSdVqvF1KlTsXPnTgVHpn5HjhxBZmYm+vXrhwULFuD06dNKDymknDhxAqWlpW6vvfj4eIwdO5avPQ9s3boVqampGDRoEO666y6cPXtW6SGpSk1NDQCgV69eAIDdu3fDarW6vd7y8vLQu3dvvt5ctH3eRG+//TaSk5MxbNgwPPLII2hsbFRieKpjt9vx3nvvoaGhAePGjZP1dcYGqkFQWVkJu92OtLQ0t+vT0tJw+PBhhUalfmPHjsUbb7yBQYMGoaSkBH/6058wceJE/PTTT4iNjVV6eCGhtLQUADp87Ym3UcemT5+OuXPnom/fvjh27Bj++Mc/YsaMGdi5cyd0Op3Sw1Ocw+HAvffei4svvhjDhg0D4Hy9GQwGJCQkuN2Xr7dWHT1vADB//nzk5uYiMzMT+/fvx3/913+hoKAAa9asUXC0yjpw4ADGjRuH5uZmxMTE4KOPPsKQIUOQn58v2+uMQRCp1owZM6T/jxgxAmPHjkVubi4++OAD/PrXv1ZwZBQObrzxRun/w4cPx4gRI9C/f39s3boVU6ZMUXBk6rBkyRL89NNPzNPzUmfP2x133CH9f/jw4cjIyMCUKVNw7Ngx9O/fP9jDVIVBgwYhPz8fNTU1WLVqFRYuXIht27bJeg4uhwVBcnIydDpdu8z1srIypKenKzSq0JOQkIDzzjsPR48eVXooIUN8ffG1579+/fohOTmZrz8Ad999N9avX4+vvvoK2dnZ0vXp6emwWCyorq52uz9fb06dPW8dGTt2LACE9evNYDBgwIABGDNmDJYtW4aRI0fib3/7m6yvMwZBQWAwGDBmzBhs2bJFus7hcGDLli0YN26cgiMLLfX19Th27BgyMjKUHkrI6Nu3L9LT091ee7W1tdi1axdfe14qLCzE2bNnw/r1JwgC7r77bnz00Uf48ssv0bdvX7fbx4wZg4iICLfXW0FBAU6fPh3Wr7funreO5OfnA0BYv97acjgcMJvN8r7O5M3dps689957gtFoFN544w3h4MGDwh133CEkJCQIpaWlSg9Ntf7whz8IW7duFU6cOCF88803wtSpU4Xk5GShvLxc6aGpSl1dnbB3715h7969AgBh+fLlwt69e4VTp04JgiAIf/7zn4WEhATh448/Fvbv3y/MmjVL6Nu3r9DU1KTwyJXV1fNWV1cnPPDAA8LOnTuFEydOCF988YUwevRoYeDAgUJzc7PSQ1fMXXfdJcTHxwtbt24VSkpKpEtjY6N0nzvvvFPo3bu38OWXXwo//vijMG7cOGHcuHEKjlp53T1vR48eFZ544gnhxx9/FE6cOCF8/PHHQr9+/YRJkyYpPHLlPPzww8K2bduEEydOCPv37xcefvhhQaPRCJ9//rkgCPK9zhgEBdHf//53oXfv3oLBYBAuuugi4bvvvlN6SKp2ww03CBkZGYLBYBCysrKEG264QTh69KjSw1Kdr776SgDQ7rJw4UJBEJzb5B999FEhLS1NMBqNwpQpU4SCggJlB60CXT1vjY2NwhVXXCGkpKQIERERQm5urvCb3/wm7D+0dPR8ARBef/116T5NTU3C7373OyExMVGIiooS5syZI5SUlCg3aBXo7nk7ffq0MGnSJKFXr16C0WgUBgwYIDz44INCTU2NsgNX0G233Sbk5uYKBoNBSElJEaZMmSIFQIIg3+tMIwiC4OPMFBEREVHIYk4QERERhSUGQURERBSWGAQRERFRWGIQRERERGGJQRARERGFJQZBREREFJYYBBEREVFYYhBERCHt5MmT0Gg0UpuBQFi0aBFmz54dsOMTkTIYBBGRohYtWgSNRtPuMn36dI8en5OTg5KSEgwbNizAIyWinkav9ACIiKZPn47XX3/d7Tqj0ejRY3U6HTuUE5FPOBNERIozGo1IT093uyQmJgIANBoNVqxYgRkzZsBkMqFfv35YtWqV9Ni2y2FVVVVYsGABUlJSYDKZMHDgQLcA68CBA7jssstgMpmQlJSEO+64A/X19dLtdrsd999/PxISEpCUlISHHnoIbbsLORwOLFu2DH379oXJZMLIkSPdxtTdGIhIHRgEEZHqPfroo5g3bx727duHBQsW4MYbb8ShQ4c6ve/BgwexYcMGHDp0CCtWrEBycjIAoKGhAdOmTUNiYiJ++OEHfPjhh/jiiy9w9913S49/9tln8cYbb+C1117Djh07cO7cOXz00Udu51i2bBnefPNNrFy5Ej///DPuu+8+3Hzzzdi2bVu3YyAiFZGt5SsRkQ8WLlwo6HQ6ITo62u3y9NNPC4Lg7MB95513uj1m7Nixwl133SUIgiCcOHFCACDs3btXEARBuPrqq4XFixd3eK6XX35ZSExMFOrr66XrPv30U0Gr1Uod4jMyMoRnnnlGut1qtQrZ2dnCrFmzBEEQhObmZiEqKkr49ttv3Y7961//Wrjpppu6HQMRqQdzgohIcZdeeilWrFjhdl2vXr2k/48bN87ttnHjxnW6G+yuu+7CvHnzsGfPHlxxxRWYPXs2xo8fDwA4dOgQRo4ciejoaOn+F198MRwOBwoKChAZGYmSkhKMHTtWul2v1+OCCy6QlsSOHj2KxsZGXH755W7ntVgsGDVqVLdjICL1YBBERIqLjo7GgAEDZDnWjBkzcOrUKXz22WfYvHkzpkyZgiVLluCvf/2rLMcX84c+/fRTZGVlud0mJnMHegxEJA/mBBGR6n333Xftvh48eHCn909JScHChQvxn//8B88//zxefvllAMDgwYOxb98+NDQ0SPf95ptvoNVqMWjQIMTHxyMjIwO7du2SbrfZbNi9e7f09ZAhQ2A0GnH69GkMGDDA7ZKTk9PtGIhIPTgTRESKM5vNKC0tdbtOr9dLycQffvghLrjgAkyYMAFvv/02vv/+e7z66qsdHmvp0qUYM2YMhg4dCrPZjPXr10sB04IFC/DYY49h4cKFePzxx1FRUYHf//73uOWWW5CWlgYAuOeee/DnP/8ZAwcORF5eHpYvX47q6mrp+LGxsXjggQdw3333weFwYMKECaipqcE333yDuLg4LFy4sMsxEJF6MAgiIsVt3LgRGRkZbtcNGjQIhw8fBgD86U9/wnvvvYff/e53yMjIwLvvvoshQ4Z0eCyDwYBHHnkEJ0+ehMlkwsSJE/Hee+8BAKKiorBp0ybcc889uPDCCxEVFYV58+Zh+fLl0uP/8Ic/oKSkBAsXLoRWq8Vtt92GOXPmoKamRrrPk08+iZSUFCxbtgzHjx9HQkICRo8ejT/+8Y/djoGI1EMjCG0KYBARqYhGo8FHH33EthVEJDvmBBEREVFYYhBEREREYYk5QUSkalyxJ6JA4UwQERERhSUGQURERBSWGAQRERFRWGIQRERERGGJQRARERGFJQZBREREFJYYBBEREVFYYhBEREREYYlBEBEREYWl/w8AHC1JJcZ00AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q-Network - Alternative"
      ],
      "metadata": {
        "id": "uSlOTDlpm78g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Write Code]"
      ],
      "metadata": {
        "id": "c9zO7SZssiaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison\n",
        "\n",
        "Compare performance of the Baseline and the Alternative Naive Q-Network Policies"
      ],
      "metadata": {
        "id": "Lg9kBHn2slYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Write Code]"
      ],
      "metadata": {
        "id": "E6DiE3YRsm2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhgXEg3097Ud"
      },
      "source": [
        "# Experience Replay Framework\n",
        "\n",
        "By now, you may have noticed that in a standard RL setup, the agent **only learns from its most recent experience** at each step. This makes training unstable and inefficient. Additionally, consecutive experiences are often highly correlated, which can lead to poor generalization.\n",
        "\n",
        "To address this, we will adopt the **Experience Replay Framework**, where past interactions are stored in a **Replay Buffer** and **a randomly sampled batch** is used to update the decision-making policy. This helps to:\n",
        "\n",
        "- **Break correlation** between consecutive experiences, stabilizing learning.\n",
        "- **Improve data efficiency** by reusing past experiences multiple times.\n",
        "- **Smooth training updates**, preventing abrupt policy changes.\n",
        "\n",
        "The figure below illustrates this process:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1S3Z6Ngpzwz3haycLS-rzx-eBe9QT88MJ\" width=\"400\">\n",
        "\n",
        "- The Agent interacts with the Environment, taking actions based on its learned policy.\n",
        "- The Replay Buffer stores past experiences `(state, action, reward, next state, done)`.\n",
        "- Instead of updating after every step, the agent samples from the buffer and learns from past interactions.\n",
        "\n",
        "This framework is used in naive DQN, DQN and DDQN to stabilize Q-learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement Replay Buffer and Functions"
      ],
      "metadata": {
        "id": "CkfcXDjNriXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store (state, action, reward, next_state, done)\n",
        "def store_experience(replay_buffer, state, action, reward, next_stat, done):\n",
        "        replay_buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "# Sample (state, action, reward, next_state, done) mini-batch for training\n",
        "def sample_experience(replay_buffer, batch_size):\n",
        "\n",
        "    # Ensure we have enough samples\n",
        "    assert len(replay_buffer) >= batch_size, (\n",
        "        f\"Not enough samples in buffer to sample {batch_size} items.\")\n",
        "\n",
        "    # Sample a mini-batch\n",
        "    minibatch = random.sample(replay_buffer, batch_size)\n",
        "\n",
        "    states, actions, rewards, next_states, dones = zip(*minibatch)\n",
        "\n",
        "    states = np.array(states, dtype=np.float32).squeeze()\n",
        "    next_states = np.array(next_states, dtype=np.float32).squeeze()\n",
        "    actions = np.array(actions, dtype=np.int32)\n",
        "    rewards = np.array(rewards, dtype=np.float32)\n",
        "    dones = np.array(dones, dtype=np.float32)\n",
        "\n",
        "    return states, actions, rewards, next_states, dones\n",
        "\n",
        "# [Hint] You may find the following statements useful\n",
        "\"\"\"\n",
        "# Define replay buffer\n",
        "replay_buffer = deque(maxlen=10000)\n",
        "\n",
        "# Store experience tuple into replay_buffer\n",
        "store_experience(replay_buffer, state, action, reward, next_state, done)\n",
        "\n",
        "# Sample mini-batch of size ba from replay_buffer\n",
        "states, actions, rewards, next_states, dones = sample_experience(replay_buffer, ba)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lJH9KigXsX8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCkBN3gIiLFP"
      },
      "source": [
        "# Naive DQN - Baseline\n",
        "\n",
        "In this section, you will complete the Naive DQN alorithm by implementing the missing components marked as `[WriteCode]`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyRVFFdXvFYk"
      },
      "source": [
        "## Define and Compile the Neural Network\n",
        "\n",
        "A single network $Q_\\theta$ (parameterized by $\\theta$) is used to approximate $Q(s,a)$.\n",
        "\n",
        "The target used by Naive DQN is then:\n",
        "\n",
        "$Y^{NaiveQ}_t = R_{t+1} + \\gamma Q_{\\theta}(S_{t+1}, a)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83PVW-l7DRc6"
      },
      "outputs": [],
      "source": [
        "# Naive DQN Baseline Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "# [WriteCode] from ... import ...\n",
        "\n",
        "# Define the Q-network\n",
        "model = Sequential()\n",
        "\n",
        "# [WriteCode]\n",
        "# model.add(...\n",
        "\n",
        "# Compile the model\n",
        "# [WriteCode]\n",
        "\n",
        "# Print the model summary\n",
        "# [WriteCode]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9X6H46OIExH"
      },
      "source": [
        "## Set Up Env and Train the Policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK70zqKbIHWJ"
      },
      "outputs": [],
      "source": [
        "# For logging\n",
        "train_reward_lst = []\n",
        "eval_reward_mean_lst = []\n",
        "eval_reward_var_lst = []\n",
        "\n",
        "# Set up environment\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "state_size = env.observation_space.shape[0] # Number of observations (CartPole)\n",
        "action_size = env.action_space.n            # Number of possible actions\n",
        "\n",
        "model_dir = \"naive_dqn_baseline\"  # TensorBoard log directory\n",
        "cb = keras.callbacks.TensorBoard(log_dir = get_run_logdir(model_dir), histogram_freq=1)\n",
        "\n",
        "# For timing training\n",
        "total_training_time = 0\n",
        "\n",
        "# Define replay buffer\n",
        "# [WriteCode]\n",
        "# replay_buffer = ...\n",
        "\n",
        "for ep in range(episode):\n",
        "    state, _ = env.reset()\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "    total_reward = 0\n",
        "\n",
        "    # record start time\n",
        "    start = time.time()\n",
        "\n",
        "    for _ in range(500):\n",
        "        # Interact with the environment with epsilon-greedy policy\n",
        "        if np.random.rand() <= epsilon:\n",
        "            action = np.random.choice(action_size)\n",
        "        else:\n",
        "            q_values = model.predict(state, verbose=0)\n",
        "            action = np.argmax(q_values)\n",
        "\n",
        "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "        next_state = np.reshape(next_state, [1, state_size])\n",
        "        done = terminated or truncated\n",
        "\n",
        "        # store experience into replay buffer\n",
        "        # [WriteCode]\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "\n",
        "        if len(replay_buffer) >= ba:\n",
        "            # Update policy with mini-batches if replay buffer contains enough samples\n",
        "            # Update policy using Q-Learning update:  Q(s, a) = r + gamma * max Q(s', a')\n",
        "            # [WriteCode]\n",
        "\n",
        "            # Hints:\n",
        "\n",
        "            # 1. Compute target Q-values:\n",
        "            # - If done, Q-target = reward (no future reward)\n",
        "            # - Otherwise, Q-target = reward + gamma * max(Q(next_state, a))\n",
        "\n",
        "            # 2. Predict current Q-values for state\n",
        "            # Update only the Q-value for the taken action\n",
        "\n",
        "            # 3. Fit the model:\n",
        "            # - Inputs: state\n",
        "            # - Targets: updated Q-values (with action Q-value replaced by computed target)\n",
        "\n",
        "            # Update exploration rate\n",
        "            if epsilon > epsilon_min:\n",
        "                epsilon *= epsilon_decay\n",
        "\n",
        "    # record end time and log training time\n",
        "    end = time.time()\n",
        "    total_training_time += end - start\n",
        "\n",
        "    # Evaluation\n",
        "    # [WriteCode]\n",
        "\n",
        "\n",
        "    print(f\"Episode {ep + 1}/{episode} | Ep. Total Reward: {total_reward}\"\n",
        "        f\" | Epsilon : {epsilon:.3f}\"\n",
        "        f\" | Eval Rwd Mean: {eval_reward_mean:.2f}\"\n",
        "        f\" | Eval Rwd Var: {eval_reward_var:.2f}\")\n",
        "\n",
        "    # Log\n",
        "    eval_reward_mean_lst.append(eval_reward_mean)\n",
        "    eval_reward_var_lst.append(eval_reward_var)\n",
        "    train_reward_lst.append(total_reward)\n",
        "\n",
        "    # Early Stopping Condition to avoid overfitting\n",
        "    # If the evaluation reward reaches the specified threshold, stop training early.\n",
        "    # The default threshold is set to 500, but you should adjust this based on observed training performance.\n",
        "    if eval_reward_mean > 500: # [Modify this threshold as needed]\n",
        "        print(f\"Early stopping triggered at Episode {ep + 1}.\")\n",
        "        break\n",
        "\n",
        "# evaluate average training time per episode\n",
        "print(f\"Training time: {total_training_time/episode:.4f} seconds per episode\")\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Results"
      ],
      "metadata": {
        "id": "HMgwUOjQ30iI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write code to plot\n",
        "# 1) Moving Averaged Training Reward, 2) Evaluation Mean, 3) Evaluation Variance\n",
        "# [Write Code]\n",
        "\n",
        "# plot_smoothed_training_rwd(...\n",
        "\n",
        "# plot_eval_rwd_mean(...\n",
        "\n",
        "# plot_eval_rwd_var(...\n"
      ],
      "metadata": {
        "id": "FcQkJXSl30iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsx1mQTZwhNC"
      },
      "source": [
        "# Naive DQN - Alternative\n",
        "You may insert extra cells in the notebook to perform tuning experiments and log results effectively. Use TensorBoard, plots, or tables to visualize the impact of different hyperparameter choices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auXumGG5w7JN"
      },
      "outputs": [],
      "source": [
        "# [Write Code]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAiI3y2yw47Q"
      },
      "source": [
        "## Comparison\n",
        "\n",
        "Compare performance of the Baseline and the Alternative Naive DQN Policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHIjFgUhw-aR"
      },
      "outputs": [],
      "source": [
        "# [Write Code]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy8REuq6iQah"
      },
      "source": [
        "# DQN\n",
        "\n",
        "In this section, you will complete the DQN algorithm by implementing the missing components marked as `[WriteCode]`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXqZUwXkxYci"
      },
      "source": [
        "## Define and Compile the Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FvxFyz5hnEP"
      },
      "source": [
        "The standard DQN [https://arxiv.org/abs/1312.5602] approach features a periodically updated target network to stabilize training:\n",
        "\n",
        "- `target_model`: A periodically updated network that stabilizes training. During training, this network is used to compute $Q(S_{t+1}, a)$ for each possible action $a$. This network is not actively trained, but at regular intervals, its weights are copied from `eval_model`. This prevents rapid fluctuations in target Q-values and improves learning stability.\n",
        "\n",
        "- `eval_model`: The online learning network that interacts with the environment. During training, this network is used to compute $Q(S_{t}, a)$ for each possible action $a$. It updates its weights by minimizing the difference between predicted and target Q-values, improving the agent's decision-making over time.\n",
        "\n",
        "The target used by DQN is then:\n",
        "\n",
        "$Y^{Q}_t = R_{t+1} + \\gamma \\max_a Q_{target}(S_{t+1}, a)$\n",
        "\n",
        "In the following section, define `[eval_model]` and `[target_model]` with identical architectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYILkt0Gzd5G"
      },
      "outputs": [],
      "source": [
        "# DQN Baseline Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "# [WriteCode] from ... import ...\n",
        "\n",
        "# Define the eval (online) network\n",
        "eval_model = Sequential()\n",
        "\n",
        "# [WriteCode]\n",
        "# model.add(...\n",
        "\n",
        "# Compile the model\n",
        "# [WriteCode]\n",
        "\n",
        "# Print the model summary\n",
        "# [WriteCode]\n",
        "\n",
        "\n",
        "# Create target_model with the same architecture\n",
        "target_model = Sequential()\n",
        "\n",
        "# [WriteCode]\n",
        "# model.add(...\n",
        "\n",
        "# Skip compiling as target_model will not be trained with .fit()\n",
        "# Instead, weights will be copied from the online model\n",
        "target_model.set_weights(eval_model.get_weights())\n",
        "\n",
        "# Print the model summary\n",
        "# [WriteCode]\n",
        "print(target_model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZfiKQHk_Vjb"
      },
      "source": [
        "## Set Up Env and Train the Policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsudLCVWB1Em"
      },
      "source": [
        "In this section, you will complete the DQN training routine by implementing the missing components marked as `[WriteCode]`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I96clO81hFJ_"
      },
      "outputs": [],
      "source": [
        "# For logging\n",
        "train_reward_lst = []\n",
        "eval_reward_mean_lst = []\n",
        "eval_reward_var_lst = []\n",
        "\n",
        "# Set up environment\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "state_size = env.observation_space.shape[0] # Number of observations (CartPole)\n",
        "action_size = env.action_space.n            # Number of possible actions\n",
        "\n",
        "model_dir = \"dqn_baseline\"   # TensorBoard log directory\n",
        "cb = keras.callbacks.TensorBoard(log_dir = get_run_logdir(model_dir), histogram_freq=1)\n",
        "\n",
        "# Train Counter for weight syncing\n",
        "train_counter = 0\n",
        "\n",
        "# For timing training\n",
        "total_training_time = 0\n",
        "\n",
        "# Define replay buffer\n",
        "# replay_buffer = ...\n",
        "\n",
        "for ep in range(episode):\n",
        "    state, _ = env.reset()\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "    total_reward = 0\n",
        "\n",
        "    # record start time\n",
        "    start = time.time()\n",
        "\n",
        "    for _ in range(500):\n",
        "        # Interact with the environment with epsilon-greedy policy\n",
        "        if np.random.rand() <= epsilon:\n",
        "            action = np.random.choice(action_size)\n",
        "        else:\n",
        "            q_values = eval_model.predict(state, verbose=0)\n",
        "            action = np.argmax(q_values)\n",
        "\n",
        "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "        next_state = np.reshape(next_state, [1, state_size])\n",
        "        done = terminated or truncated\n",
        "\n",
        "        # store experience into replay buffer\n",
        "        # [WriteCode]\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "        if len(replay_buffer) >= ba:\n",
        "            train_counter += 1\n",
        "            # Update policy with mini-batches if replay buffer contains enough samples\n",
        "            # Update policy using Deep Q-Learning update: Q(s, a) = r + gamma * max Q_target(S', a)\n",
        "            # [WriteCode]\n",
        "\n",
        "            # Compute target Q-values:\n",
        "            # - If done, Q-target = reward (no future reward)\n",
        "            # - Otherwise, Q-target = reward + gamma * max(Q_target(next_state, a))\n",
        "\n",
        "            # Predict current Q-values for state using eval_model\n",
        "            # Predict future Q-values using target_model (NOT eval_model)\n",
        "\n",
        "            # Update only the Q-value for the taken action\n",
        "\n",
        "            # Fit the model:\n",
        "            # - Inputs: state\n",
        "            # - Targets: updated Q-values (with action Q-value replaced by computed target)\n",
        "\n",
        "\n",
        "            # Update exploration rate\n",
        "            if epsilon > epsilon_min:\n",
        "                epsilon *= epsilon_decay\n",
        "\n",
        "            # Periodically update the target network\n",
        "            if train_counter % target_update_freq == 0:\n",
        "                target_model.set_weights(eval_model.get_weights())\n",
        "\n",
        "    # record end time and log training time\n",
        "    end = time.time()\n",
        "    total_training_time += end - start\n",
        "\n",
        "    # Evaluation\n",
        "    # [WriteCode]\n",
        "\n",
        "\n",
        "    print(f\"Episode {ep + 1}/{episode} | Ep. Total Reward: {total_reward}\"\n",
        "        f\" | Epsilon : {epsilon:.3f}\"\n",
        "        f\" | Eval Rwd Mean: {eval_reward_mean:.2f}\"\n",
        "        f\" | Eval Rwd Var: {eval_reward_var:.2f}\")\n",
        "\n",
        "    # Log\n",
        "    eval_reward_mean_lst.append(eval_reward_mean)\n",
        "    eval_reward_var_lst.append(eval_reward_var)\n",
        "    train_reward_lst.append(total_reward)\n",
        "\n",
        "    # Early Stopping Condition to avoid overfitting\n",
        "    # If the evaluation reward reaches the specified threshold, stop training early.\n",
        "    # The default threshold is set to 500, but you should adjust this based on observed training performance.\n",
        "    if eval_reward_mean > 500: # [Modify this threshold as needed]\n",
        "        print(f\"Early stopping triggered at Episode {ep + 1}.\")\n",
        "        break\n",
        "\n",
        "# evaluate average training time per episode\n",
        "print(f\"Training time: {total_training_time/episode:.4f} seconds per episode\")\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Results"
      ],
      "metadata": {
        "id": "cWTB-X8Q35lX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write code to plot\n",
        "# 1) Moving Averaged Training Reward, 2) Evaluation Mean, 3) Evaluation Variance\n",
        "# [Write Code]\n",
        "plot_smoothed_training_rwd(train_reward_lst, window_size=20)\n",
        "plot_eval_rwd_mean(eval_reward_mean_lst)\n",
        "plot_eval_rwd_var(eval_reward_var_lst)"
      ],
      "metadata": {
        "id": "gUC2aelO35lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DQN - Alternative\n",
        "\n",
        "You may insert extra cells in the notebook to perform tuning experiments and log results effectively. Use TensorBoard, plots, or tables to visualize the impact of different hyperparameter choices."
      ],
      "metadata": {
        "id": "aGOFWup5ZiYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Results"
      ],
      "metadata": {
        "id": "eOwN55lA34nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write code to plot\n",
        "# 1) Moving Averaged Training Reward, 2) Evaluation Mean, 3) Evaluation Variance\n",
        "# [Write Code]\n",
        "\n",
        "# plot_smoothed_training_rwd(...\n",
        "\n",
        "# plot_eval_rwd_mean(...\n",
        "\n",
        "# plot_eval_rwd_var(..."
      ],
      "metadata": {
        "id": "hf5220Bw34nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [Write Code]"
      ],
      "metadata": {
        "id": "SvxOyxpPZlfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison\n",
        "\n",
        "Compare performance of the Baseline and the Alternative DQN Policies"
      ],
      "metadata": {
        "id": "0oTzmTnlZlru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Write Code]"
      ],
      "metadata": {
        "id": "HiMW7bE1Zq2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yGOGzD5iRw5"
      },
      "source": [
        "# DDQN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define and Compile the Neural Networks\n",
        "\n",
        "The Double Deep Q-Network (DDQN) [https://arxiv.org/abs/1509.06461] improves upon standard DQN by reducing overestimation bias in Q-values. DDQN achieves this by decoupling action selection from value estimation using two networks, which is almost identical as DQN:\n",
        "\n",
        "- `target_model`: A periodically updated network that stabilizes training. During training, this network is used to compute $Q(S_{t+1}, a)$ for each possible action $a$. This network is also not trained but synced from `eval_model`. **However, unlike DQN, this network is only used to evaluate the Q-value of the action chosen by `eval_model`, making value updates more stable.**\n",
        "\n",
        "- `eval_model`: The online learning network that interacts with the environment. During training, this network is used to select the best action using $\\arg\\max_a Q(S_{t}, a)$ and updates its weights by minimizing the difference between predicted and target Q-value.\n",
        "\n",
        "The target used by DDQN is then:\n",
        "\n",
        "$Y^{Q}_t = R_{t+1} + \\gamma Q_{target}(S_{t+1}, \\arg \\max_{a} Q_{eval}(S_{t+1}, a))$"
      ],
      "metadata": {
        "id": "-nURxQ5zZwu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DDQN Baseline Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "# [WriteCode] from ... import ...\n",
        "\n",
        "# Define the eval (online) network\n",
        "eval_model = Sequential()\n",
        "\n",
        "# [WriteCode]\n",
        "# model.add(...\n",
        "\n",
        "# Compile the model\n",
        "# [WriteCode]\n",
        "\n",
        "# Print the model summary\n",
        "# [WriteCode]\n",
        "\n",
        "\n",
        "\n",
        "# Create target_model with the same architecture\n",
        "target_model = Sequential()\n",
        "\n",
        "# [WriteCode]\n",
        "# model.add(...\n",
        "\n",
        "# Skip compiling as target_model will not be trained with .fit()\n",
        "# Instead, weights will be copied from the online model\n",
        "target_model.set_weights(eval_model.get_weights())\n",
        "\n",
        "# Print the model summary\n",
        "# [WriteCode]"
      ],
      "metadata": {
        "id": "NoH_Tjmz3FBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up Env and Train the Policy"
      ],
      "metadata": {
        "id": "-uZT2NevZzo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For logging\n",
        "train_reward_lst = []\n",
        "eval_reward_mean_lst = []\n",
        "eval_reward_var_lst = []\n",
        "\n",
        "# Set up environment\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "state_size = env.observation_space.shape[0] # Number of observations (CartPole)\n",
        "action_size = env.action_space.n            # Number of possible actions\n",
        "\n",
        "model_dir = \"ddqn_baseline\"  # TensorBoard log directory\n",
        "cb = keras.callbacks.TensorBoard(log_dir = get_run_logdir(model_dir), histogram_freq=1)\n",
        "\n",
        "# Train Counter for weight syncing\n",
        "train_counter = 0\n",
        "\n",
        "# For timing training\n",
        "total_training_time = 0\n",
        "\n",
        "# Define replay buffer\n",
        "# replay_buffer = ...\n",
        "\n",
        "for ep in range(episode):\n",
        "    state, _ = env.reset()\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "    total_reward = 0\n",
        "\n",
        "    # record start time\n",
        "    start = time.time()\n",
        "\n",
        "    for _ in range(500):\n",
        "\n",
        "        # Interact with the environment with epsilon-greedy policy\n",
        "        if np.random.rand() <= epsilon:\n",
        "            action = np.random.choice(action_size)\n",
        "        else:\n",
        "            q_values = eval_model.predict(state, verbose=0)\n",
        "            action = np.argmax(q_values)\n",
        "\n",
        "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "        next_state = np.reshape(next_state, [1, state_size])\n",
        "        done = terminated or truncated\n",
        "\n",
        "        # store experience into replay buffer\n",
        "        # [WriteCode]\n",
        "\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "        if len(replay_buffer) >= ba:\n",
        "            train_counter += 1\n",
        "            # Update policy with mini-batches if replay buffer contains enough samples\n",
        "            # Update policy using Double Deep Q-Learning update:\n",
        "            # Q(s, a) = r + gamma * Q_target(S', argmax Q_eval(S', a))\n",
        "            # [WriteCode]\n",
        "\n",
        "            # Compute target Q-values:\n",
        "            # - If done, Q-target = reward (no future reward)\n",
        "            # - Otherwise, Q-target = reward + gamma * Q_target(S', argmax Q_eval(S', a))\n",
        "\n",
        "            # Predict current Q-values for state using eval_model\n",
        "            # Use eval_model to determine best action in next_state\n",
        "            # Use target_model to compute Q-value for that action\n",
        "\n",
        "            # Update only the Q-value for the taken action\n",
        "\n",
        "            # Fit the model:\n",
        "            # - Inputs: state\n",
        "            # - Targets: updated Q-values (with action Q-value replaced by computed target)\n",
        "\n",
        "\n",
        "            # Update exploration rate\n",
        "            if epsilon > epsilon_min:\n",
        "                epsilon *= epsilon_decay\n",
        "\n",
        "            # Periodically update the target network\n",
        "            if train_counter % target_update_freq == 0:\n",
        "                target_model.set_weights(eval_model.get_weights())\n",
        "\n",
        "    # record end time and log training time\n",
        "    end = time.time()\n",
        "    total_training_time += end - start\n",
        "\n",
        "    # Evaluation\n",
        "    # [WriteCode]\n",
        "\n",
        "\n",
        "    print(f\"Episode {ep + 1}/{episode} | Ep. Total Reward: {total_reward}\"\n",
        "        f\" | Epsilon : {epsilon:.3f}\"\n",
        "        f\" | Eval Rwd Mean: {eval_reward_mean:.2f}\"\n",
        "        f\" | Eval Rwd Var: {eval_reward_var:.2f}\")\n",
        "\n",
        "    # Log\n",
        "    eval_reward_mean_lst.append(eval_reward_mean)\n",
        "    eval_reward_var_lst.append(eval_reward_var)\n",
        "    train_reward_lst.append(total_reward)\n",
        "\n",
        "    # Early Stopping Condition to avoid overfitting\n",
        "    # If the evaluation reward reaches the specified threshold, stop training early.\n",
        "    # The default threshold is set to 500, but you should adjust this based on observed training performance.\n",
        "    if eval_reward_mean > 500: # [Modify this threshold as needed]\n",
        "        print(f\"Early stopping triggered at Episode {ep + 1}.\")\n",
        "        break\n",
        "\n",
        "# record end time and calculate average training time per episode\n",
        "# evaluate average training time per episode\n",
        "print(f\"Training time: {total_training_time/episode:.4f} seconds per episode\")\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "id": "4U9ntMqg3TH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Results"
      ],
      "metadata": {
        "id": "oKfbQWJq363X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write code to plot\n",
        "# 1) Moving Averaged Training Reward, 2) Evaluation Mean, 3) Evaluation Variance\n",
        "# [Write Code]\n",
        "\n",
        "# plot_smoothed_training_rwd(...\n",
        "\n",
        "# plot_eval_rwd_mean(...\n",
        "\n",
        "# plot_eval_rwd_var(..."
      ],
      "metadata": {
        "id": "L7qIOwiX363Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DDQN - Alternative\n",
        "\n",
        "You may insert extra cells in the notebook to perform tuning experiments and log results effectively. Use TensorBoard, plots, or tables to visualize the impact of different hyperparameter choices."
      ],
      "metadata": {
        "id": "YgVEqsvQHsiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Write Code]"
      ],
      "metadata": {
        "id": "0xno9cGCHrx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison\n",
        "\n",
        "Compare performance of the Baseline and the Alternative DDQN Policies"
      ],
      "metadata": {
        "id": "5MBGp2LfHxDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Write Code]"
      ],
      "metadata": {
        "id": "3NDTwhmwH3Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize with Tensorboard"
      ],
      "metadata": {
        "id": "VUo4vcwQnbWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=./ee4802_logs --port=6006"
      ],
      "metadata": {
        "id": "ZcIJ3DQc3-Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison Across Four Alternative Policies\n",
        "\n",
        "Compare hyperparameters and performance of the four alternative policies.\n",
        "\n",
        "You may insert extra cells in the notebook to tabulate/plot/log results effectively."
      ],
      "metadata": {
        "id": "l-insiT7D_lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Write Code]"
      ],
      "metadata": {
        "id": "SjQwsaxSE5Jh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}